{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 \n",
    "import textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is done here:\n",
    "\n",
    "The PyPDF2 library lets us extract text from pdf files. The task here is to extract casualties and damage reports from the Damages section in the reports. We used PyPDF2 to extract the text from each page of the pdf and from the extracted text, we store only the 'Damages' section in the DAMAGE_SECTION string.\n",
    "\n",
    "TODO:\n",
    "Figure out a way to extract raw numbers from the string DAMAGE_SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a for-loop to open many files (leave a comment if you'd like to learn how).\n",
    "filename = 'AL012004_Alex.pdf' \n",
    "\n",
    "#open allows you to read the file.\n",
    "pdfFileObj = open(filename,'rb')\n",
    "\n",
    "#The pdfReader variable is a readable object that will be parsed.\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "#Discerning the number of pages will allow us to parse through all the pages.\n",
    "num_pages = pdfReader.numPages\n",
    "count = 0\n",
    "text = \"\"\n",
    "\n",
    "#The while loop will read each page.\n",
    "while count < num_pages:\n",
    "    pageObj = pdfReader.getPage(count)\n",
    "    count +=1\n",
    "    text += pageObj.extractText()\n",
    "    \n",
    "#This if statement exists to check if the above library returned words. It's done because PyPDF2 cannot read scanned files.\n",
    "if text != \"\":\n",
    "   text = text\n",
    "\n",
    "#If the above returns as False, we run the OCR library textract to #convert scanned/image based PDF files into text.\n",
    "else:\n",
    "   text = textract.process(fileurl, method='tesseract', language='eng')\n",
    "\n",
    "#Now we have a text variable that contains all the text derived from our PDF file. Type print(text) to see what it contains. It likely contains a lot of spaces, possibly junk such as '\\n,' etc.\n",
    "#Now, we will clean our text variable and return it as a list of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The word_tokenize() function will break our text phrases into individual words.\n",
    "tokens = word_tokenize(text)\n",
    "#We'll create a new list that contains punctuation we wish to clean.\n",
    "punctuations = []#['(',')',';',':','[',']',',']\n",
    "#We initialize the stopwords variable, which is a list of words like \"The,\" \"I,\" \"and,\" etc. that don't hold much value as keywords.\n",
    "stop_words = []#stopwords.words('english')\n",
    "#We create a list comprehension that only returns a list of words that are NOT IN stop_words and NOT IN punctuations.\n",
    "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  1374  end:  1529\n"
     ]
    }
   ],
   "source": [
    "start = keywords.index('Casualty')\n",
    "end = keywords.index('d.')\n",
    "print('start: ',start,' end: ', end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Casualty and Damage Statistics A 26 year-old male was drowned in strong waves and residual rip currents off of Nags Head , North Carolina , two days after the passage of Alex . Storm surge damage and beach erosion was significa nt in Dare and Hyde counties on the Outer Banks . Significant wind and water damage occ urred from Buxton southward and across Ocracoke Island , where hundreds of vehicles and hom es were flooded from sound-side surge . Hurricane force winds produced minor structural dam age to homes and businesses and caused extensive damage to trees and power lines . There was insufficient wind damage associated with Alex to meet the $ 25 million reporting level threshold of the American Insurance Services Group . Insured damage from flooding is estimated to be about $ 2 million . The total damage from Alex is estimated to be not more than $ 5 million .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAMAGE_SECTION = ''\n",
    "for word in keywords[start:end]:\n",
    "    DAMAGE_SECTION +=(word + ' ')\n",
    "DAMAGE_SECTION.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
