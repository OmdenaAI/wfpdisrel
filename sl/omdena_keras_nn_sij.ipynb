{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PgLv7G2mtxxE"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'property' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a960913d72e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplotnine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mggplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat_smooth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacet_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_histogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotnine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeom_boxplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_y_log10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mggtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotnine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfacet_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_x_log10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/plotnine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mqplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mqplot\u001b[0m            \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mggplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mggplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mggsave\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mggplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_as_pdf_pages\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwatermark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwatermark\u001b[0m    \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m                  \u001b[0;31m# noqa: F401,F403,E261\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/plotnine/qplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpatsy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mggplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mggplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_aesthetics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_aesthetics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/plotnine/ggplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsetbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnchoredOffsetbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mArtist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \"\"\"\n\u001b[1;32m     59\u001b[0m     \u001b[0mAbstract\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mrender\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mFigureCanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mArtist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \"\"\"\n\u001b[1;32m     63\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'Artist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mdeprecate\u001b[0;34m(obj, message, name, alternative, pending, addendum)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mBasic\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.4.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mthe_function_to_deprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'property' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "! # pip install eli5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap, geom_histogram\n",
    "from plotnine import geom_boxplot, scale_y_log10, geom_bar, geom_line, ggtitle\n",
    "from plotnine import facet_wrap, scale_x_log10\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import itertools\n",
    "import scipy.stats as scs\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import LeakyReLU, BatchNormalization, ReLU\n",
    "from keras import callbacks, optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "#from eli5.sklearn import PermutationImportance\n",
    "#import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5paffY9gcMe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting plotnine\n",
      "  Downloading plotnine-0.6.0-py3-none-any.whl (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 337 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.1 in /Users/cydal/miniconda3/lib/python3.6/site-packages (from plotnine) (0.5.1)\n",
      "Collecting mizani>=0.6.0\n",
      "  Downloading mizani-0.6.0-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /Users/cydal/miniconda3/lib/python3.6/site-packages (from plotnine) (0.11.1)\n",
      "Collecting matplotlib>=3.1.1\n",
      "  Downloading matplotlib-3.2.1-cp36-cp36m-macosx_10_9_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /Users/cydal/miniconda3/lib/python3.6/site-packages (from plotnine) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/cydal/miniconda3/lib/python3.6/site-packages (from plotnine) (1.18.1)\n",
      "Collecting pandas>=0.25.0\n",
      "  Downloading pandas-1.0.3-cp36-cp36m-macosx_10_9_x86_64.whl (10.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2 MB 1.6 MB/s eta 0:00:01    |█████████████████▋              | 5.6 MB 2.3 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting descartes>=1.1.0\n",
      "  Downloading descartes-1.1.0-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: six in /Users/cydal/miniconda3/lib/python3.6/site-packages (from patsy>=0.4.1->plotnine) (1.14.0)\n",
      "Collecting palettable\n",
      "  Downloading palettable-3.3.0-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/cydal/miniconda3/lib/python3.6/site-packages (from matplotlib>=3.1.1->plotnine) (2.2.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp36-cp36m-macosx_10_9_x86_64.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 4.1 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /Users/cydal/miniconda3/lib/python3.6/site-packages (from matplotlib>=3.1.1->plotnine) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/cydal/miniconda3/lib/python3.6/site-packages (from matplotlib>=3.1.1->plotnine) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/cydal/miniconda3/lib/python3.6/site-packages (from pandas>=0.25.0->plotnine) (2019.3)\n",
      "Installing collected packages: pandas, kiwisolver, matplotlib, palettable, mizani, descartes, plotnine\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 0.23.4\n",
      "    Uninstalling pandas-0.23.4:\n",
      "      Successfully uninstalled pandas-0.23.4\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 2.1.2\n",
      "    Uninstalling matplotlib-2.1.2:\n",
      "      Successfully uninstalled matplotlib-2.1.2\n",
      "Successfully installed descartes-1.1.0 kiwisolver-1.2.0 matplotlib-3.2.1 mizani-0.6.0 palettable-3.3.0 pandas-1.0.3 plotnine-0.6.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "7mSQ72lrUFO-",
    "outputId": "835e7103-ee46-46ac-ebae-8a134d679cb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nland = pd.read_csv('/content/drive/My Drive/omdena-model-b-c-nn/dataset/LAND_COVER_03052020050019102.csv')\\nland = land[['COU', 'VARIABLE', 'YEA', 'Value']]\\nland = land[land['YEA'] == 2015]\\n\\nland_pivot = land.pivot(columns='VARIABLE', values='Value')\\nland_pivot = land_pivot.fillna(0.0)\\n\\nland_final = pd.concat([land, land_pivot], axis=1)\\n\\nld_cols = ['COU', 'CROPL',\\t'FOREST',\\t'GRSL',\\t'SHRUBL',\\t\\n           'SPARSE_VEGETATION', 'URBAN',\\t'WATER', 'WETL']\\n\\nland_final = land_final[ld_cols]\\n\\n\\nland_final_g = land_final.groupby(['COU']).sum()\\n\\n\\ndf = pd.merge(df, land_final_g, how='left', left_on=['ISO'], right_on=['COU'])\\n\""
      ]
     },
     "execution_count": 246,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "land = pd.read_csv('/content/drive/My Drive/omdena-model-b-c-nn/dataset/LAND_COVER_03052020050019102.csv')\n",
    "land = land[['COU', 'VARIABLE', 'YEA', 'Value']]\n",
    "land = land[land['YEA'] == 2015]\n",
    "\n",
    "land_pivot = land.pivot(columns='VARIABLE', values='Value')\n",
    "land_pivot = land_pivot.fillna(0.0)\n",
    "\n",
    "land_final = pd.concat([land, land_pivot], axis=1)\n",
    "\n",
    "ld_cols = ['COU', 'CROPL',\t'FOREST',\t'GRSL',\t'SHRUBL',\t\n",
    "           'SPARSE_VEGETATION', 'URBAN',\t'WATER', 'WETL']\n",
    "\n",
    "land_final = land_final[ld_cols]\n",
    "\n",
    "\n",
    "land_final_g = land_final.groupby(['COU']).sum()\n",
    "\n",
    "\n",
    "df = pd.merge(df, land_final_g, how='left', left_on=['ISO'], right_on=['COU'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUKzvBHEFImk"
   },
   "source": [
    "## Load important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MpiHuEet8SK"
   },
   "outputs": [],
   "source": [
    "# Import File\n",
    "filepath = '/content/drive/My Drive/omdena-model-b-c-nn/dataset/OUTPUT_WBI_exposer_cyclones_v14.csv'\n",
    "df = pd.read_csv(filepath, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "AjZV9ok3ORm-",
    "outputId": "e53e7edb-3b02-419d-fd70-027935dea67a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ISO</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>COORDS</th>\n",
       "      <th>COORDS_MAX_WINDS</th>\n",
       "      <th>COORDS_MIN_DIST2LAND</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>SUB BASIN</th>\n",
       "      <th>MONTH_START</th>\n",
       "      <th>MONTH_END</th>\n",
       "      <th>DATE_START</th>\n",
       "      <th>DATE_END</th>\n",
       "      <th>DATE_LAND_START</th>\n",
       "      <th>DATE_LAND_END</th>\n",
       "      <th>TOTAL_HOURS_EVENT</th>\n",
       "      <th>TOTAL_HOURS_IN_LAND</th>\n",
       "      <th>NATURE</th>\n",
       "      <th>GENERAL_CATEGORY</th>\n",
       "      <th>MAX_WIND</th>\n",
       "      <th>MIN_PRES</th>\n",
       "      <th>MIN_DIST2LAND</th>\n",
       "      <th>MAX_STORMSPEED</th>\n",
       "      <th>MAX_USA_SSHS</th>\n",
       "      <th>MAX_USA_SSHS_INLAND</th>\n",
       "      <th>V_LAND_KN</th>\n",
       "      <th>DISTANCE_TRACK</th>\n",
       "      <th>DISTANCE_TRACK_VINCENTY</th>\n",
       "      <th>34KN_POP</th>\n",
       "      <th>64KN_POP</th>\n",
       "      <th>96KN_POP</th>\n",
       "      <th>64KN_ASSETS</th>\n",
       "      <th>34KN_ASSETS</th>\n",
       "      <th>96KN_ASSETS</th>\n",
       "      <th>TOTAL_DAMAGE_(000$)</th>\n",
       "      <th>TOTAL_DEATHS</th>\n",
       "      <th>POP_DEN_SQ_KM</th>\n",
       "      <th>RURAL_POP(%)</th>\n",
       "      <th>HDI</th>\n",
       "      <th>Arable land (hectares per person)</th>\n",
       "      <th>Cereal yield (kg per hectare)</th>\n",
       "      <th>Food production index (2004-2006 = 100)</th>\n",
       "      <th>GDP per capita (constant 2010 US$)</th>\n",
       "      <th>Net flows from UN agencies US$</th>\n",
       "      <th>Life expectancy at birth, total (years)</th>\n",
       "      <th>Adjusted savings: education expenditure (% of GNI)</th>\n",
       "      <th>Income_level_Final</th>\n",
       "      <th>POP_MAX_34_ADJ</th>\n",
       "      <th>POP_MAX_50_ADJ</th>\n",
       "      <th>POP_MAX_64_ADJ</th>\n",
       "      <th>TOTAL_AFFECTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949163N07145</td>\n",
       "      <td>DELLA</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1949</td>\n",
       "      <td>[(21.5, 125.424), (22.2, 125.8), (22.9089, 126...</td>\n",
       "      <td>[(27.6584, 128.82), (28.9141, 129.572999999999...</td>\n",
       "      <td>[(31.9866, 130.683), (33.5183, 130.97299999999...</td>\n",
       "      <td>WP</td>\n",
       "      <td>WP</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>19/06/1949 9:00</td>\n",
       "      <td>24/06/1949 6:00</td>\n",
       "      <td>20/06/1949 15:00</td>\n",
       "      <td>23/06/1949 3:00</td>\n",
       "      <td>117.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Cat 4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>952</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>99.82</td>\n",
       "      <td>3889.480640</td>\n",
       "      <td>3632.626180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>419.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>77.20</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>4173.5</td>\n",
       "      <td>67.79</td>\n",
       "      <td>8607.657082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.666098</td>\n",
       "      <td>2.867878</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.198300e+07</td>\n",
       "      <td>5.803981e+06</td>\n",
       "      <td>3.320907e+06</td>\n",
       "      <td>194046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950241N23140</td>\n",
       "      <td>JANE</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1950</td>\n",
       "      <td>[(23.8845, 139.74), (23.9335, 139.639), (23.98...</td>\n",
       "      <td>[(28.7509, 133.748), (29.1201, 133.762), (29.6...</td>\n",
       "      <td>[(34.9374, 135.476), (36.1016, 136.095), (37.2...</td>\n",
       "      <td>WP</td>\n",
       "      <td>WP</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>30/08/1950 3:00</td>\n",
       "      <td>05/09/1950 0:00</td>\n",
       "      <td>03/09/1950 3:00</td>\n",
       "      <td>04/09/1950 0:00</td>\n",
       "      <td>141.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>ET</td>\n",
       "      <td>Cat 4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>940</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>99.82</td>\n",
       "      <td>3596.090691</td>\n",
       "      <td>2787.480021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>509.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>47.00</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>4173.5</td>\n",
       "      <td>67.79</td>\n",
       "      <td>8607.657082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.666098</td>\n",
       "      <td>2.867878</td>\n",
       "      <td>Low</td>\n",
       "      <td>3.160822e+07</td>\n",
       "      <td>1.559196e+07</td>\n",
       "      <td>1.018936e+07</td>\n",
       "      <td>642117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951224N12316</td>\n",
       "      <td>CHARLIE</td>\n",
       "      <td>JAM</td>\n",
       "      <td>1951</td>\n",
       "      <td>[(17.3398, -75.4138), (17.6, -76.2), (17.9, -7...</td>\n",
       "      <td>[(17.6, -76.2), (17.9, -76.9)]</td>\n",
       "      <td>[(17.9, -76.9), (18.1, -77.8)]</td>\n",
       "      <td>NAm</td>\n",
       "      <td>CS</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>17/08/1951 21:00</td>\n",
       "      <td>18/08/1951 12:00</td>\n",
       "      <td>18/08/1951 3:00</td>\n",
       "      <td>18/08/1951 6:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Cat 3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>132.40</td>\n",
       "      <td>438.214691</td>\n",
       "      <td>435.729082</td>\n",
       "      <td>2788659.0</td>\n",
       "      <td>2788659.0</td>\n",
       "      <td>2552903.0</td>\n",
       "      <td>2.148198e+10</td>\n",
       "      <td>2.148198e+10</td>\n",
       "      <td>1.948346e+10</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>66.23</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.100541</td>\n",
       "      <td>868.3</td>\n",
       "      <td>69.93</td>\n",
       "      <td>3796.219401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.770000</td>\n",
       "      <td>2.578304</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.689243e+06</td>\n",
       "      <td>1.687083e+06</td>\n",
       "      <td>1.195052e+06</td>\n",
       "      <td>20200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951337N09150</td>\n",
       "      <td>AMY</td>\n",
       "      <td>PHL</td>\n",
       "      <td>1951</td>\n",
       "      <td>[(12.0725, 130.967), (12.1333, 130.517), (12.1...</td>\n",
       "      <td>[(11.7833, 127.9)]</td>\n",
       "      <td>[(10.7333, 124.8), (10.534, 123.174), (10.6833...</td>\n",
       "      <td>WP</td>\n",
       "      <td>WP</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>07/12/1951 9:00</td>\n",
       "      <td>17/12/1951 0:00</td>\n",
       "      <td>09/12/1951 12:00</td>\n",
       "      <td>11/12/1951 0:00</td>\n",
       "      <td>231.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Cat 4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>924</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>119.20</td>\n",
       "      <td>2238.058669</td>\n",
       "      <td>1905.587795</td>\n",
       "      <td>20464826.0</td>\n",
       "      <td>12675908.0</td>\n",
       "      <td>5618193.0</td>\n",
       "      <td>1.131050e+11</td>\n",
       "      <td>1.880280e+11</td>\n",
       "      <td>4.897333e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>569.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>75.35</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.180442</td>\n",
       "      <td>996.3</td>\n",
       "      <td>25.68</td>\n",
       "      <td>1059.467412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.105000</td>\n",
       "      <td>2.757732</td>\n",
       "      <td>Low_Middle</td>\n",
       "      <td>4.760039e+06</td>\n",
       "      <td>3.006670e+06</td>\n",
       "      <td>1.114774e+06</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1952180N05144</td>\n",
       "      <td>EMMA</td>\n",
       "      <td>PHL</td>\n",
       "      <td>1952</td>\n",
       "      <td>[(9.33776, 130.185), (9.38633, 129.61), (9.45,...</td>\n",
       "      <td>[(9.45, 129.017), (9.50407, 128.407), (9.56613...</td>\n",
       "      <td>[(10.4667, 123.867), (10.6492, 123.239), (10.8...</td>\n",
       "      <td>WP</td>\n",
       "      <td>WP</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>01/07/1952 6:00</td>\n",
       "      <td>04/07/1952 18:00</td>\n",
       "      <td>02/07/1952 12:00</td>\n",
       "      <td>02/07/1952 21:00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Cat 3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>968</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>110691.00</td>\n",
       "      <td>1876.186790</td>\n",
       "      <td>1797.712213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>66.9</td>\n",
       "      <td>72.41</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.180442</td>\n",
       "      <td>996.3</td>\n",
       "      <td>25.68</td>\n",
       "      <td>1059.467412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.105000</td>\n",
       "      <td>2.757732</td>\n",
       "      <td>Low_Middle</td>\n",
       "      <td>5.130796e+06</td>\n",
       "      <td>2.789486e+06</td>\n",
       "      <td>1.988524e+06</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SID     NAME  ISO  ...  POP_MAX_50_ADJ POP_MAX_64_ADJ TOTAL_AFFECTED\n",
       "0  1949163N07145    DELLA  JPN  ...    5.803981e+06   3.320907e+06         194046\n",
       "1  1950241N23140     JANE  JPN  ...    1.559196e+07   1.018936e+07         642117\n",
       "2  1951224N12316  CHARLIE  JAM  ...    1.687083e+06   1.195052e+06          20200\n",
       "3  1951337N09150      AMY  PHL  ...    3.006670e+06   1.114774e+06          60000\n",
       "4  1952180N05144     EMMA  PHL  ...    2.789486e+06   1.988524e+06            103\n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i42qngTPDIF3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlgvpKl6FtyG"
   },
   "source": [
    "# Drop Columns & Some Pre - preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQvmJjwtt9ye"
   },
   "outputs": [],
   "source": [
    "# Drop some unimportant features\n",
    "drop_cols = ['34KN_POP', '34KN_ASSETS', '64KN_POP', '64KN_ASSETS', \n",
    "             '96KN_POP', '96KN_ASSETS', \"SID\", 'NAME', 'ISO', \n",
    "             'TOTAL_DAMAGE_(000$)', 'TOTAL_DEATHS', 'DATE_LAND_END',\n",
    "             'DATE_START',\t'DATE_END',\t'DATE_LAND_START', 'MONTH_END',\n",
    "             'COORDS',\t'COORDS_MAX_WINDS',\t'COORDS_MIN_DIST2LAND', \n",
    "             'TOTAL_HOURS_EVENT']\n",
    "\n",
    "df = df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CrrEpKyt_Lj"
   },
   "outputs": [],
   "source": [
    "### Xaview Preprocessing\n",
    "df[\"SUB BASIN\"]= df[\"SUB BASIN\"].replace('MM', np.nan) \n",
    "df[\"BASIN\"]= df[\"BASIN\"].replace('MM', np.nan)\n",
    "\n",
    "df['SUB BASIN']= np.where(df['SUB BASIN'].isnull(), df['BASIN'], df['SUB BASIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8d_l0VwhuAnS",
    "outputId": "91d4118c-9e7a-440f-a3ab-d4d169248a1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WP', 'NAm', 'SP', 'EP', 'SI', 'NI'], dtype=object)"
      ]
     },
     "execution_count": 251,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"BASIN\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "OBqM6HBwKQJP",
    "outputId": "ac28c65e-a889-4e11-fb5d-dd277cb618dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 991 entries, 0 to 990\n",
      "Data columns (total 31 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   YEAR                                                991 non-null    int64  \n",
      " 1   BASIN                                               991 non-null    object \n",
      " 2   SUB BASIN                                           991 non-null    object \n",
      " 3   MONTH_START                                         991 non-null    int64  \n",
      " 4   TOTAL_HOURS_IN_LAND                                 991 non-null    float64\n",
      " 5   NATURE                                              991 non-null    object \n",
      " 6   GENERAL_CATEGORY                                    991 non-null    object \n",
      " 7   MAX_WIND                                            991 non-null    float64\n",
      " 8   MIN_PRES                                            991 non-null    int64  \n",
      " 9   MIN_DIST2LAND                                       991 non-null    int64  \n",
      " 10  MAX_STORMSPEED                                      989 non-null    float64\n",
      " 11  MAX_USA_SSHS                                        991 non-null    int64  \n",
      " 12  MAX_USA_SSHS_INLAND                                 991 non-null    object \n",
      " 13  V_LAND_KN                                           991 non-null    float64\n",
      " 14  DISTANCE_TRACK                                      991 non-null    float64\n",
      " 15  DISTANCE_TRACK_VINCENTY                             991 non-null    float64\n",
      " 16  POP_DEN_SQ_KM                                       991 non-null    float64\n",
      " 17  RURAL_POP(%)                                        991 non-null    float64\n",
      " 18  HDI                                                 991 non-null    float64\n",
      " 19  Arable land (hectares per person)                   990 non-null    float64\n",
      " 20  Cereal yield (kg per hectare)                       981 non-null    float64\n",
      " 21  Food production index (2004-2006 = 100)             987 non-null    float64\n",
      " 22  GDP per capita (constant 2010 US$)                  982 non-null    float64\n",
      " 23  Net flows from UN agencies US$                      991 non-null    float64\n",
      " 24  Life expectancy at birth, total (years)             987 non-null    float64\n",
      " 25  Adjusted savings: education expenditure (% of GNI)  981 non-null    float64\n",
      " 26  Income_level_Final                                  991 non-null    object \n",
      " 27  POP_MAX_34_ADJ                                      911 non-null    float64\n",
      " 28  POP_MAX_50_ADJ                                      911 non-null    float64\n",
      " 29  POP_MAX_64_ADJ                                      911 non-null    float64\n",
      " 30  TOTAL_AFFECTED                                      991 non-null    int64  \n",
      "dtypes: float64(19), int64(6), object(6)\n",
      "memory usage: 240.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "0v1ONiuvuCA-",
    "outputId": "1f22a978-66be-4ea1-d6f2-b278b6a92da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR ---- 0.0\n",
      "BASIN ---- 0.0\n",
      "SUB BASIN ---- 0.0\n",
      "MONTH_START ---- 0.0\n",
      "TOTAL_HOURS_IN_LAND ---- 0.0\n",
      "NATURE ---- 0.0\n",
      "GENERAL_CATEGORY ---- 0.0\n",
      "MAX_WIND ---- 0.0\n",
      "MIN_PRES ---- 0.0\n",
      "MIN_DIST2LAND ---- 0.0\n",
      "MAX_STORMSPEED ---- 0.20181634712411706\n",
      "MAX_USA_SSHS ---- 0.0\n",
      "MAX_USA_SSHS_INLAND ---- 0.0\n",
      "V_LAND_KN ---- 0.0\n",
      "DISTANCE_TRACK ---- 0.0\n",
      "DISTANCE_TRACK_VINCENTY ---- 0.0\n",
      "POP_DEN_SQ_KM ---- 0.0\n",
      "RURAL_POP(%) ---- 0.0\n",
      "HDI ---- 0.0\n",
      "Arable land (hectares per person) ---- 0.10090817356205853\n",
      "Cereal yield (kg per hectare) ---- 1.0090817356205852\n",
      "Food production index (2004-2006 = 100) ---- 0.4036326942482341\n",
      "GDP per capita (constant 2010 US$) ---- 0.9081735620585267\n",
      "Net flows from UN agencies US$ ---- 0.0\n",
      "Life expectancy at birth, total (years) ---- 0.4036326942482341\n",
      "Adjusted savings: education expenditure (% of GNI) ---- 1.0090817356205852\n",
      "Income_level_Final ---- 0.0\n",
      "POP_MAX_34_ADJ ---- 8.072653884964682\n",
      "POP_MAX_50_ADJ ---- 8.072653884964682\n",
      "POP_MAX_64_ADJ ---- 8.072653884964682\n",
      "TOTAL_AFFECTED ---- 0.0\n"
     ]
    }
   ],
   "source": [
    "## Check features null count\n",
    "def checkNull(col, df):\n",
    "  return(df[col].isna().sum() / len(df[col]) * 100.0)\n",
    "  \n",
    "for each in df.columns.values:\n",
    "  print('{} ---- {}'.format(each, checkNull(each, df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "5SCuBqRZFayO",
    "outputId": "66ca37a2-32df-43dd-a620-286575212187"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "## USA_SSHS Preprocessing\n",
    "\n",
    "df['MAX_USA_SSHS_INLAND'][df['MAX_USA_SSHS_INLAND'] == 'No landing'] = -7\n",
    "df['MAX_USA_SSHS_INLAND'] = df['MAX_USA_SSHS_INLAND'].astype('int')\n",
    "\n",
    "## Engineer new features\n",
    "# If value is 7\n",
    "# And if value falls in the SS scale\n",
    "\n",
    "df['MAX_SSH_7'] = np.where(df['MAX_USA_SSHS_INLAND'] == -7, 1, 0)\n",
    "df['MAX_SSH_SS'] = np.where(df['MAX_USA_SSHS_INLAND'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ykRzGYNKFx2q"
   },
   "source": [
    "# Numerical Features With NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JybfXsF-wgEe"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FE13rb25gOLR"
   },
   "outputs": [],
   "source": [
    "objects_viz = ['BASIN', 'SUB BASIN', 'NATURE', 'GENERAL_CATEGORY', \n",
    "               'Income_level_Final']\n",
    "\n",
    "\n",
    "## Bi & MultiVariate Plots\n",
    "def plotBiMulti(x, y='TOTAL_AFFECTED', scale_x=False, scale_y=False):\n",
    "  return\n",
    "  x_corr = (np.log10(df[x] + 1) if scale_x else df[x])\n",
    "  y_corr = (np.log10(df[y] + 1) if scale_y else df[y])\n",
    "\n",
    "  print(\"Correlation - \", pearsonr(x_corr, y_corr)[0])\n",
    "\n",
    "  null = geom_point()\n",
    "  for each in objects_viz:\n",
    "    print(ggplot(df, aes(x=x, y=y, fill=each))\n",
    " + geom_point(color='steelblue')\n",
    " + (scale_x_log10() if scale_x else null)\n",
    " + (scale_y_log10() if scale_y else null))\n",
    "    \n",
    "\n",
    "## Categorical\n",
    "def plotBiMulti_cat(x, y='TOTAL_AFFECTED', fill=\"#990099\"):\n",
    "  return\n",
    "\n",
    "  objects_viz_temp = [cat for cat in objects_viz if cat != x]\n",
    "\n",
    "  for each in objects_viz_temp:\n",
    "    print(ggplot(df, aes(x=x, y=y, fill=each)) + geom_bar(stat=\"identity\", \n",
    "                                                          position=\"dodge\"))\n",
    "\n",
    "    \n",
    "\n",
    "## Checks for outliers. \n",
    "def outlier_check(x):\n",
    "  upper_quartile = np.nanpercentile(x, 75)\n",
    "  lower_quartile = np.nanpercentile(x, 25)\n",
    "  IQR = 1.5 * (upper_quartile - lower_quartile)\n",
    "  q_both = [lower_quartile - IQR, upper_quartile + IQR]\n",
    "\n",
    "  outliers = np.where(x < q_both[0])[0], np.where(x > q_both[1])[0]\n",
    "\n",
    "  return({\"lower\": outliers[0], \n",
    "          \"upper\": outliers[1], \n",
    "          \"q_both\": q_both, \n",
    "          'min-max': [x.min(), x.max()]})\n",
    "\n",
    "\n",
    "### Helper Func - Clip outliers\n",
    "def clip_outliers(x, outlier_dict):\n",
    "  lower_idx = outlier_dict[\"lower\"]\n",
    "  upper_idx = outlier_dict[\"upper\"]\n",
    "  q_both = outlier_dict[\"q_both\"]\n",
    "\n",
    "  x[lower_idx] = q_both[0]\n",
    "  x[upper_idx] = q_both[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yMoIv3ICbVBC"
   },
   "source": [
    "## MAX_STORMSPEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLoJIR-5KNZ3"
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#############################################################################\n",
    "################ Numerical Features With NaNs ###############################\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "### MAX_STORMSPEED\n",
    "\n",
    "plotBiMulti('MAX_STORMSPEED', scale_x=0, scale_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gcq4ac0PbX1S"
   },
   "source": [
    "## Arable land (hectares per person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pd6jvVWcOcEO"
   },
   "outputs": [],
   "source": [
    "## Arable land (hectares per person) ---- 0.09950248756218905\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "r2OhxLLbx_6I",
    "outputId": "3349d3e6-31c5-4500-8007-6451d4be5a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([  6,  28,  35,  42,  61,  92,  97, 139, 166, 172, 211, 220, 247,\n",
      "       257, 260, 290, 307, 309, 312, 321, 328, 334, 357, 358, 360, 365,\n",
      "       377, 379, 383, 388, 393, 406, 412, 417, 419, 453, 458, 470, 480,\n",
      "       481, 483, 496, 507, 519, 539, 545, 555, 563, 565, 566, 579, 642,\n",
      "       648, 654, 658, 660, 674, 689, 720, 737, 739, 755, 767, 777, 783,\n",
      "       830, 850, 851, 878, 894, 904, 916, 927, 932, 941, 972, 977]), 'q_both': [-0.13987619737500004, 0.39300619562500005], 'min-max': [0.004410046, 3.069372586]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('Arable land (hectares per person)', scale_x=True, scale_y=True)\n",
    "print(outlier_check(df['Arable land (hectares per person)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bU5ug1zby5Y"
   },
   "source": [
    "## Food production index (2004-2006 = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wg6T9h0xUn-X"
   },
   "outputs": [],
   "source": [
    "## Food production index (2004-2006 = 100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "aYY0J5Zb10d5",
    "outputId": "ae235646-225f-47c6-8b37-94c2040322ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([ 7,  9, 12, 16, 17, 20, 23, 26, 36, 39]), 'upper': array([965]), 'q_both': [19.474999999999987, 170.63500000000002], 'min-max': [13.36, 202.3770886]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('Food production index (2004-2006 = 100)', \n",
    "            scale_x=True, scale_y=True)\n",
    "print(outlier_check(df['Food production index (2004-2006 = 100)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nox1lQpXb5Dn"
   },
   "source": [
    "## GDP per capita (constant 2010 US$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7HtJZusUoCA"
   },
   "outputs": [],
   "source": [
    "## GDP per capita (constant 2010 US$)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "kET47xrc2xFb",
    "outputId": "2b36c14b-8da5-4173-fc63-a8bb36b010a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([ 24,  29,  35,  61,  77,  81,  86,  87,  92,  96, 116, 121, 122,\n",
      "       132, 134, 135, 139, 146, 163, 164, 166, 170, 172, 177, 191, 211,\n",
      "       219, 220, 233, 247, 248, 256, 257, 260, 277, 290, 304, 307, 309,\n",
      "       312, 317, 318, 321, 328, 333, 334, 337, 349, 357, 358, 360, 361,\n",
      "       365, 366, 368, 377, 379, 383, 384, 388, 393, 394, 404, 412, 417,\n",
      "       419, 427, 429, 438, 446, 447, 453, 456, 458, 470, 475, 478, 480,\n",
      "       481, 483, 492, 496, 499, 501, 502, 505, 506, 507, 508, 515, 518,\n",
      "       519, 520, 521, 522, 538, 539, 542, 545, 555, 556, 563, 565, 566,\n",
      "       579, 581, 596, 604, 609, 614, 642, 648, 654, 656, 658, 660, 661,\n",
      "       662, 674, 688, 689, 695, 709, 720, 726, 734, 736, 737, 738, 739,\n",
      "       740, 755, 767, 768, 769, 770, 777, 783, 800, 802, 807, 812, 824,\n",
      "       829, 830, 839, 840, 850, 851, 855, 861, 865, 867, 878, 892, 893,\n",
      "       894, 898, 901, 904, 916, 925, 927, 928, 932, 935, 939, 941, 945,\n",
      "       971, 972, 974, 975, 977]), 'q_both': [-9845.485122749998, 20177.00074325], 'min-max': [141.2763632, 86150.46221]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('GDP per capita (constant 2010 US$)', \n",
    "            scale_x=True, scale_y=True)\n",
    "print(outlier_check(df['GDP per capita (constant 2010 US$)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6m2hmkhajFEY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvGgbuo1cCAC"
   },
   "source": [
    "## Life expectancy at birth, total (years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3qyDQlCjf56"
   },
   "outputs": [],
   "source": [
    "### Life expectancy at birth, total (years)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "D_VzBOiG7eX8",
    "outputId": "35655a3f-1fed-4793-9eb8-41a80548df2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([  5,   7,   9,  12,  15,  16,  17,  20,  23,  26,  31,  33,  38,\n",
      "        41,  42,  43,  44,  53,  76,  84, 101, 102, 107, 114, 128, 140,\n",
      "       150, 154, 173, 197, 202, 228, 237, 326, 392, 464, 465, 593, 630,\n",
      "       675]), 'upper': array([], dtype=int64), 'q_both': [53.64792682499997, 87.95124390500003], 'min-max': [41.762, 84.0997561]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('Life expectancy at birth, total (years)', \n",
    "            scale_x=False, scale_y=True)\n",
    "print(outlier_check(df['Life expectancy at birth, total (years)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nEAeAICjcHKX"
   },
   "source": [
    "## POP_MAX_34_ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xBxhvYREjf-k"
   },
   "outputs": [],
   "source": [
    "## POP_MAX_34_ADJ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "NAkW4RTn9KLL",
    "outputId": "96b698d1-1328-4e11-e7a8-ce4d3effc860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([ 34,  36,  58, 176, 200, 221, 259, 278, 288, 293, 300, 315, 331,\n",
      "       347, 380, 381, 385, 397, 402, 403, 419, 427, 429, 447, 450, 472,\n",
      "       475, 477, 495, 504, 519, 522, 536, 537, 543, 570, 574, 575, 577,\n",
      "       596, 598, 603, 604, 619, 631, 638, 643, 658, 665, 681, 687, 695,\n",
      "       711, 713, 729, 737, 740, 756, 759, 760, 770, 777, 793, 798, 802,\n",
      "       805, 809, 823, 824, 839, 840, 841, 860, 862, 864, 881, 897, 900,\n",
      "       908, 920, 929, 932, 935, 945, 961, 966, 970, 971, 972, 974]), 'q_both': [-41609129.53625001, 77542042.32975], 'min-max': [0.0, 376497216.0]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('POP_MAX_34_ADJ', \n",
    "            scale_x=True, scale_y=True)\n",
    "print(outlier_check(df['POP_MAX_34_ADJ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oWAq2C-AcKqh"
   },
   "source": [
    "## POP_MAX_50_ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kYseatlP-kMp"
   },
   "outputs": [],
   "source": [
    "### POP_MAX_50_ADJ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "rKlcu6Vt95sZ",
    "outputId": "e4de4556-674a-469e-e8c9-c23d00d8538b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([ 39, 122, 132, 135, 145, 163, 176, 177, 200, 233, 242, 248, 288,\n",
      "       293, 300, 315, 317, 323, 331, 347, 361, 367, 370, 380, 381, 385,\n",
      "       394, 397, 413, 421, 447, 449, 472, 475, 477, 495, 504, 521, 522,\n",
      "       527, 537, 538, 541, 543, 569, 570, 577, 596, 598, 604, 619, 638,\n",
      "       639, 643, 658, 660, 665, 681, 687, 695, 713, 737, 740, 756, 760,\n",
      "       770, 777, 793, 797, 798, 802, 805, 812, 823, 838, 839, 840, 841,\n",
      "       855, 860, 862, 864, 869, 892, 897, 898, 900, 908, 935, 945]), 'q_both': [-22726869.377499994, 40697566.59449999], 'min-max': [0.0, 322276189.0]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('POP_MAX_50_ADJ', \n",
    "            scale_x=True, scale_y=True)\n",
    "print(outlier_check(df['POP_MAX_50_ADJ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QxUkt_I5cNXj"
   },
   "source": [
    "## POP_MAX_64_ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3OywRiB-r5Y"
   },
   "outputs": [],
   "source": [
    "### ### POP_MAX_64_ADJ\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "                                            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "vR1oFv5t-QBE",
    "outputId": "d19d34ac-f1ed-49c3-a52b-a4e1c0d7dbf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([ 39,  50, 108, 122, 163, 200, 221, 242, 259, 288, 289, 293, 300,\n",
      "       313, 315, 331, 347, 361, 380, 381, 385, 397, 413, 415, 421, 427,\n",
      "       429, 475, 477, 501, 504, 507, 519, 521, 522, 536, 537, 538, 543,\n",
      "       550, 569, 570, 574, 575, 577, 583, 598, 604, 619, 631, 638, 639,\n",
      "       643, 658, 660, 665, 667, 670, 681, 687, 695, 696, 703, 706, 711,\n",
      "       713, 729, 737, 740, 756, 758, 760, 770, 777, 778, 790, 793, 797,\n",
      "       798, 805, 823, 825, 829, 838, 839, 840, 841, 855, 860, 864, 869,\n",
      "       871, 882, 891, 892, 897, 898, 899, 900, 908, 925, 935, 937, 945,\n",
      "       964, 966, 971, 973, 974]), 'q_both': [-7936958.950250001, 13966258.90135], 'min-max': [0.0, 107368555.8]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('POP_MAX_64_ADJ', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['POP_MAX_64_ADJ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "snLY-g50cQJC"
   },
   "source": [
    "## Adjusted savings: education expenditure (% of GNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-o6hyMzgjf4o"
   },
   "outputs": [],
   "source": [
    "## Adjusted savings: education expenditure (% of GNI)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "IBexQm5z-bIW",
    "outputId": "2f6fd5fd-a9cf-4ea2-ba67-49dc97bbb703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([120, 219, 318, 337, 451, 457, 497, 509, 515, 533, 554, 615, 647,\n",
      "       653, 659, 672, 734, 766, 776, 858, 903, 931, 939, 959, 976]), 'q_both': [-1.8457142855, 7.9828571425], 'min-max': [0.538880795, 14.01]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('Adjusted savings: education expenditure (% of GNI)', \n",
    "            scale_x=True, scale_y=True)\n",
    "print(outlier_check(df['Adjusted savings: education expenditure (% of GNI)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFKVknRRcTgV"
   },
   "source": [
    "## Cereal yield (kg per hectare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rm1SkrYujftx"
   },
   "outputs": [],
   "source": [
    "### Cereal yield (kg per hectare)\n",
    "                                            \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "myJLlCVj-uyU",
    "outputId": "ee16525d-6782-495c-e0fe-ee40a8fdeffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([], dtype=int64), 'q_both': [-2268.0999999999995, 9272.699999999999], 'min-max': [393.3, 8900.0]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plotBiMulti('Cereal yield (kg per hectare)', \n",
    "            scale_x=0, scale_y=True)\n",
    "print(outlier_check(df['Cereal yield (kg per hectare)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "24JFzYjFrMao",
    "outputId": "08c4b682-485b-47dd-dc8e-2d1ca7878d57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf['CROPL'] = SimpleImputer(missing_values=np.nan, \\n                                            strategy='median').fit_transform(\\n    np.array(df['CROPL']).reshape(-1, 1))\\n\\n##                                \\n                                            \\ndf['FOREST'] = SimpleImputer(missing_values=np.nan, \\n                                            strategy='median').fit_transform(\\n    np.array(df['FOREST']).reshape(-1, 1))\\n                                            \\n ##                                \\n                                            \\ndf['GRSL'] = SimpleImputer(missing_values=np.nan, \\n                                            strategy='median').fit_transform(\\n    np.array(df['GRSL']).reshape(-1, 1))\\n                                            \\n ##                                \\n                                            \\ndf['SHRUBL'] = SimpleImputer(missing_values=np.nan, \\n                                            strategy='median').fit_transform(\\n    np.array(df['SHRUBL']).reshape(-1, 1))\\n                                            \\n ##                                \\n                                            \\ndf['SPARSE_VEGETATION'] = SimpleImputer(missing_values=np.nan, \\n                                            strategy='median').fit_transform(\\n    np.array(df['SPARSE_VEGETATION']).reshape(-1, 1))\\n                                            \\n ##                                \\n                                            \\ndf['WATER'] = SimpleImputer(missing_values=np.nan, \\n                                            strategy='median').fit_transform(\\n    np.array(df['WATER']).reshape(-1, 1))\\n                                            \\n ##                                \\n                                            \\ndf['CROPL'] = SimpleImputer(missing_values=np.nan, \\n                                            strategy='median').fit_transform(\\n    np.array(df['CROPL']).reshape(-1, 1))\\n                                            \\n ##                                \\n                                            \\ndf['WETL'] = SimpleImputer(missing_values=np.nan, \\n                                            strategy='median').fit_transform(\\n    np.array(df['WETL']).reshape(-1, 1))\\n                                             \\n##                                \\n                                            \\ndf['URBAN'] = SimpleImputer(missing_values=np.nan, \\n                                            strategy='median').fit_transform(\\n    np.array(df['URBAN']).reshape(-1, 1))\\n                                            \\n\""
      ]
     },
     "execution_count": 275,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "df['CROPL'] = SimpleImputer(missing_values=np.nan, \n",
    "                                            strategy='median').fit_transform(\n",
    "    np.array(df['CROPL']).reshape(-1, 1))\n",
    "\n",
    "##                                \n",
    "                                            \n",
    "df['FOREST'] = SimpleImputer(missing_values=np.nan, \n",
    "                                            strategy='median').fit_transform(\n",
    "    np.array(df['FOREST']).reshape(-1, 1))\n",
    "                                            \n",
    " ##                                \n",
    "                                            \n",
    "df['GRSL'] = SimpleImputer(missing_values=np.nan, \n",
    "                                            strategy='median').fit_transform(\n",
    "    np.array(df['GRSL']).reshape(-1, 1))\n",
    "                                            \n",
    " ##                                \n",
    "                                            \n",
    "df['SHRUBL'] = SimpleImputer(missing_values=np.nan, \n",
    "                                            strategy='median').fit_transform(\n",
    "    np.array(df['SHRUBL']).reshape(-1, 1))\n",
    "                                            \n",
    " ##                                \n",
    "                                            \n",
    "df['SPARSE_VEGETATION'] = SimpleImputer(missing_values=np.nan, \n",
    "                                            strategy='median').fit_transform(\n",
    "    np.array(df['SPARSE_VEGETATION']).reshape(-1, 1))\n",
    "                                            \n",
    " ##                                \n",
    "                                            \n",
    "df['WATER'] = SimpleImputer(missing_values=np.nan, \n",
    "                                            strategy='median').fit_transform(\n",
    "    np.array(df['WATER']).reshape(-1, 1))\n",
    "                                            \n",
    " ##                                \n",
    "                                            \n",
    "df['CROPL'] = SimpleImputer(missing_values=np.nan, \n",
    "                                            strategy='median').fit_transform(\n",
    "    np.array(df['CROPL']).reshape(-1, 1))\n",
    "                                            \n",
    " ##                                \n",
    "                                            \n",
    "df['WETL'] = SimpleImputer(missing_values=np.nan, \n",
    "                                            strategy='median').fit_transform(\n",
    "    np.array(df['WETL']).reshape(-1, 1))\n",
    "                                             \n",
    "##                                \n",
    "                                            \n",
    "df['URBAN'] = SimpleImputer(missing_values=np.nan, \n",
    "                                            strategy='median').fit_transform(\n",
    "    np.array(df['URBAN']).reshape(-1, 1))\n",
    "                                            \n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98ZFCMwkF3do"
   },
   "source": [
    "# Numerical Features Without NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfcMzHUQPJRq"
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#############################################################################\n",
    "################ Numerical Features Without NaNs ############################\n",
    "#############################################################################\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJI9mM-bcV6e"
   },
   "source": [
    "## TOTAL_HOURS_EVENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTzvSlq_PJY8"
   },
   "outputs": [],
   "source": [
    "## TOTAL_HOURS_EVENT\n",
    "## Further investigate - may be outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BJofvPAP_Oje"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-MtpnancYWz"
   },
   "source": [
    "## TOTAL_HOURS_IN_LAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cebfq-7NPJWR"
   },
   "outputs": [],
   "source": [
    "## TOTAL_HOURS_IN_LAND\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "lbJkDJPL_yYR",
    "outputId": "485d6ede-d853-42ce-adaa-66963c47f5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([  6,  36,  38,  45,  58,  79, 128, 133, 152, 154, 172, 204, 257,\n",
      "       259, 268, 290, 293, 300, 307, 312, 331, 347, 351, 365, 379, 380,\n",
      "       390, 411, 417, 419, 482, 487, 495, 504, 507, 519, 537, 539, 551,\n",
      "       566, 570, 574, 579, 598, 621, 641, 642, 643, 648, 654, 672, 674,\n",
      "       675, 690, 694, 704, 714, 720, 721, 752, 760, 767, 783, 797, 803,\n",
      "       850, 878, 894, 927, 932, 953, 958, 960, 966, 967, 968, 970, 972]), 'q_both': [-36.0, 60.0], 'min-max': [0.0, 333.0]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('TOTAL_HOURS_IN_LAND', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['TOTAL_HOURS_IN_LAND']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vdeRgSFYcaVS"
   },
   "source": [
    "## MONTH_START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fN1NQuLp3bfV"
   },
   "outputs": [],
   "source": [
    "### MONTH_START\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "WpyAUAEVAGQG",
    "outputId": "32b056c2-800c-49d5-9d40-39950e1e7ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([ 38,  41,  44,  52,  53,  61,  73,  74,  75,  84, 103, 119, 120,\n",
      "       140, 141, 150, 151, 152, 153, 160, 161, 172, 186, 196, 197, 198,\n",
      "       209, 210, 237, 252, 286, 309, 326, 327, 343, 377, 388, 389, 390,\n",
      "       442, 443, 444, 461, 462, 463, 465, 487, 488, 528, 563, 564, 593,\n",
      "       626, 627, 628, 674, 719, 720, 721, 748, 749, 750, 751, 752, 783,\n",
      "       784, 785, 786, 818, 819, 820, 847, 848, 849, 850, 851, 879, 914,\n",
      "       951, 952, 953, 985]), 'upper': array([], dtype=int64), 'q_both': [2.5, 14.5], 'min-max': [1, 12]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('MONTH_START', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['MONTH_START']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1PiS80_ccEY"
   },
   "source": [
    "## MONTH_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu4OLGRYB4re"
   },
   "outputs": [],
   "source": [
    "### MONTH_END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LP-fMLEHAjLV",
    "outputId": "a02b4c1d-37a2-49fe-b02a-939a166f9576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plotBiMulti('MONTH_END', \\n            scale_x=0, scale_y=1)\\nprint(outlier_check(df['MONTH_END']))\""
      ]
     },
     "execution_count": 283,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plotBiMulti('MONTH_END', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['MONTH_END']))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxcX-LkXCKuy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdwLD5U8cdqb"
   },
   "source": [
    "## MAX_WIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D48zD1HJRddu"
   },
   "outputs": [],
   "source": [
    "### MAX_WIND\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "164d-VMXAxyw",
    "outputId": "77d1fea5-5d52-48a0-9696-d17a0e5e7e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([], dtype=int64), 'q_both': [-22.5, 197.5], 'min-max': [0.0, 185.0]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('MAX_WIND', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['MAX_WIND']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9juZ7iDPcf0C"
   },
   "source": [
    "## MIN_PRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HUD9mHyCWv0"
   },
   "outputs": [],
   "source": [
    "### MIN_PRES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "d3ThixFAA_yL",
    "outputId": "8039f806-e6e0-4ea4-9d57-96e15019f54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([  2,   5,  15,  35,  38,  41,  43,  44,  53,  61,  64,  75,  76,\n",
      "        84, 136, 139, 148, 377, 388, 749, 873]), 'upper': array([], dtype=int64), 'q_both': [872.5, 1044.5], 'min-max': [0, 1013]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('MIN_PRES', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['MIN_PRES']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gC5IzJAch6S"
   },
   "source": [
    "## MIN_DIST2LAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xquluy2NRdbl"
   },
   "outputs": [],
   "source": [
    "### MIN_DIST2LAND\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "YkQvuINGBZNV",
    "outputId": "40eb2d88-d825-4b26-c378-6eb2e51e25c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([ 24,  27,  29,  31,  35,  42,  48,  57,  61,  65,  68,  70,  86,\n",
      "        92, 103, 104, 114, 115, 120, 121, 123, 124, 130, 131, 139, 140,\n",
      "       141, 142, 144, 149, 153, 161, 162, 167, 170, 177, 179, 180, 186,\n",
      "       192, 193, 196, 198, 199, 202, 209, 210, 218, 219, 222, 223, 230,\n",
      "       231, 236, 241, 256, 260, 263, 265, 266, 267, 271, 276, 286, 291,\n",
      "       294, 298, 299, 302, 310, 314, 316, 317, 318, 329, 335, 338, 341,\n",
      "       344, 345, 369, 371, 372, 376, 377, 378, 389, 394, 395, 401, 402,\n",
      "       404, 414, 418, 420, 423, 443, 444, 448, 454, 455, 456, 461, 467,\n",
      "       469, 478, 483, 484, 492, 493, 498, 500, 502, 503, 505, 506, 509,\n",
      "       510, 511, 512, 513, 517, 518, 523, 524, 531, 532, 534, 546, 552,\n",
      "       554, 556, 560, 572, 578, 585, 594, 599, 600, 601, 602, 617, 620,\n",
      "       623, 635, 644, 646, 650, 655, 656, 657, 661, 664, 676, 684, 688,\n",
      "       699, 708, 710, 718, 719, 723, 727, 730, 731, 735, 736, 750, 764,\n",
      "       768, 771, 774, 779, 781, 784, 788, 804, 807, 812, 818, 819, 822,\n",
      "       828, 832, 833, 849, 852, 854, 858, 865, 866, 875, 880, 883, 886,\n",
      "       896, 901, 909, 911, 917, 919, 922, 928, 930, 931, 940, 943, 948,\n",
      "       950, 952, 955, 956, 959, 963, 976, 986, 987, 988]), 'q_both': [0.0, 0.0], 'min-max': [0, 199]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('MIN_DIST2LAND', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['MIN_DIST2LAND']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wh2XrBcTwy6z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DkL8UlrvckXN"
   },
   "source": [
    "## MAX_STORMSPEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "di6VJmqRRdZL"
   },
   "outputs": [],
   "source": [
    "### MAX_STORMSPEED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "4yDvfAPSBq2w",
    "outputId": "6efe93d6-44e8-414f-e22d-fcee866c87d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([983]), 'upper': array([  8,  21,  25,  27,  34,  75,  92, 116, 121, 122, 123, 135, 146,\n",
      "       160, 163, 164, 177, 191, 220, 233, 236, 248, 259, 261, 265, 266,\n",
      "       288, 293, 307, 317, 321, 328, 349, 361, 366, 368, 379, 384, 447,\n",
      "       453, 461, 463, 475, 478, 480, 483, 485, 492, 499, 501, 508, 521,\n",
      "       522, 542, 555, 556, 569, 570, 658, 660, 689, 740, 770, 802, 812,\n",
      "       824, 839, 840, 855, 880, 892, 893, 916, 935, 941, 945, 971, 974,\n",
      "       975, 977]), 'q_both': [1.0, 33.0], 'min-max': [0.0, 69.0]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('MAX_STORMSPEED', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['MAX_STORMSPEED']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxNd7y3lcmKN"
   },
   "source": [
    "## V_LAND_KN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ajrM1k68RdXT",
    "outputId": "a8c48c94-4a8f-4446-c2f7-f76acbac8ca3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/plotnine/stats/stat_bin.py:93: PlotnineWarning: 'stat_bin()' using 'bins = 68'. Pick better value with 'binwidth'.\n",
      "  warn(msg.format(params['bins']), PlotnineWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (8754638804758)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/plotnine/stats/stat_bin.py:93: PlotnineWarning: 'stat_bin()' using 'bins = 15'. Pick better value with 'binwidth'.\n",
      "  warn(msg.format(params['bins']), PlotnineWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (-9223363282204241194)>\n"
     ]
    }
   ],
   "source": [
    "### V_LAND_KN\n",
    "print(ggplot(df, aes(x='V_LAND_KN'))\n",
    " + geom_histogram(fill='darkred')\n",
    " + scale_x_log10())\n",
    "\n",
    "df['V_LAND_KN'] = SimpleImputer(missing_values=110691.0, \n",
    "                                                        strategy='median').fit_transform(np.array(\n",
    "    df['V_LAND_KN']).reshape(-1, 1))                   \n",
    "\n",
    "print(ggplot(df, aes(x='V_LAND_KN'))\n",
    " + geom_histogram(fill='darkred')\n",
    " + scale_x_log10())   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "35k491E8B_iS",
    "outputId": "2b8fa749-83be-4286-90b3-86f8793460f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([], dtype=int64), 'q_both': [-16.124999999999986, 194.075], 'min-max': [30.0, 171.8]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('V_LAND_KN', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['V_LAND_KN']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "25qJsR6Pcnnr"
   },
   "source": [
    "## MAX_USA_SSHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "colab_type": "code",
    "id": "twResU63HKKZ",
    "outputId": "537f0229-3b2a-47b9-dbc6-ac6bee56df42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/plotnine/stats/stat_bin.py:93: PlotnineWarning: 'stat_bin()' using 'bins = 14'. Pick better value with 'binwidth'.\n",
      "  warn(msg.format(params['bins']), PlotnineWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (-9223363282215971012)>\n"
     ]
    }
   ],
   "source": [
    "### MAX_USA_SSHS\n",
    "print(ggplot(df, aes(x='MAX_USA_SSHS'))\n",
    " + geom_histogram(fill='darkred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2GDaZw9MHbh3",
    "outputId": "15816668-31ab-4940-a84a-ef4ccd5035c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([], dtype=int64), 'q_both': [-6.0, 10.0], 'min-max': [-6, 5]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('MAX_USA_SSHS', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['MAX_USA_SSHS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVDGa0IwcpvN"
   },
   "source": [
    "## POP_DEN_SQ_KM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "LxuiL1TIRdT-",
    "outputId": "e68a1240-839c-41ea-bc23-fcf2345d230a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (8754639169877)>\n"
     ]
    }
   ],
   "source": [
    "### POP_DEN_SQ_KM\n",
    "\n",
    "\n",
    "print(ggplot(df, aes(x='POP_DEN_SQ_KM'))\n",
    " + geom_histogram(fill='darkred', binwidth=0.1)\n",
    " + scale_x_log10())\n",
    "\n",
    "df['POP_DEN_SQ_KM'] = np.log10(df['POP_DEN_SQ_KM'] + 1)\n",
    "\n",
    "df[\"pop_break\"] = np.where(df['POP_DEN_SQ_KM'].between(1, 2), 1, 0)\n",
    "df[\"pop_break_two\"] = np.where(df['POP_DEN_SQ_KM'].between(2, 3), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4plLe-W0C8nQ",
    "outputId": "d7d1eff9-5449-4846-ad88-d4212e2bae22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([ 61,  92, 172, 211, 309, 328, 377, 379, 388, 393, 417]), 'upper': array([], dtype=int64), 'q_both': [0.548792780081591, 3.6478786143215736], 'min-max': [0.44404479591807633, 3.104145550554008]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('POP_DEN_SQ_KM', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['POP_DEN_SQ_KM']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fC4e8wQzcsz3"
   },
   "source": [
    "## RURAL_POP(%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dS-D3MqMRdRV"
   },
   "outputs": [],
   "source": [
    "### RURAL_POP(%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "7Mf6W4W3DEgS",
    "outputId": "66541532-cb48-499a-c223-1d89faf2a6f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([], dtype=int64), 'upper': array([], dtype=int64), 'q_both': [-36.925000000000004, 126.47500000000001], 'min-max': [0.0, 92.4]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('RURAL_POP(%)', \n",
    "            scale_x=1, scale_y=1)\n",
    "print(outlier_check(df['RURAL_POP(%)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36YyLGv2cvQE"
   },
   "source": [
    "## DISTANCE_TRACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxCbp8HNRdO8"
   },
   "outputs": [],
   "source": [
    "### DISTANCE_TRACK\n",
    "\n",
    "\n",
    "#df['DISTANCE_TRACK'] = np.log10(df['DISTANCE_TRACK'] + 1)\n",
    "\n",
    "df = df.drop(columns=['DISTANCE_TRACK'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZnQXHNjYDTS3"
   },
   "outputs": [],
   "source": [
    "#plotBiMulti('DISTANCE_TRACK', \n",
    "            #scale_x=1, scale_y=1)\n",
    "#print(outlier_check(df['DISTANCE_TRACK']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BB4UN4hKcw3u"
   },
   "source": [
    "## DISTANCE_TRACK_VINCENTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlbHERzzJIsc"
   },
   "outputs": [],
   "source": [
    "## DISTANCE_TRACK_VINCENTY\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['DISTANCE_TRACK_VINCENTY'] = np.log(df['DISTANCE_TRACK_VINCENTY'] + 1)\n",
    "\n",
    "df = df.drop(columns=['DISTANCE_TRACK_VINCENTY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTy-b8wSDgfL"
   },
   "outputs": [],
   "source": [
    "#plotBiMulti('DISTANCE_TRACK_VINCENTY', \n",
    "            #scale_x=0, scale_y=1)\n",
    "#print(outlier_check(df['DISTANCE_TRACK_VINCENTY']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eu98cv3Vcyav"
   },
   "source": [
    "## HDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Na1GouWwJiAK"
   },
   "outputs": [],
   "source": [
    "## HDI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "p75weXHGDsrh",
    "outputId": "c20a6626-551d-42bc-ab2f-bf5f98fbfb8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': array([101, 150, 197, 326, 392, 465, 986, 989]), 'upper': array([], dtype=int64), 'q_both': [0.3439999999999999, 1.0], 'min-max': [0.217, 0.937]}\n"
     ]
    }
   ],
   "source": [
    "plotBiMulti('HDI', \n",
    "            scale_x=0, scale_y=1)\n",
    "print(outlier_check(df['HDI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-exMMd4jgwCM"
   },
   "outputs": [],
   "source": [
    "### Inpute features in bulk\n",
    "\n",
    "df[\"MAX_STORMSPEED\"]= df[\"MAX_STORMSPEED\"].replace(0, np.nan) \n",
    "df[\"MIN_PRES\"]= df[\"MIN_PRES\"].replace(0, np.nan) \n",
    "\n",
    "\n",
    "df[\"RURAL_POP(%)\"]= df[\"RURAL_POP(%)\"].replace(0, np.nan) \n",
    "df[\"RURAL_POP(%)\"]= df[\"RURAL_POP(%)\"].replace(0.8, np.nan) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "median_cols = ['MAX_STORMSPEED', \n",
    "'Arable land (hectares per person)', \n",
    "'Food production index (2004-2006 = 100)', \n",
    "'GDP per capita (constant 2010 US$)', \n",
    "'Life expectancy at birth, total (years)',\n",
    "'Adjusted savings: education expenditure (% of GNI)',\n",
    "'Cereal yield (kg per hectare)',\n",
    "'MIN_PRES',\n",
    "'RURAL_POP(%)',\n",
    "'Arable land (hectares per person)', \n",
    "'POP_MAX_34_ADJ', \n",
    "'POP_MAX_50_ADJ', \n",
    "'POP_MAX_64_ADJ']\n",
    "\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, \n",
    "                               strategy='median').fit(df[median_cols])\n",
    "\n",
    "df[median_cols] = median_imputer.transform(df[median_cols])\n",
    "\n",
    "\n",
    "df['Expectancy_break'] = np.where(\n",
    "    df['Life expectancy at birth, total (years)'] > 67, 1, 0)\n",
    "\n",
    "\n",
    "df[\"cereal_break\"] = np.where(df['Cereal yield (kg per hectare)'].between(2500, 5000), 1, 0)\n",
    "df[\"cereal_break_two\"] = np.where(df['Cereal yield (kg per hectare)'] > 3650.0, 1, 0)\n",
    "\n",
    "\n",
    "df[\"rural_break\"] = np.where(df['RURAL_POP(%)'] < 37.5, 1, 0)\n",
    "df[\"rural_break_two\"] = np.where(df['RURAL_POP(%)'].between(37.5, 62.5), 1, 0)\n",
    "df[\"rural_break_three\"] = np.where(df['RURAL_POP(%)'] > 62.5, 1, 0)\n",
    "\n",
    "\n",
    "df[\"rural_break_four\"] = np.where(df['RURAL_POP(%)'] > 37.5, 1, 0)\n",
    "\n",
    "\n",
    "df['dis2land_bin'] = np.where(df['MIN_DIST2LAND'] == 0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HV2DZqU0_ZzP"
   },
   "outputs": [],
   "source": [
    "# Dump Median imputer\n",
    "pickle.dump(median_imputer, open(\"median.imp\", 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aEijYmLajohd"
   },
   "outputs": [],
   "source": [
    "'''log_cols = ['TOTAL_HOURS_EVENT', 'TOTAL_HOURS_IN_LAND', \n",
    "            'POP_DEN_SQ_KM', 'Arable land (hectares per person)']\n",
    "\n",
    "for each in log_cols:\n",
    "  df[each] = np.log(df[each] + 1)'''\n",
    "\n",
    "\n",
    "df[\"pop_break\"] = np.where(df['POP_DEN_SQ_KM'].between(1, 2), 1, 0)\n",
    "df[\"pop_break_two\"] = np.where(df['POP_DEN_SQ_KM'].between(2, 3), 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W76NdlwHF6hM"
   },
   "source": [
    "# Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AncOy5dRdMG"
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "#############################################################################\n",
    "################ Categorical Variables ######################################\n",
    "#############################################################################\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8WgHTjDc0Sz"
   },
   "source": [
    "## GENERAL_CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1EcnAe6pKo6l"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plotBiMulti_cat('GENERAL_CATEGORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmbJCAwXxp9V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUR9VJ9ryBVb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLjEv81pc62y"
   },
   "source": [
    "## NATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uk6yu8_BKfG-"
   },
   "outputs": [],
   "source": [
    "#### NATURE\n",
    "\n",
    "\n",
    "plotBiMulti_cat('NATURE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSNOQh-byufB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5llsQHJVc8ks"
   },
   "source": [
    "## MAX_USA_SSHS_INLAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4QHDo5ERdJX"
   },
   "outputs": [],
   "source": [
    "### MAX_USA_SSHS_INLAND\n",
    "df['MAX_USA_SSHS_INLAND'] = df['MAX_USA_SSHS_INLAND'].astype('object')\n",
    "\n",
    "## Get Frequency Mapping\n",
    "MAX_SSHS_dict = {x: df['MAX_USA_SSHS_INLAND'].value_counts()[x] \n",
    "                 for x in df['MAX_USA_SSHS_INLAND'].value_counts().index}\n",
    "\n",
    "df['SSH_Freq'] = df['MAX_USA_SSHS_INLAND'].map(MAX_SSHS_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "OiFh1p4y9GMX",
    "outputId": "c7deeb4f-1431-4020-ede9-4bc81785efc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-7: 218,\n",
       " -6: 1,\n",
       " -5: 2,\n",
       " -4: 8,\n",
       " -3: 7,\n",
       " -2: 2,\n",
       " -1: 97,\n",
       " 0: 272,\n",
       " 1: 161,\n",
       " 2: 91,\n",
       " 3: 80,\n",
       " 4: 43,\n",
       " 5: 9}"
      ]
     },
     "execution_count": 313,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SSHS_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFd8JsXN7qAE"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plotBiMulti_cat('MAX_USA_SSHS_INLAND')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Za2m5Vxc-Mo"
   },
   "source": [
    "## BASIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpJedkTa7kfs"
   },
   "outputs": [],
   "source": [
    "### BASIN\n",
    "\n",
    "plotBiMulti_cat('BASIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwhlL8-uy_6B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Ahun_ezdAJv"
   },
   "source": [
    "## SUB BASIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iu4GlCJtAHyx"
   },
   "outputs": [],
   "source": [
    "### SUB BASIN\n",
    "\n",
    "plotBiMulti_cat('SUB BASIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5a5-u4OzgLg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdm_Z6HedDPJ"
   },
   "source": [
    "## Income_level_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdZSr693AH5t"
   },
   "outputs": [],
   "source": [
    "# Income_level_Final\n",
    "\n",
    "\n",
    "\n",
    "plotBiMulti_cat('Income_level_Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMnLYTygkXnJ"
   },
   "outputs": [],
   "source": [
    "### Final Trans\n",
    "\n",
    "\n",
    "df['NEW_GEN_CAT'] = np.where(df['GENERAL_CATEGORY'] == 'Cat 1', 1, 0)\n",
    "df['NEW_GEN_CAT'] = np.where(df['GENERAL_CATEGORY'] == 'TS', 2, 0)\n",
    "df['NEW_GEN_CAT'] = df['NEW_GEN_CAT'].astype('object')\n",
    "\n",
    "\n",
    "df['NEW_NATURE'] = np.where(df['NATURE'] == 'TS', 1, 0)\n",
    "df['NEW_NATURE'] = np.where(df['NATURE'] == 'ET', 1, 0)\n",
    "\n",
    "\n",
    "df['NEW_BASIN'] = np.where(df['BASIN'] == 'SP', 1, 0)\n",
    "df['NEW_BASIN'] = np.where(df['BASIN'] == 'WP', 2, 0)\n",
    "df['NEW_BASIN'] = df['NEW_BASIN'].astype('object')\n",
    "\n",
    "\n",
    "df['NEW_SUB BASIN'] = np.where(df['SUB BASIN'] == 'EP', 1, 0)\n",
    "df['NEW_SUB BASIN'] = np.where(df['SUB BASIN'] == 'NAm', 2, 0)\n",
    "df['NEW_SUB BASIN'] = np.where(df['SUB BASIN'] == 'CS', 3, 0)\n",
    "df['NEW_SUB BASIN'] = df['NEW_SUB BASIN'].astype('object')\n",
    "\n",
    "\n",
    "df['NEW_Income_level_Final'] = np.where(df['Income_level_Final'] == 'Low_Middle', 1, 0)\n",
    "df['NEW_Income_level_Final'] = np.where(df['Income_level_Final'] == 'High_Middle', 2, 0)\n",
    "df['NEW_Income_level_Final'] = df['NEW_Income_level_Final'].astype('object')\n",
    "\n",
    "\n",
    "df[\"SUBGEN\"] = df['NEW_SUB BASIN'] + df['NEW_GEN_CAT']\n",
    "df[\"SUBINCOME\"] = df['NEW_SUB BASIN'] + df['NEW_Income_level_Final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msYi6R0gz15O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-e4RuwXyBikm"
   },
   "outputs": [],
   "source": [
    "# Make Categorical\n",
    "df['MONTH_START'] = df['MONTH_START'].astype(\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReN1qwZOF91H"
   },
   "source": [
    "# Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bHPIMttGdMnC"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 967
    },
    "colab_type": "code",
    "id": "xbJzG8vYBukR",
    "outputId": "a134e07a-854c-4aa3-aaa5-a5756e4a4b57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/plotnine/stats/stat_bin.py:93: PlotnineWarning: 'stat_bin()' using 'bins = 608'. Pick better value with 'binwidth'.\n",
      "  warn(msg.format(params['bins']), PlotnineWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (8754650534341)>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (-9223363282215960923)>\n"
     ]
    }
   ],
   "source": [
    "#############################################################################\n",
    "#############################################################################\n",
    "################ Target Variable ############################################\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "print(ggplot(df, aes(x='TOTAL_AFFECTED'))\n",
    " + geom_histogram(fill=\"#E69F00\"))\n",
    "\n",
    "print(ggplot(df, aes(x='TOTAL_AFFECTED'))\n",
    " + geom_histogram(fill=\"#E69F00\", binwidth=0.1)\n",
    " + scale_x_log10())\n",
    "\n",
    "df['TOTAL_AFFECTED'] = np.log10(df['TOTAL_AFFECTED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FrgKle2x0qO2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJX6PsvDuFCB"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=['Income_level_Final', 'BASIN', 'SUB BASIN', 'NATURE', 'GENERAL_CATEGORY'])\n",
    "\n",
    "#df['MAX_USA_SSHS_INLAND'] = df['MAX_USA_SSHS_INLAND'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7DMf1iblM48"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CrEByJ7oln03",
    "outputId": "c5bbbe3a-9d00-4687-fbc5-f0673a5b97d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='ignore', sparse=False)"
      ]
     },
     "execution_count": 322,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_columns = [col for col in df.columns.values if df[col].dtype == 'object']\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "enc.fit(df[object_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "P2v91X6VlM1d",
    "outputId": "ccfdabfe-e0f4-4de5-9510-050e9a96975b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MONTH_START',\n",
       " 'MAX_USA_SSHS_INLAND',\n",
       " 'NEW_GEN_CAT',\n",
       " 'NEW_BASIN',\n",
       " 'NEW_SUB BASIN',\n",
       " 'NEW_Income_level_Final',\n",
       " 'SUBGEN',\n",
       " 'SUBINCOME']"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3KNS-XyI5DN"
   },
   "outputs": [],
   "source": [
    "pickle.dump(enc, open(\"enc.encoder\", 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vf9sq4flkxwT"
   },
   "outputs": [],
   "source": [
    "\n",
    "###dummies = pd.get_dummies(df[object_columns]) old way\n",
    "\n",
    "dummies = enc.transform(df[object_columns])\n",
    "dummies = pd.DataFrame(data=dummies, \n",
    "                       columns=pd.get_dummies(df[object_columns]).columns.values)\n",
    "\n",
    "df_dummies = pd.concat([df, dummies], axis=1)\n",
    "df_dummies = df_dummies.drop(columns=object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "Qii6x7s65OH9",
    "outputId": "1f248d43-c755-4684-bb28-1a739f7870a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MONTH_START_1', 'MONTH_START_2', 'MONTH_START_3', 'MONTH_START_4',\n",
       "       'MONTH_START_5', 'MONTH_START_6', 'MONTH_START_7', 'MONTH_START_8',\n",
       "       'MONTH_START_9', 'MONTH_START_10', 'MONTH_START_11',\n",
       "       'MONTH_START_12', 'MAX_USA_SSHS_INLAND_-7',\n",
       "       'MAX_USA_SSHS_INLAND_-6', 'MAX_USA_SSHS_INLAND_-5',\n",
       "       'MAX_USA_SSHS_INLAND_-4', 'MAX_USA_SSHS_INLAND_-3',\n",
       "       'MAX_USA_SSHS_INLAND_-2', 'MAX_USA_SSHS_INLAND_-1',\n",
       "       'MAX_USA_SSHS_INLAND_0', 'MAX_USA_SSHS_INLAND_1',\n",
       "       'MAX_USA_SSHS_INLAND_2', 'MAX_USA_SSHS_INLAND_3',\n",
       "       'MAX_USA_SSHS_INLAND_4', 'MAX_USA_SSHS_INLAND_5', 'NEW_GEN_CAT_0',\n",
       "       'NEW_GEN_CAT_2', 'NEW_BASIN_0', 'NEW_BASIN_2', 'NEW_SUB BASIN_0',\n",
       "       'NEW_SUB BASIN_3', 'NEW_Income_level_Final_0',\n",
       "       'NEW_Income_level_Final_2', 'SUBGEN_0', 'SUBGEN_2', 'SUBGEN_3',\n",
       "       'SUBGEN_5', 'SUBINCOME_0', 'SUBINCOME_2', 'SUBINCOME_3',\n",
       "       'SUBINCOME_5'], dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df[object_columns]).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDWrhfl5uGcf"
   },
   "outputs": [],
   "source": [
    "## Split data\n",
    "features = [x for x in df_dummies.columns.values if x != 'TOTAL_AFFECTED']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_dummies[features], df_dummies['TOTAL_AFFECTED'], \n",
    "    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaRS70uFgPyQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tZAc5yuD0ApA",
    "outputId": "ce37cdfd-d262-40b3-d449-c6ff41a432a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR',\n",
       " 'TOTAL_HOURS_IN_LAND',\n",
       " 'MAX_WIND',\n",
       " 'MIN_PRES',\n",
       " 'MIN_DIST2LAND',\n",
       " 'MAX_STORMSPEED',\n",
       " 'MAX_USA_SSHS',\n",
       " 'V_LAND_KN',\n",
       " 'POP_DEN_SQ_KM',\n",
       " 'RURAL_POP(%)',\n",
       " 'HDI',\n",
       " 'Arable land (hectares per person)',\n",
       " 'Cereal yield (kg per hectare)',\n",
       " 'Food production index (2004-2006 = 100)',\n",
       " 'GDP per capita (constant 2010 US$)',\n",
       " 'Net flows from UN agencies US$',\n",
       " 'Life expectancy at birth, total (years)',\n",
       " 'Adjusted savings: education expenditure (% of GNI)',\n",
       " 'POP_MAX_34_ADJ',\n",
       " 'POP_MAX_50_ADJ',\n",
       " 'POP_MAX_64_ADJ',\n",
       " 'MAX_SSH_7',\n",
       " 'MAX_SSH_SS',\n",
       " 'pop_break',\n",
       " 'pop_break_two',\n",
       " 'Expectancy_break',\n",
       " 'cereal_break',\n",
       " 'cereal_break_two',\n",
       " 'rural_break',\n",
       " 'rural_break_two',\n",
       " 'rural_break_three',\n",
       " 'rural_break_four',\n",
       " 'dis2land_bin',\n",
       " 'SSH_Freq',\n",
       " 'NEW_NATURE',\n",
       " 'MONTH_START_1',\n",
       " 'MONTH_START_2',\n",
       " 'MONTH_START_3',\n",
       " 'MONTH_START_4',\n",
       " 'MONTH_START_5',\n",
       " 'MONTH_START_6',\n",
       " 'MONTH_START_7',\n",
       " 'MONTH_START_8',\n",
       " 'MONTH_START_9',\n",
       " 'MONTH_START_10',\n",
       " 'MONTH_START_11',\n",
       " 'MONTH_START_12',\n",
       " 'MAX_USA_SSHS_INLAND_-7',\n",
       " 'MAX_USA_SSHS_INLAND_-6',\n",
       " 'MAX_USA_SSHS_INLAND_-5',\n",
       " 'MAX_USA_SSHS_INLAND_-4',\n",
       " 'MAX_USA_SSHS_INLAND_-3',\n",
       " 'MAX_USA_SSHS_INLAND_-2',\n",
       " 'MAX_USA_SSHS_INLAND_-1',\n",
       " 'MAX_USA_SSHS_INLAND_0',\n",
       " 'MAX_USA_SSHS_INLAND_1',\n",
       " 'MAX_USA_SSHS_INLAND_2',\n",
       " 'MAX_USA_SSHS_INLAND_3',\n",
       " 'MAX_USA_SSHS_INLAND_4',\n",
       " 'MAX_USA_SSHS_INLAND_5',\n",
       " 'NEW_GEN_CAT_0',\n",
       " 'NEW_GEN_CAT_2',\n",
       " 'NEW_BASIN_0',\n",
       " 'NEW_BASIN_2',\n",
       " 'NEW_SUB BASIN_0',\n",
       " 'NEW_SUB BASIN_3',\n",
       " 'NEW_Income_level_Final_0',\n",
       " 'NEW_Income_level_Final_2',\n",
       " 'SUBGEN_0',\n",
       " 'SUBGEN_2',\n",
       " 'SUBGEN_3',\n",
       " 'SUBGEN_5',\n",
       " 'SUBINCOME_0',\n",
       " 'SUBINCOME_2',\n",
       " 'SUBINCOME_3',\n",
       " 'SUBINCOME_5']"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "3791Lv-OgIip",
    "outputId": "ecaec7a0-55f2-4fd5-dd10-c8256c855a8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MONTH_START',\n",
       " 'MAX_USA_SSHS_INLAND',\n",
       " 'NEW_GEN_CAT',\n",
       " 'NEW_BASIN',\n",
       " 'NEW_SUB BASIN',\n",
       " 'NEW_Income_level_Final',\n",
       " 'SUBGEN',\n",
       " 'SUBINCOME']"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOAY8wZVuH8j"
   },
   "outputs": [],
   "source": [
    "# Standard scaler\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIvYuHdtxyQ9"
   },
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import RobustScaler\n",
    "# Standard scaler\n",
    "scaler = RobustScaler()\n",
    "scaled_X = scaler.fit_transform(X_train)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ND-rq5tVquhu"
   },
   "source": [
    "# Clustering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skPXQDGu1OXG"
   },
   "source": [
    "## KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "zW_LBBRtybwe",
    "outputId": "02529058-2350-4ad6-9aaf-3f9022eb5651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -- 0.0999875076262445\n",
      "3 -- 0.11360082869812246\n",
      "4 -- 0.11114451214003646\n",
      "5 -- 0.11503101905313329\n",
      "6 -- 0.0995743578675544\n",
      "7 -- 0.1054664489517942\n",
      "8 -- 0.11674950227472639\n",
      "9 -- 0.11760572556319361\n",
      "10 -- 0.12705636238961338\n"
     ]
    }
   ],
   "source": [
    "for n_cluster in range(2, 11):\n",
    "  km = KMeans(n_clusters=n_cluster, random_state=42).fit(scaled_X)\n",
    "  print('{} -- {}'.format(n_cluster, silhouette_score(scaled_X, km.labels_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "tkrU0XkOcyYx",
    "outputId": "13962d00-f44f-46a2-a8b6-169acf6b4f8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 327,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=2, random_state=42).fit(scaled_X)\n",
    "km.fit(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvtUhhV-ZsHY"
   },
   "outputs": [],
   "source": [
    "pickle.dump(km, open(\"kmeans.cluster\", 'wb')) \n",
    "pickle.dump(scaler, open(\"scale.scaler\", 'wb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBcFR9Yc1SN_"
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "id": "eQ4YGEDNrCk_",
    "outputId": "9f9ad08a-b218-4ead-bd6e-c1de274ed779"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAGvCAYAAACpcEg3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd1iT1xfA8W8SCHvvKbjAvRAcuBXFvVfVn1vr7NCqratV67ato3VUa92jKu5R98KFigMFHKCCICB7hpDfH1haNyAYkPt5nj5VefPmvFxCTu577rkSlUqlQhAEQRAEQRCEHFJ1ByAIgiAIgiAIRY1IkgVBEARBEAThFSJJFgRBEARBEIRXiCRZEARBEARBEF4hkmRBEARBEARBeIVIkgVBEARBEAThFSJJFgRBEARBEIRXiCRZEARBEARBEF6hoe4APobo6Gh1h/BB5HI5GRkZ6g5DLSQSCTo6OqSmplJS970R419yx1+MfckdexDjr6Ojg66urrpDEUowMZNcDGhpaak7BLWRSqXo6uoilZbcH1Ux/iV3/MXYl9yxBzH+IkEW1K3k/vYRBEEQBEEQhLcQSbIgCIIgCIIgvEIkyYIgCIIgCILwCpEkC4IgCIIgCMIrRJIsCIIgCIIgCK8QSbIgCIIgCIIgvEIkyYIgCIIgCILwCpEkC4IgCIIgCMIrRJIsCIIgCIIgCK8QSbIgCIIgCIIgvEIkyYIgCIIgCILwCpEkC4JQZCkUCjIyMtQdhiAIglACiSRZEIQiJzk5mWFDhmBrY4OOjg69e/YgLi5O3WEJgiAIJYhIkgVBKHLGffUVl0+cYFXTBvzZvCH3/fz4fOhQdYclCIIglCAa6g5AEAThv7Kystizdw9LG9algZ01ALPca9D94DGSkpLQ19dXc4SCIAhCSSBmkgVBKFJUKhUqFUiR5PybRCLJ+ZogCIIgfAxiJlkQhCJFJpPRtnVrZpw+jZZMiqZMyvTL/jRu0AADAwN1hycIgiCUEGImWRCEImfRL79QtX49+v19ip4Hj2NfpSorfv9d3WEJgiAIJUixnEk+f/48mzZtIjIyEkNDQwYNGkS9evXUHZYgCAVEX1+fNWv/RKFQYGxsTFpaGkqlUt1hCYIgCCVIsUuS/f39+f333xk3bhyurq4kJCSQlpam7rAEQSgE2tra6OjoiNe4IAiC8NEVuyR506ZN9OjRg4oVKwJgbGys5ogEQRAEQRCET02xSpKVSiXBwcG4u7szfPhw0tLSqFGjBoMHD0ZPTy/nuOjoaKKjo3P+LpVKsbCwUEfIBUIikSCTydQdhlr8c90l9fpBjP9//1/SiLEvuWMPYvwFQd0kqmLUUykmJoYBAwbg7OzMlClT0NbWZuHChRgbGzN27Nic41asWMGqVaty/t6/f39GjRqljpAFQRAEQRCEYqhYzSRraWkB0KZNG8zNzQHo1q0bP/7440vHdenShUaNGuX8XSqVEhsb+/ECLWB6enokJyerOwy1kMlkGBoakpCQUGIXbonxL7njL8a+5I49iPE3NDRUdxhCCVeskmR9fX3Mzc1zNhZ4G3Nz85wkGrLLL4rzL1mVSlWs4y8ISqWyxH4PxPiX3PEXY19yxx7E+AuCuhW7PsleXl7s37+f2NhYUlJS2LFjB+7u7uoOSxAEQRAEQfiEFKuZZMgur0hISGDkyJHIZDLc3NwYPHiwusMSBEEQBEEQPiHFLkmWyWQMHTqUoUOHqjsUQRAEQRAE4RNV7MotBEEQBEEQBKGwiSRZEARBEARBEF4hkmRBEARBEARBeIVIkgVBEARBEAThFSJJFgRBKAL++usvqlWqhK2NDc2bNOHOnTvqDkkQBKFEE0myIAiCmh09epSRI0bQy96KlU3qY5OcQJeOHYmKilJ3aIIgCCWWSJIFQRDUbOvmzXQoXYrhVSriaWvNkIouJCcmUMfNjf/16cPjx4/VHaIgCEKJI5JkQRAENVMoFOhoyAB4EJ9Av8Mn8LSxZoiTPbG3btDW25uYmBg1RykIglCyiCRZEARBzVq1bs2OB484GPKYVbfuUs7EiKWN6/GZa1lWNakPqSn4+PioO0xBEIQSpdjtuCcIgvCp6dGjB48fP+aLBQvIysqinbMjEokEAC2ZDGMNDSIjI9UcpSAIQskiZpIFQRDUTCKRMH78eB48eEC1atU48ugJfs+iUKlUHAx5zJ3nsWRlZX3UmGJjY9m6dSvr1q0jODj4oz63IAhCUSBmkgVBEIoIPT09Sjk4kBYaQs+Dx9GUSlGqVBjr6ODo6Jinc507d47FP/1E7PMYarl78N3kyejr6+fqsQ8ePKBT+/ZkJCehL5czKSGR5StX0q5du/xcliAIQrEkZpIFQRCKkGYtWhCanML3dWqxsIEH/3MtR0pmJvXq1cv1Oc6dO0fXLl0wCX9Ec7mUozt30Kt7dzIzM3P1+HFffklZuQYnO3rzdzsvxlStyKgRI0hMTMzvZQmCIBQ7YiZZEAShCOnVqxcP7t9n2uLFAOjr6rLy998pW7bsG49//vw5jx49wsbGBisrKwCW/vIL7Z0dmVPPHYD2zqVosnM/ly5dylWyfefOHaZWrYCWLLvjRi+XMiy4eoPQ0FAqV65cEJcpCIJQ5ImZZEEQhCJEIpEwecoUAgMDuXbtGrcCAmjduvUbj123bh2VK1WiRYsWVK5cmXnz5gEQF/scZ8N/SyusdHXQ1ZITHx+fqxgsLSzwj/635Zx/1HMALCws8ntZgiAIxY6YSRaEXFAqlWzevJnAwEBsbGzo169frus7BSE/TE1NKVWq1FtLHK5cucL4ceOYUacWbZ1L4fs0kjE//YSrqytuHnXYvnUL7Z1LYaOny9qAINIzlbmeBZ48fTp9+/QhLDkFUy05ux4+4vPhw3NmqgVBEEoCkSQLwnsolUr+17cvF8+dpZalOXtj49m0fj0HDh/G0NBQ3eEJJdTZs2epZm1J9/JlAGjmaEcLBzvOnDnD999/z62bN2iycz+6cjmKrCwWL12Kg4NDrs7dokULdvn4sGH9epJSU5k1bCR9+vQpzMsRBEEockSSLAjvceDAAc6ePs3u1s0oZWhAYoaCLoeOs2zZMiZNmqTu8IQSSltbm9j0DDKzstCQSlGpVESlp+Ooo4Ouri5/7dzFlStXiI+Pp2LFitjb2+fp/HXr1qVu3bqFFL0gCELRJ2qSP4BKpVJ3CMJHEBoaShkTY0oZGgBgINfE3dyU0NBQNUf2brdu3aKtdysqurjQsnkzrly5ou6QhALUsWNHErJUjDlzkb0PQpl8wY8b0c/p2bMnADKZDA8PD7y8vPKcIAuCIAgiSc6XkJAQ2nl7Y2drS4Xy5Vm1apW6QxIKkZOTE/eexxKSkF0bmpiRwcXo5zg5Oak3sHd4/PgxHdu1w/x5NN9VdsE5JYnOnToSFBSk7tCEAmJtbc2efftItrJhbkAw93T0+GvnTipWrKju0ARBED4Jotwij5KSkujWuTP2KiUrm9TnYXwi06dOxcDAIGcGR/i0tG7dmoaNG9Pl0HFqWVpwNzYeIysrRo4cqe7Q3mrXrl1YamuxsL47MqmU1k4OPEhMZtu2bUyePFnd4QkFxMXFhd379qk7DEEQhE+SSJLz6PLly4Q/fcru7h3Q1dTA09aasORktmzcKJLkYk6lUhEXF0dWVhampqZIJBIApFIpa9etY+vWrQQFBdHU2po+ffoU6e4WaWlpmGjJkUmzbxZJJBLMtOWkpqaqOTJB+HiUSiUSiQSpVNw0FQQh78RvjjzKzMxEQypFLvv3W6eroYEyU6HGqIQPFRcXR4+uXSlfvjyurq60b9OGZ8+e5XxdJpPRu3dvpk+fzvDhw4t0ggzg6enJlfAIdtx7SJJCwcGQx5x8HEajRo3UHZogFLqEhAQG9v8fDvb2ONjbMXrkSFJSUtQdliAIxYxIkvOoVq1a6Ojp8t0FP0ITkjjxJJy1gfdp2aatukMTPsCYUaN4cvsWO9o0Z087L1JCQxgycGCuHqtSqdi0aRPDhg7hi7Fj8fPzK+Ro369evXrMnjOHyRf8qLFpJ1+cucDESd/i5eWl7tAEodCNGD6c276+rGhcj8UN6nD60EEmjB+v7rAEQShmJKoS0KIhOjq6QM939epVBvyvH+ERkUgkEoYOGcIPM2YU2i09AwODt24o8KmTyWSYmJgQGxuLUqkslOdQKpXY29mxqqknnrbWANyMfk7n/X9z//799/ZCnjZ1Kn+s/p32Tg7EpGVwMuwpW7ZuLbBZ2w8Z/+fPn/P48WNsbW2L5W5pH2P8izLx2s/72CclJeHs7MxW72bUtDQH4NjjMMaeucijJ0+KVemFGH8TdYchlHCiJjkfatasydXr/jx79gwDA4Mif+tdeDeJRIJMKiU989834rQXb8rve0ONiIjg199+Y03zRjSwy06wZ1y6xvdTpnD89OnCCzqXTE1NMTU1VXcYgvDRZGVlAaAhleT8m1wqJUulEm07BUHIE5Ek55NMJsPGxkbdYQgFQCqV0rVrV77fvw+FKgtNqZTZ127Rxtv7vR+AIiMjAahpaZbzbzUszDh0O7BQYxYE4c0MDQ3xrFuXqZevM6N2DRRZWcy8ehPvVi2RyWTqDk8QhGJEJMmCAMyZN49vZTK+2b6dTKWSihUrMuaLL977OCcnJ7TlcrYFPWBAJRfSlUp2hzzG1bXCR4g6m0KhwNfXl/j4eKpWrUqpUqU+2nMLQlG0as0ahgwcSOf9fwPg1bw5P/2yWM1RFY7k5GR8fX1JT0+nVq1aWFtbqzskQfhkiJrkYkDUpX2cmtTAwEA6tmuHplKJgVyTh3HxLF+xgvbt27/zcTt27GDUyJE4mxiTkJ6BVEcHn717cXZ2RqlUoqHxYZ9F3zX+iYmJ9OjaFf8b/ujJtUjOyGDx0qV06dLlg56zqCjONcm3bt3izp07WFpa4unpma9ZTPHa/7CxT0hIQCqVFtuSuPeNf3h4OF06duDJkzDkGjJUUhlr162jYcOGrx2bmJjI/v37SUhIwM3NjZo1axZm6B9M1CQLRYFIkosB8Ub5cZKkNq1aYhwTzc8NPNCUSllx8w6/BgRx+86d977JBgQE4Ovri46ODl5eXmzfvp0F8+aSkJRM5QoVWLl6NeXKlctXXO8a/2/Gj+PUnj1saN4ACx0d1gYEMf/aTS5evvxJbEVcXJPkn3/6idmzZ2NlYEBMSjL169Vn/aZNaGlp5ek84rVfdMY+IiKCgwcPkpGRQcOGDalQofDvFr1v/Ht260pCYCArm9RDV0ODuX7+7HoSgf/Nm+jo6LwUe4e2bYmPjsZCT5egqGhmzJzJ0KFDC/0a8kskyUJRUHyW+QpCIQsMDKKTsyOaLxbrdS3nTEpaGmFhYe99bMWKFRk0aBC9e/fm77//Zub332PyYjOSW3fu4NWsWU79ckG6evkK3Us7YvHiDfF/FcqhKZMSEBBQ4M8l5I6fnx+zZ8/m18b1Od3Jm8MdvLlz7RpLly5Vd2iFJiUlhcjIyJxFc5+a27dv06hBA5b8OIv1v/xMs6ZN2bt3r7rD4tq16/RzKY2+piZSiYRhlSsQGx9PaGjoS8dNnzoVw/RUjnVoyV7vpizw9GDKlCmvHScIwstEkix8khITE4mOjs7TanYrK0v8ov6963DtWQwSiSTPrdO2b9mMiVyOhY42Pm292NCyCbqoGJ2HbaxVKhWbN2+mXWtvGtarx0+LFr1xNs3E1JR78f/ONIUlp5CSocDY2DhPMQsF58aNG5Q2M6WZox0A9vp6tLK3wf/aNTVHVvCysrKYMnkyTk5OVK5cmdo1a+Lv76/usArcV2PHUMfEiCPtvNjXuhljqlZg9MiRat/B0sTYmOC4hJy/34uLB3jt9R8YEEAbBzv0NDUBaOvsiJaGjODg4I8XrCAUQyJJFj4pKSkpDB08mNKlS1OhQgWaNW7Eo0ePcvXY6TNm8kdAEJ+fOMfEc5f44swFvv766zy3UIuOiiYyNZXZ9d2pZGaCh7Ul37nX4Mrly7k+x+rVqxn31VdUTU2ivkrBrz//zMQJE1477ouvv8bnQSjjz15kmf9t+hw9TSNPT2rVqpWnmIWCY2ZmRmRSEjFpaUD2B57A+ATMzM1fOi4hIYEvxozBo1ZNmjVqxI4dO9QR7gdZtmwZG//8k9+a1OdwR2+qa2vSq3t34uLi1B1agQoMCqaDsyMaL+4ydS7jTHJqKuHh4WqNa9zEiSy7EcD0C378fO0mI09foO9nn722eM/KxoZr0c9zJg3uxMaRmqEQi/wE4T1ETXIxIOoSc1+XOO7rrzm624d5dWphoqXFTD9/YvUMOH7qVK4W0F26dInNmzaRlp5O8+bN6dy5MxKJ5KVjYmJi8PPzQ1NTE3d3d/T09HK+tnbtWsa/2NnrQPtWlDMxAmD3/RBm+gcwd8EC4uPjqVmzJtWqVXtrHJUruDKktCP/q1AegLPhEQz4+xT37t3DyMjopWPPnz/PsiVLSIiNxa1OHb6ZMOGlesTiLL91qRkZGchkMrW0/EpPT6ettzcJYU9oZW/Drdh4rsbE8vexY5QtWxbI3sCmU/v2PLsXzACXMoQlJbMqIIhff/uNTp065ZyrsF/76enpbN++nfDwcMqVK0eHDh3ytNlGm5Ze1MlSMLpaJQAylEpqbd3Nnxs20LRp0w+KrSjVJNetXZum+jqMr1UVgIMhj/nizAWCg4Pfu9nQh8jN+B84cIA/16whLTWVpl5ejBo16rWfe39/f9q1bUsNMxMc9HQ5+CgM73btWLJs2Wu/34oKUZMsFAUiSS4GRJKc+zfKSq4ufFOhHB3KOAHwNDmFhn/t5cKFC5QpUybfcfj4+HDyxAniExI4e+oUGenpZGZlYW9nx/adO3F0dCQuLo6KFSowza0ay2/dRVsmY7J7DZIUmUy5eBWplhbKjHTMdXV5EPOcH2fPZtCgQW98Pgd7e5Z6etDIPrsXd1hSMo137OPq1as4ODjk+zqKm3eNf1JSEvPmzuX6VT/MzC344quvsLW1ZcSwYZw6exYNmYyePXsye86cPC+Y+1CJiYnMmzeP2zf8sbS24auvv6Z8+fI5X/f396d58+ac7toOGz1dAOb7+XNFKufwsWM5xxXmaz81NZVO7dvzMCiIcqbG3I6KoUnzZvy+5o9cJ8rtvL2pnp7M1zWzk8cURSa1t/qwqQB2nCxKSfKRI0f4X79+NLKzwVBTg30hjxk/YQJffvlloT5vQY7/3bt3Wb16NQnxcdR292DgwIFFevdBkSQLRYHokyx8UmQyDdL/84b6z58/ZEZx/vz5/LxoES0cbDnxOBzvUg7MrOdGulLJiFO+jB4xgt379hEWFoYiM5NWTo60KOXAN2cvMujoaVRA2dKlkScmsM67CQZyObsfhDDh229p1qwZTk5Orz2nW82a/H43mJqW5mhryFhyIwBbKyuxgc0LCoWCXt27Ex4cRMdS9twNuEmb1q0pW7o00ucxbPBqTKJCwVQfH7S0tJg9Z85Hjc/AwIAZM2a89etJSUnIpFIsdLRz/s1GT5fk6I9XprBy5UrCH9znQNsWmOlocz8+gS4Hj7F37146dOiQq3N0792bSRMmYKOnS2lDA1beCcLW1vaTK/fx8vJi9549bNmyhYz0dH6d+B0dO3ZUd1h54urqyvz589UdhiAUKyJJFj4p3Xr0YMHq39HR0MBYS4sF/rdxr1ULR0fHfJ0vJiaG+fPns7RRPSqZmbD/4SOs9XRYdO0mLiZGDHAty+izlwCwtbVFJpVyKuwp7UuXYlWzBkw6f4VgLR3IyqKNox0GcjkAHUo7Me3SNYKCgt6YJC/59Ve6de6Ex7bdyF70ed24ZcsH91x+m9TUVB49eoSJiQmWlpaF8hwF6cyZM1y7fo3jHVtjqauDSqVi5ClfjgcGsr9DK8oYZd8CT8pQMHvHjo+eJL+Pnp4eGlIps69c55ta1XianMIfgfdp/p9Si8J279496liYYfYiUS9jZIirmSn379/P9Tn69OlDYmIiPy9cSEJSEjWrV2Pb8hXFti/xu7i7u+Pu7q7uMARB+IhKRJIsl8s/+u3WgqShoYGBgUGBnU+hUDBr5kwO7NmDXC7nf4MHM3jw4CJZm/ZPTHp6ernqVPHj7NlIJBKm/r6KDEUmzZo0YeXq1a/V8eZWSEgIKpUKD2tL4jPS0ZRK2Hk/hPLGRmy6e4/SRgYYGxhg8OK/2XPm8M3Eiex7FEZcegaBcfEcOHSIObNmceN+ECqVColEQnBsPMnpGTg5Ob1xbCtUqMAlv6tcvHiRrKwsatSokecFhLl1/Phx+vTuzfMXi60GDxzIL0uWFIktfN82/qmpqZjo6GKpq5NzXHkjA05JJEj59+dYKpGgUqkK9PXzoWJiYujfty8uJsbsCH7IujvZHQbc3Woxf8HCl2rcC/q1/1+lS5dm85HDJCsU6GlqEpmSyr3YOEaULZun55wwYQITJkwgKyurQG/f5/W1/ykqzPEv6ori+5FQ8pSIJDkjI4OMjAx1h5FvBV2XOGbUKI7s28eQCmVJVmQy7quviIuLY/jw4QX2HCqVip07d3LhwgUMDAzo06cPpUuXzvN5ZDIZmpqaLFiwgK0bN6LKyqJ1hw58+eWXb03iJk+ZwneTJ6NSqXLetPP7/TM1NUVbLsfnQQhhScmUMjDgrzbN0dPUJDA2jo57j9BvwICc8w8YMIBSpUpx8uRJtLW1Wdq1K+XLl2fchAm0bdOGQcfP4qSvx75HT+jYvj3lypV7Z2xubm45418YtakRERH06NaNrqXsGd6yMcFx8YzcvBkbOzvGjBlT4M+XVzKZDLlcTnJy8kt1qWXLliUqKQmf+yF0LOPE0+QU9jwKw8TMjAkXrjC5VlUSMhTM979Nu46dilRN/44dO1AkJ7GpQysylEruxSWw6NotnMuWIysr66VYC7MmeeDAgWzbvIkOB49T1cSYi1HRVKpaFW9v7yLx/Xrb2JckJX09ivzFnTdBUJcSkSSXNElJSZw9e5bExETq1auHnZ1dzteeP3/O5q1b2dCyCR7W2bfVTbS0WPrLzwWaJE+dMoW1a9bQzN6W66mprF2zhr3791OpUqU8n+uHH35g/uzZDK1YHk2pJisWLyYmOvqdt9AlEkmBzEQYGhqy8KefGDN6NAZyOZ1KO+b0GnUxMcbR2AhXV9eXHtO0adPXVvZXq1aNQ4cPs2rlSmLj4viiVx+GDh2q9tmSK1euIM3KYqJbNaQSCR7WlnxWzpnjfx8pEkny27i4uDB7zhwmTpzIPP/bxKem4uZWm58XL2bMyBF02X8UiURC186dmTFzprrDfUlqaiqGWlpoyWRoyWTUsDSnlKEeaR+5566RkRGH/j7K77//Tnh4OKPKlmXgwIFovvj5FoqHuLg4Lly4kH3Hy8Oj0O44CUJJJJLkT8yTJ0/wbtmSmOhoFFlZaEqljP3qKya86LGblJQEZG9w8A97Az0Sk5Lfe+7o6GiWL1/O06dPcXV1ZejQoW8sY7l//z7LV6zIScSzVCrGnL7AD9OmsfWvv/J0PSqVioXz5zPFrRpdyjoD2bWTw9esYeq0aR+l1Vn37t1xcXHhu+++41xwEGmZmWhraHAvLoGwpORcd5uoVKkSP//ySyFHmzdaWlpkKDNJycxE/0VyFJ+egbap9nseqX4DBgzA09OTW7duYWpqSv369dHQ0GDvgYMkJSWhoaGBtnbhXEd8fDwHDhwgMTERDw+Pd7bze1XdunX5LjaOcacvEJacTFx6BiGJScwZOqJQYn0XIyMjvv7664/+vMVNRkYGq1evJiAgAEtLS4YOHYqVlZW6wyIgIIAeXbuSlJCARAI6evps2b6dKlWqqDs0QfgkFN3+L0K+DBs8mKioKPpXKMf21s0ZVtmVhQsWcP78eSB7cZm9jQ0/Xb9FulJJXHo6y28H4vGeBSlRUVG0aNqUgxvWo7x6mRU/LaJ71y4oFIrXjn3y5AkaUinuVtk71UklEupamfPkce429fgvpVJJcmrqS0m9g352jWJKSkqez5df1apVY+3ataTr6tH2wDFGnPKl++ETtGrZkmbNmuUcp1KpiIiIIDw8vFjUUdarVw9bW1uGn/TlcOgTlvrfZkvwA/r2H6Du0N7Jx8eHdt7eDB88mBv+/tSpU+elRY36+vqFliCHhYXRtFEjZnz7Let+/omWXl6sW7cu14+vUKECvXr3Zm/II6pbmNOhTCn05XKuXLpUKPF+iKysLE6cOMGmTZu4evVqoT+fSqUiLCyM0NDQIlNioVQq6dOrF4vnzSXjykWObNpIi6ZNiYiIUHdoDBs8mOr6Olzs1o6L3drjbmTAkIFF+7UrCMWJSJI/MTdv3aKiqQnja1WjuoUZY2tUoZalOVu2bAGyF4KsXb+eC/FJVNu0E/etu0kzMmHxsmXvPO+vv/6KviKDnd5NmVPfnb9aNuHmdX/27dv32rHOzs4oVSqOPAoDsjcY+DssgjLlyr927PtoaGhQ192dZbfukpiRQWpmJj/536acs/NHv61obm7O0RMn6DtyFM5erZg5dy4rV6/OKZmIjo6mfZs2VKlShWrVquHt5VUk3kjfRU9Pj792+aBbthxTrt5k7/MElixdSps2bdQd2lv99ddffD58OJVSEvHW0eSvdX8ybMiQt34oycjIYNWqVUyYMIElS5bk3E3Jr+8mTcRapeR4h5bsa92MGXVqMeGbb/I01qePH+erGlWY4FaN4VUqsrxJPbZs20ZkZOQHxVaQFAoFfXr3pm/v3iyYPg3vVq2Y+Y62dh8qNjaWTh06UL16ddzc3GjcoAGhoaGF9ny5deTIES5euMD2lk2YW9+dHa2aYI6KxYsXqzWu1NRU7gYHM7hCeeQyGZpSKYMrlud+SGiJrWMWhIImyi0+MTo6OkgkL68MlkmlL5VFVKtWDd9Ll7hx4wZyuZyqVau+t/tHeFgY1U2N0XqxWM5aTxcnYyOePn362rGOjo5MnjyZsbNmUdPGisjkFNI1NNk/a1a+rmnD5s14NWtGrS0+SABba2u2bN+slnpeY2Njxo4d+8avjRw+nISQhxxo3wqpVMJEXz+GDhrInv0HPnKUeWNvb8+2YrQl8uJFixhe2fKD5cMAACAASURBVJWx1SsDUN/WivZ7D/Lw4cPXFocqFAq6d+1C4M2buFmYcfh5HNu3bOHA4cP5blN2N+AO/UvZo/1i5rpLWWcm+17h/v37ud7mNyExEadyTjl/d3rRwSAhIUEtt/GfPHmCn58fOjo6eHp6oqury6pVq7h64QL727WklKE+559GMmjZUho3aYKnp2eBxzB29GhigoM40L4VWhoyvrtwlU7t23P0xIkCf668CAsLw97IMOdullwmo4aZMWGPH6s1Li0tLXS0tQmOi6eahRkA9+Lj0dLURFdXV62xCcKnQswkf2JGjBrFrejnLPG/TWBsHKtu3eVyZBRdu3Z96TgDAwPq169P7dq1c9Uer7yLC2cio4hJTQPgdkwsQTHPc7bZfdWYMWP4a8cOmvX9H0PHjefE6dOUKlUqX9fk5OTEyTNn2Lt3Lz67d3Pm/HlcXFzyda7ColAoOHnmDN/WrEI5EyPKGBkyxa0qvpcuU87Ziblz56o7xI9OoVAw+8cfaVC3Dk08Pfntt99emu1VqVT8+eeftPNuRZuWLfntt9/Iysp673kTEhJwNPi3/KbUfxLMV+3YsYPb/v7satWUJQ3rsrd1M5KeRbJy5cp8X5eVtTVXo57nXIt/VAxZKlWuE2QAt9purL4bTHx6BsqsLH7xv42FqWm++3l/iCNHjlCvbh2+GTuGwQP655QS+F+/TnNbK0oZZn+YqGdjhYu5OTdv3izwGFQqFcePH2dctUqUMzHC0UCfqbWrce3GDaKiogr8+fKifPnyPHwei39UDACxaemcehpF+VcW7H5sUqmUr8eNY/rl68y5cp15fv5MvnCVL776qki0bxSET4GYSf7EjB07luTkZH5dupTF12+hLZez7Ndf8fDw+KDzfv755/x96BDe+/7GydiQO1ExdO7cmRYtWrz1MZ6engU246Sjo/PB11CYpFIpMqmUpIx/a7STFJlIgN6lS7FowQKSk5P54Ycf3vh4pVLJkiVLOHJgP5qacnr360ePHj0+UvSFY8I333Bg106GVSxPhjKLubNmkpyczLhx4wBYvHgxC+bOZYBrWTSlUub/OItnz54xbdq0d57X3cODtb7naWhrg7GWnEXXbmJiaPjGD2xnz57FSU8X6xdbPxvI5VQ3NebJkyf5vq7J06bRqUMHYtLSsNHVYX/oE/r17Zunbc8X/fwL3Tp3xmPbbjRlMnR0dVm/ceNbP7CqVCq2bdvG8WNH0dLS5rM+fQrk9ZCQkMCwIUMYWL4MY6tXJkmhYNCJ80wYNw4HJycuJCSizMpCJpUSl55OeGISZmZmH/y8b6KpqUnCf1p1Jr54Lam7DViDBg3o/dlnfLZpExUtzQmNS8De2emtd5Q+pjFjxmBmZsauv7aDCmbNGULfvn3VHZYgfDIkquKwuugDRUdHqzuED5KfXplZWVnEx8djZGRUYA3+09PT8fHxyelu0bJly0IveZDJZJiYmBAbG1tkFvK8zVdffMGRPbv5pnplZBIJc/38qW1lwcIGdZh7xZ/1d4PZuHUrjRo1eu2x48eNw2fbNv7nUoZkRSbrAu8xY9YsBg4cWCx7pSYlJeHs7Mya5o1oYJc9w7o9+AHzbt4l+MEDVCoVZZydmVStIt3KZZdIHA59wtjTvoQ+epSTLL5p/GNiYujZrSv+t25nJ5ja2qxdv/61D2RBQUE0btQIObD7RclATFoaHQ8cY+iXXzF69Og8X5e/vz87duwgIiKCxIQEDA0MqFu/Pv369cvz6ywtLQ0/Pz/S09OpVq3aG5PPf8b+x1mz+HXZUjo4ORKboeD44zDWb9jwzg+pubmWZcuWsWvXLpY2rkfLUtldWnzuh/BT8EP2HTxEsyZNKKenQ00zE46GRaBtZc2Bw4cLpavM5MmT2b5+Pd/UqIy2TMaiGwG4NW7C72vWqP21r1Kp+Pvvv3O6W3Tq1OmjdNYpjq/9gvLPa18Q1EkkycWA+EVZPJLk9PR0pk6ZwtbNm0nPSKdTaSemetREW0ODNbcDWXP7LgotbW7evv3S7FhcXBzlypVjbYtG1LfNTij/CAjkj5AwbgQE5Iy/SqXK2SDl+vXrfD91KuFhTyhbvjyzZs954/bWAH5+fqz780+Sk5Jo2Lgxffv2LfQPN5GRkVSuXJlDHb1ztog+/zSSwcfP8iQsDKVSiZ2dHZtaNsHtRReU4Nh4Wu85RGBgYM6izLeNv0Kh4OrVq6SkpFC1atU3JpiLFi1iz+pVWMo18XsWTVVzM27FPEfX2JgLl6/kOck5fvw4fT77jNpWFuhqaHDicRiz58xhwIDC6yZgYGBASEgIrq6urGjagKYOtgDMueLP2TQFZy9cyNd5T506Re+ePallZYGuVMLJJ0+Z4FaNARVdmOfnj28mnDhzhpCQEBYtXEhEWBjlK1bkm2++wdDQsCAvMYdCoeDHWbPYunkzmcpMWrduw4pVq8jIyCjyr/3C8s9rPzU1lWvXrqFUKqlWrVqhjUFRIpJkoSgQ5RaCUEC0tLSYO28e3Xv0oK23N3KZjEyVijvPY/kjIJAmDrZsCXrA06dPX6rPfvbsGQC+TyNRZGXRyM6G0oaGxCXeAbLvCsyZM4eVy5eTmpZGtSpVuH3nDs3tbGhlZ8XBu3do17o1J06fxtzc/KWYzpw5Q4/u3Wlka42FthZTjxwm4PZtZsycWaibRlhaWlLGqRSLrt9mfr3apCuVLL15B4/atZFKpUilUqpWqsSKgCAqmZkgk0hYdusOzo6OuXpj1NTUfG+5gVKpRFtDg9+aeLL7QSghCYlEpqbh2bpNvmYBJ40fTz+XMkx0qw7AtqD7TP7uO3r27Fmos4r//HzUtPz3g0ANCzN2Xs1/bfCkb76hd/nSfFe7BgC774fwzblL3ImJY0/II1avWQNkrwdYvGTJB0Sfe5qamkybPp1p06cD2UmSnp5esd4ttSA8fvyYHl278CAkFKlEgqmJCZu2bqVq1arqDk0QPnli4Z4gFLBatWoxbMQItgbfp8amnbTfe4Sq5mbUtbZCIpG8NOuZnJzMyOHD0dfU5Ex4JCNPnOM738usCgiiVo2aACxcuJCVy5YypUYl1jRrQFb4E+SqLObUrUWP8mVY0bgeGooMdu/e/VosM6ZPo3tZZ35rUp8JbtWoYmLMmjVrsLez4399+75xsRvAuXPnqOfhgb2tLfU8PDh37lyevgcSiYS16zcQkK6g+uaduG/1IcnAiGXLlxMTE0Ov7t25cfs2556EU3PzLmpu8eFKQjJr/vyzwGa5W7RogX9kFL/fDqSGhTlmOtrci41jj49PvhafPXkaTn2bfxfnedpak6FQFPrCMgcHB3S1tdka9ADIbqm46+EjXD9g8WpYeDj1bP7tolHXxooslYpIKxs2bNxYpFsAvktSUhK7d+9m8+bN3L9/X93hvFFSUhInT57k2LFjxMXFvff4UZ9/jllaGpd7dORar064G+kzoF+/XC1yFQThw4iZZEEoBN9++y27du4k/OlTvBztsNTRYtzZiwwZMuSl1mNLlizh+eNHHO3cGjNtba5HxdDj4DGsLS3Z/+uvAGxa9ycjKrnSqUz2joPljY2os203wfEJVDYzRUsmw0JH5439fyMjI+ldLvtx352/QnhyCmtaNEImkfD9pYuM/Pxz1m/c+NJj7t69S8/u3elauhSTGtXl2JOn9OzRg6PHjuWpq4irqytnfX25ffs2GhoaVKpUCblcTqcOHXgeHMR6r8Y8T0tj+qXr1KhblxUrV2JkZJTn7/XbVK9eneUrVjBi+HAWXL2BtkzGVPea+EXH0Kd3Ly5d8ctVZ5d/lHZy4tCjJ3jaZn/YORDyGF0d7UJv2aavr8+SZcv4fNgwfB6FkZSRQZamHJ/N+d+9sWzp0hwMfUIjOxukEgn7Qx6hraXF5i1bim37sPDwcDq2a8fzqCj0teREJSXz6/LldOjQQd2h5Xjw4AHdu3ThaUQEUokEQ0NDNm/b9tZZYZVKxWU/P1Y2qY+BPPvOz9iqFWm+6wCRkZHY2Nh8zPAFocQRSbLwyUtOTmbHjh1ERUVRqVKlXC04vH//PsHBwVhZWVG9evU8z27u27ePpLhY5nt6cPxxOE9TUjHX1X2tNVPQ3bs0srbA7MXucNUtzChjasJnn3+Ovb09AEplVk5/agC5LPsG0I3o51Q0NWHfw0f4R0Qyo06d1+KoWLEiPsFBtHC041DoY1Y1a4Dni7rnGe416H3oCCkpKS8lRj4+PriamjDVvQYSiQRPW2tuxcXj4+OTs715bunp6eH+n90co6KiOOfry552XlQw/aesQsK3Fy5gZGREdHQ006dOJeDmTaxsbJg0eTJNmzbN03P+V4cOHfhuwgSGlXWkZ/nsLhqt0xzx2OrDgwcPqFChQq7PtfDnX+jetSv+sXHoamhw81k0v/72W54S7fxq3749Li4unDt3DrlcTsuWLbGwsMj3+Rb+8gtdOnWk7YGj6GtqciMyiqXLlhXbBBlgwvhxmCsy2NXJGz1NTVbdusuokSNp2LBhkaltHTl8OKUkKvZ074CGVMIk3ysM/N//uHz16ht/x0gkEgz09XiU+O8H4H/+bPCi9aEgCIVHJMnCJy0hIYF2rVsTFRaGk5EBPz2LpmevXsxfsOCtie/y5cuZNm0quppyktLTcXZ2pmPHjvTr1y8ncX2fiIgIShkZ0bGMEx3LOAEw2fcykREvb75iY2eH7+VLZCiVyGUynianEJ6U9FLNcvtOnVi2fDlOhgbY6Oky/9pNTAwMmHbBj+kXryKVSJgxcyYeHh45s8n/zFbPmb+ADm3b0mz3IbJUqpeuWfrijxs2bODgvr0AdO7WnfT0dPQ0NXKOlUgk6GtqvnEL8rz6Z52w9MW5VSoVEckpZGZm8vDhQ/r06oU8MYH2jnZcfXCfll5eNG7UCEcnJ0aOHJmvPsK6ujoolCo0X3Sf+KfXd17riN3d3Tl+8iT79+9HoVAwr2lTqlevnud48svFxaXA+oNXr16dE6dOs3fvXjIyMpjXpMlHvZbCcPPGDcaWLYXei1r7fhXKMc/Pn/v37+Pm5qbm6LJr5K/6+7OuRSN0NbPfekdUqUArn4NERUVhaWn5xseN+eJLZs+axbOUVHQ0NFh9N5gB/fvnezMcQRByTyTJQq5dvnyZ7yZO5PHjxzg7OTFnwYKc24RZWVmcPXuWZ8+e4erqSuXKld97vnPnzrFp40Yy0tNp1qIFPXr0+KB61OjoaL4cO4azZ8+hq6PN4GHDiY+PJz3qGYfatcBQLsc/KoZeGzfSsVOnN/ZwvnbtGtOmTmVRgzpcjYpma9ADymRmcODPtaxdvZqDR47k9MMNDg4mIiKC0qVLY2dn99J5XFxcCIqOwT8qhmoWZjxLSeV0RBT9u7w8czl69Gj2+vjQ9dAJKpkYcvppFDXd3GjVqlXOMdOmTycyIoKBL8oiypcpw/7Dh9HQ0CA8PBxnZ2f09PTo1aMHR48fB6Bpo0YsX7WKUqVKcfLMGQ4dOsSqFSv44Yo/M9ylyCQSpl2+TtnSzsyYPp1+LmVQAZMmTKB7jx5cCHvKxrv3aOpgy/HHYVwIe8qEZs3yPTb/sLCwoE7t2ky6cJXvalbhl+u38I14hlQioV7duuhqanCyU2u0NTQ49vgkJnJNbMIfcT3gFs137ODo8eN5TpQHDh3GrB9+QKlSYaatxa+3g2jaqFG+NrcpXbp0vlrHFUWOjo6MHDlS3WHk2pMnT5gxfToP7t+nlJMTk6dNe6mji4WFBbdj4uj0ol11QEwswGuLWdVFJpNhqKfHw4REPKyzE+KQ+ESkUuk7Z4VHjBiBnp4eWzduIDNDybDRY/jiyy8/VtiCUKKJFnDFQGG3gAsLC2PShAkE3LqFlZUV306dSv369V86JigoiObNmtHawZaGtlYceRzOmWcxnDh1Cmtra/7Xpw+nz5zGTFePyMREJk6cyJdfffXW59y/fz8DBgzAUkcbTamUiNRUxowZy6Rvv33puNy2gFMqlbRp1Yq08CeMruTKs9RU5l67iWMpJ+pqwKQXq/gBWu37m+ETJ9G/f//XzvP777/zx6KFLKpbi7Z7DrPFuym1LC1QZmUx7OR59CpVZu269Xwzfjxr//wT2YvZyVk//sigQYNyzqNSqRg/bhybN22inJkpj+ITqFSlCtt37kT7RWnFPyIjI1mxYgURT59SsVIlhg4d+lKLuH/GPzk5mZSUFMzNzV/7MNG+TRueBQfxY51aSCQw5dJ1HKpUZfO2bTnHJCYmMmrECA4cOgRAs8aNOXP2LD/WrUWH0k4A7Lj3kO/9bjBz1iy+nTiRdIUCbbmcufPn07t377d+//Pi2bNnDBs8mLO+vhhoarKpVVPKmxgx9tR5bsXEcqxzG/Y8CGX6BT8OdfTGWk8XZVYWff4+TUWvlixcuDBPz6dSqVi5ciV/rFpFWnoajZs0ZeaPPxaLmbi3vfbj4uK4cuUKUqmU2rVrf5K33v/72o+IiKBpo0Y4aspobGPFuYgo7qakcuLUqZy63OPHj9O7Vy9albLHSkebvx48on3nzvz0S/5rtwvasmXLmD1rFgNcyyKXSvkj8B59+g/ghxkz3ni8aP9ZNMpkhJJLzCSXUGFhYRw9epTk5GRW/vYrdlIJw50cuB79nG5du7L/wAFq1Pg3sdy2bRuuxkbMruuGRCKhVSkH2h84xq5du1CpVPhfvsTWVk2JSU3nZsxz5syZg4urKxkZGejq6uLp6flSveMXY8agI5PRsbQTiYoMtgQ9YNFPPzH888/z9YsxKCgIv+vXOd21HTYvdldLVmSyPOgBV3S0c8oZQhOSCEtIxNbW9o3nMTY2Jio5heC4BPQ0NahlmV33KZNKqWdlwf7QR2zYsIHtWzazzbsZ1S3M2PMglG8mTaJGjRrUrJndkUIikTB/wQJat2lDYGAg1tbWtG3b9o1t16ysrJg6dep7r1FPTw89Pb3X/n3M6NH4XrrEeq/G1LTMnjWb7laNXoeOk5qamlNWYGBgwJ/r15OamopKpSIrKwtnZ2fK/mexXFkjQ1LT0ujWrRtdu3bl2bNnWFlZFWiLM0tLS3bt2UO3zp0oFxuNq6kxAMOrVKDjvr+puXknyYpM7PX1cnbKk0mlVDE1IjQ0NM/PJ5FIGDZsGMOGDSuwa1CnW7du0bNbNxIS4lGpsmdKt+/c+dYt4ouC6Ohodu3aRWJiIh4eHq99CH+frVu3op2ZyR8tGyGXyRhQsTwdDx5nw4YNjB8/HoCmTZuyc9cu1q5Zw5PkZMb36svQoUML43LybcSIERgaGrJt8yaylFl8PXESn3/+ubrDEgThLUSSXAL5+fnRvWsXjDQ0SFUoSM9QcLB7e3Q0NOharjTRaen8sWYNNf7THzUtLQ1TLXnODKZUIsFEW4vU1FTuBgTgZmbK4KOnScnMRJmlQksmY9DAgRhpa5OqUGBnb8/O3buxtrYmLi6OuIQEVjdvSEO77FkgWz09Fl+/RXR0dL6S5H96qepr/vsjrS/XxNBAn6hMJZ0PncDVyIAzT5/RsFEjmjdv/sbztGrVip8WLGDZrTskKzI5ExZBAztr0pVKjodH4lyzFr7nz+PtaIerqTFr7wQRlpSMpb4e58+fz0mSITs5a9q06WsLz9LT05FKpR/cp1ilUjF0yBB8XrR+y/zPTSHli/rjN5Wv/DfhLefszKqAQObVq40KWBUQhGu5cjnH5KckIbeMjE0If/Io5+//bOM9uJIr9nq6TDh/Gd+nkdS1sSI6NY2DIY9JeRROTExMoW2NrC5xcXHcvHkTLS0tqlev/tatmFUqFYP698fNUI95rRqTpVIx9sxFhg0ezLGTJz9u0Ln06NEj2np7o5GRjqWuLvPmzuW7yZPzVLYSFxeHvYEu8hcLWDWkUhz19V5roVavXj3q1atXoPEXJIlEQt++fcXW0YJQTIg+ySXQqOHD8bKx5mj7loyq7IqJthY6Gv8ml9Y62iS9couvYcOGnHoSxoGQRyRmKNh57yGXwp7SsGFDjE1NORX2lIZ2Nvj16sylnh2pYmaCiVwT3y5tONulLQYpyXwz7msAYmOzawXLG/87g1nO2AilSvVabW9uubi44GBry0TfKzxJSubqs2h+vRVIK+/WHD1xgtZ9+2FQ15Nxkyfz5/r1b91CWF9fn9379uHu1QprCwsGHztN36OnabP/KKGKTKb98AMGhoY8Tkql96HjrL4dSFhSCqnpGWxct+6ljQ+CgoLw9vLC0cGeWtWrs2nTJj7r1QsHBwfs7e1p37Zt9q5we/a8Vkpy48YNvvryS4YMGsSKFSve2BN137597N+3jz9aNKKNkwNTfK9w6slTzoQ9ZcLZi2hpaLy3D+vKNWu4kpCM+/Y9uG/bw42UNFauXk16ejrjx42jtJMTjg4ODBsy5I0t5t4lKSmJb8aPo4mnJx3atOHIkSMvfX3IsGEcfhTGlAt+bAq8x9dnL1LZ3JRR1SrRsawzjeys6f/3SVrvPkiLXQew1tPFQq7J8uXL8xRHQbh//z7Dhw2jU7t2TJo4kfj4+AI55+HDh9mwYQPubm706NaNtm3b0qZly7eWiMXFxfEgNJTPK7sil8kISUgiND6BWwEB1KpenX379n1wXAVtynff4qQp42DbFmxp0ZCfG9ZhxowZPHr06P0PfsHNzY1L4ZFcjMjeWOXqs2jOhD0tEgvyBEH4dImZ5BImMzOTeyEhzPRuilQiwc3KghmXrrHxbjA9ypfhRvRz9oQ+ZvLAIS89zsvLi2+/m8yXM2eSlZWFhkzG7DlzqFevHhKJhI0bNzKyaiU0pVI0pVI+r1qRIcdOA2Ag16R3WScWXrsOgJ2dHSaGhqy8dZfJ7jVIVyr5IyAQl3Ll8t2CSltbm01bt9Lvs89osiM7UejYvj1Tp09HW1ubb1+pdX4Xc3Nzfnkxi3706FGuXLmCkZERXbt2xcLCgv79+9P0zz8xlmtyoH0rTLS1eJaSSrsDR9m6dSt9+/YlJiaGzh06UFVfh8X13bkZE8sXY8dia2DAeq/GKLKymHTuEoE3/EnPymJzvfqs37QJDQ0NLl26ROeOHaljbYGNjg6TjxzmyuXLLPrpp5fi9PX1pZGdDZ621tSwMGOK7xWGHj+DSqWijJEhuqrsYzp16vTWa61cuTJnzp/n8uXLQHYHB2NjY8Z9/TWHdu3kx9rVkUulzDl1khHDh7Nuw4ZcfQ+VSiWf9exJeFAgvcs68Tghln59+7Ju/Xq8vLwA8PDwYNv27cz78UeuRERj6uCILO45qhez4DUtzQlJSKRn+TJY6OjQzMGWKRf8ePr06XuevWA9fPiQli2aU9nIkBpmJhz22cX5s2c5eORIvn9ely1bxvfff4+eXJO0DAVdy5VmnHdTDoY+5rdbdxk+ZAh/7dr12uP09PTQkMl4EJ+IiZYW/Y6cxMPagm9rV+daVAyDBw1ix86deS5nKEz3goLpbW+T08awpaM9GlIpDx48yPUizFatWjF02DD6LFuGkY4O8ampDB40iI4dOxZm6IIglHAiSS5hNDQ0MDMxxu9ZNLUsLXAxMaZTGSd+uHSV6RevAtCvb983LmobPXo0vXv3JiwsDAcHh5yyiCpVqgAQkpBIKUP9nD/ra2jm3O4PikvAzNQUgOfPn+Pl7c2WHTvYcT8ElUqFiZkZu1/Z1CKvXF1d8b10ibCwMHR1dQtkVXvz5s1fK82oUKECrdu0IfX6VUy0s3vkWurqUMnMNKdm9vjx4yjTUvm5VWPkMhmN7W0JiU/geVp6zsr2H+q6MfLEOQ52aEX3IydZv349AwYMYNYPP9DGyYE5L+q/u5R1ptuGDYwYOfKlulMDAwMi09LJUqnQ09RkrqcH155FE52WxvKmnnQ7fPK93UIiIiKIjIzMSY4h+5b+tm1bmV/HjZalslvemWhr0ePgYRISEjA0NHzv9+3atWv4XrrEqS5tc2rEVcCyxYtzkmSABg0a0ODgQQACAgLwat6c+Vdv0MLRjjvP43iSlEJtKwsqmJoQmZLK+chohuazDZpKpWL16tUsW/wLSUnJeNTxYNHPv2BpaUlcXBw+Pj7Ex8fj5ub2UpK5fPlyyunpsaapJ1KJhP4VytNiz2H2799Pt27d8hzH5cuX+eH77/mlYV1KGxnQds9h+lcsR/eDR4lJTcdQrsnps2fZuHEjw4cPz3lcUlIS169fp2PHjkzcuwcPC3PkMik/NayLhlRKQzsb7sUnsHXLliKVJNs7OOAb+pBeLmWRSiRceRaNQqnMdTvFf0ybPp1u3bsTEhKCg4NDzu8dQRCEwiKS5BLoh5mzGD1qFAHP49CUStkX8oiJk76lbt26WFpaUrp06bc+1szM7LV6UH19fYYMHsxXGzfQ36UsqZmZrLkdSJZKxeCjp7HQ1WbnvRDW/PEHoaGhtPJqgZlUSjMHW049eYpH/fqsXrMmV8nX+8hksnz10s2rMmXKsP7o38SkpmGmo83T5BRuRT+n04sa3oyMDLQ1NHJ68wIYyOU8e9GjF0BKdgLrYKBPbUtzAgMDAYiMiMDb1iInwa1qbopUIiEiIuKlJLl37978vnIlo0754mljyZHQJ0SlpTPZrQaLrt9GU0eHBg0avDF+lUrFjB9+YMnSpQBoy+Us+vlnunXrhkqlQqlUoqPx7wYm2i/+/K4OI/+VkJCAXEOGte6/9c+O+nr4v6NMoWLFivy5fj1fjhnDqlt3sTA1pU7duvQ4fILyZqY8iI2nSrVq+V6MtWHDBqZPmcJX1Stjr6/Hihv+9OrenT/WraNju3ZkJiVhra/L7B9/ZNKkSYz94gsAnkdHU85QP6e3s5GWHAsdbQ4dOkTLli3z/HPr5+eHq6U53k4OhCUlA/Djpevoa2ryV+sWGMg12RJ0n/HjxtGuXTsMDQ0JCAigV/duPIuKRgWYGhsTrAJNmQzZfz4I6WloFEg/64I0Zfp0HBf6VAAAIABJREFU2rVpQ88jJ7HT1eHo43CG/p+9sw6IKn3b8DUzDEM3Q4iAIChhIHZ3YreunSuu3bv2Gruu3bH22ro2qNhrE/YaqJQi3Tn1/QHOLj9RwUVd95vrL+Kc97znnInnPO/z3PeQIR/VaOju7o67u/snmOXXw+vXr5k4fhzBgUGYmJgwbtIkOnfu/KWnpUHDfxJNkPz/gFevXvHbb7+RkpJCtWrV6Nq1K5aWlhw6dAilQsGvM2bTunXrIo2VkJBAUFAQIpGIGjVqqGW05v74IwDrt2zBWk+XcVUqYKClxeybIVTx8mLX7gV4enoybOgQnCXabG1aHy2hkHvxiXQ+GUBoaGiBprd/M6GhoWzeuBGVXEGrI36UNzPlQWISlbyr0qNHDwDq1KnD1KxsloTco1e5stxPSGTf0+eY6+kSGBOHTKlk7s1gWjjYkSWX82dSClWt85zw3NzdOXo7hPZODuhqaXEw9AUikeitoMLBwYHjJ08y84cf2BERgcTYFO3UdKbfCMK9nCv7Dm57Z4Pb3r172bh+PZub1qeK1IIDoS8Y9d13uLm54enpSfOmzVh48wamEgnaIiEzb96murd3kZsqPTw8EIm0WHXnAb6VPIjOyGRn6AuadXr/l3mTJk24++AB2dnZ6OjoIBQKuXLlCsHBwdjY2NC2bduPbnjcsWULQzzKMdAjLxPtbWVBzb1HGD9mDFKVgq1tm6GjpUVAxEtGzJ+PT9u2ODs7U7lKFVaePcug1DQcjAy59DKa0IREEgLO0KxxY477+RXL/c7ExISY9EwyZDJs9fVo5VCaiy9fMdG7ktp6uLuLE3NuhvD48WOqVq3KwH59qainwy+9OiFTKhl58TopxiY8jYtnxZ0HdHNxIiQunqMvwpk39N+lluDp6UnAuTwlitTUVJbUrEmXLl2+9LS+SrKysujaqRM6aSlM9SzH85RUfEeMQCKR4OPjA+Q9ACcmJmJgYPBZ3CA1aPgvowmS/+M8f/6c1i1bYiESUtpAj62bNxN46xZzf/yRRo0aFWusoKAgevXoQU5WJgqlCisrKw78/juOjo6IRCLMLSxwl1qyr3kD9T4XX8fi7O2NQqGgetWqKOUyRlRwRys/w1rBwgwzPT0iIyO/aJAsk8kICwtDIpFQunTp95YpLJg3j0qmxqyqX5NDoS+4F5/I9egYJk+bpg7gHB0d2bJtG8OHDGHdvT8RCAR8++1wHj14SE//PMMPfbGYx0nJNDh4Aj0TEwYOHAjAvIULadu6NY2P+GOmq8uzhEQW/fIL1vlB9N9xc3Nj38GD6t9VKhVyufyDgeTFCxfwcbSjXr66SD83V/a/iOTq1at4enqybOVKhg4aRKcTZwCo6uXFr1u3Fvl6WllZsX7jRoYNGcK6+4/IVSioW7sW04sgdQeotaQFAgFt27albt26Rc5iv4uc7GyMjP+S0DMUixEJhUSEh9OjlA06+c2rTe1Loact5tmzZzg7OzN06FCuXblCy6P+GGppkZKTy8hKHgzyKE/vgEssmDePJcuWFXkePj4+LF+ymL5nL9PKzpZclQqFCu7EJ/JN/jaPkpKRKRRYWVmRkJDAs7BwVrZviUQkQiIS8a1nOfqeucjWrVsZPnQoq+48QAAY6eiwcP58atSogUwmY8vmzaSlplK7bl0GDBjwzobVT42zszPe3t6cza/xd3Fx+eod/r4EN27c4PmLF1zr2hajfAWU5Jwctv66CR8fH+7du8eg/v15ERGBSCjk2xEjmD59+he77xo0fO1oguT/OHNnzcJNX5eNjeqgJRRyKyaOXuvX06t3b9zc3D48QD4KhYKB/frRRGrOnBrNyFUo8b10je++/ZZj+TWlWlpaZMvl6sYrgGy5AplMxtDBgxng6sSrjEzOR71ioEc5JCIRN1/HkpiZSZkyZd557OjoaHbs2EFmZiZ16tQpoN9cEjx+/JhvevYkLDISgEYN6vPrlq3vNGh4FRVJQ0tzdLW06F3eBYDzr2OJjY0tsF2TJk24/+efvHz5EgsLC/WyfFZWFmfPnmXIoEEYSyTYGeZlJ/ft28fgwYOxtbXl3MWL+Pv7k56eTsOGDdUufx9CIBAUKdOqq6tLVPZfShy5CgWpOTlq6TdjY2P27N9PYmIiSqWyUAOTD9GyZUtuBQXx8OFDjI2NqVixIiKR6MM7fgIuX75MeFQUayIUVLY0x85Qn19C7mNmYoKjkxM3X4TST+WKUCDgXnwiGTm5ai1tsVjM9p07+emnn1i3aiUdy5YhV6nkaXIKjW2tuJlfJlNU8hRUTjBn1iz8Hz7EupwbiyZMYsL4caSfl2Onr8fhsEi6dOqEu7s7cXFxCAQCItMycMlXhIlIS0dfV5e6deuiVKkY5lme4RXd0RGJGPfHTYYOHkxYWBi1rKXY6ukwLyCAB/fuFSuYLw7Pnz8nKioKR0fHQsudli1bxs8LF9LCwY5UmZzW27eza/duGjZs+Enm818lOzsbiZYIg7+9x810dHiSlUVycjI9u3WjmpEBq9u15HlqGlM2bsTKyqpAbbsGDRqKjiZI/o8TERZGG2upOnNbzcoSA4mEiIiIYgXJr1+/5lVMDMPrVEVLKERLKGSQmwvDLlxRB8U+Pj4s+eUXZt4IppWDHX+8iuFWTBwdPTzYkZPDd5U8iMvKprvfWVr8fhJbA33uJiQxfNgwtb31//L48WPatWmDrkqJsUSbH+fOZcnSpSXm/iaTyfimZ09chPBb13Yk5+Qw8vINpkyaxOq1awvdx6VceU5fOEef8i7oibW49DKapMysQmssJRLJWzXeurq6zJ87l17lyjK9el7AfzD0BdOnT6dHjx4YGBhgbGxM9+7dgU/jutWnb1/a7NnDnJvBeFmYczQ8CpVEh1atWqm3EQgEBco15HI5IpGoWMGyVCpFKpWW6NyLS3h4OH1696aTgx1R6el08zsLgFn+g4COjg5tWrWi5+kL2OvrERAVTZ/evQtYqwuFQvT09MjKlRGZls7L9Aw23X+Ek6kxFRo2fteh34lUKmXVmjUF/la+fHk2bdzI65QUxvbozbBhwxAIBOjq6jJk8GAm7dzJkGQXchUKNv75hDHjJxAdHU12Tg4DPMqpA6e2jnaM/+MGPo72LKxdDYCOzmXo+ttvjBg5ssRMR+7fv8+KZcsICgwk4uVLREIhSpWK77//ntGjR6u3S05OZsGCBSyrV5NWjqUBmHcrhOlTp3L52rUSmUtRUCqV79QOLy4KhYKUlBRMTU1LZLyi4uXlBSItfgq6g29Fd56lpLLz6XMG+Y4kKCiIlJQUfspvFnYxNeZxUjLHD/+uCZI1aPhINEHyfxxHZycuhATTx80FsVDItegY0nNycHR0LNY4xvmubM9TUrE3zKtDfpaSirGhkfpLwtnZmb379zNu1Cj2nrmIgZ4eejo6zJ87F5VSyfOUNFxMjTns05yRF64QiZBNW7bQokWLdx53wtixVDbSZ0W9mmgJhex6HMrECeOxtbXl6dOnGBsb07p164+2GA4LCyMsMpLfurZDqqeLVE+X7zzLs/DcuXfu88OMGfhcu0bzY6ewNTDgXmwcEyZMeOuhQyaTcfbsWeLi4vDw8CAzM5OVy5aRnJREWEQEkxrUUm9b19YamVxOTEzMZ7FL9vLyYu++fcyaPp1TD59QvrwbhxcvLlQR5NGjR4wYOpT7jx5hYmjIpKlTGTx48CefI+QZUbRp2ZJbQYEIAT19A3r06sWIESPUdsQf4tKlS5hJtJle3QuBQEBsZhZzbgajW9lbvSpx5uxZtm3bRkpyMnN8q/HNN98UGEOlUrFu9Wp8K7oz2itPVWH1nQesvvuQnVOmlMi5enl5sfp/Auc3zJk7FwtLS04cOYJIJGL6rNkMHjyYlJQUhPkrRC0d8gLQWzHxCIVCKluYqfd/0/wZExNTIkHy/fv3adWyJc4G+kQnJbOteUNqWUsJiHzJd/PnU7lyZRo0yCu7iomJQalUUt36r7rtGlZSfr91+x/PoygkJycz+ruRnAk4i0gkolu3bsxfsOCj63V3797N1MmTycjKwszEhFVr1tCsWbMSnnXhWFlZsXX7dgYPGMDmB3krGF27dGbs2LFcvnwZpUqF4m+mQjKlEoGm1EKDho9GEyT/x5kxazatW7TA50QAdgb6XH/1mtGjRlGumDJaBgYGDBs6lHHbt9OvnDNZMjk7njxj9ty5BbarWbMmV2/eZOSIEVw65c/4Su6oVLAg8A7d/c8xooIbrzIyCYpLYMvWrbRs2fK9x3369CnTPFzVmfD2Tg7MvB5E927dcLW0IC4jg6W/LOLoiZPFap56w5svyuScHKT5SgzJObnv/QKVSqUEnD/P4cOHSUpKYnqVKm+pSGRmZtK9Sxfu3rmD1ECf8MQkBAIBHcs6UsXQkEcCOBkWSYNSNggEAvzDI9GRSIoc+L0hODiYAwcOIJfLadasWbG+rOvVq/dBl7akpCS6dupERX1dprZoxJOkZGb88AOmpqafvKM+IyODDm3bIs3N5qda1VkUfIf49DS2b9rE1s2b2bJt2zudE/+OQCBAoVKhVKkQCQRI9XTREYnQ+puBjrOzM3PmzHnnGJmZmcQnJdG49l/mFY1K27Ls9v3P4v4nEokYO3YsY8eOLfB3ExMTJk+ezPhFiwiIfEVyrowrr15TtUoV9oQ+x0BLCxdTY27HJSASiQot28nOzubWrVtkZWVRpUqVIkknLl+6lDpWltjo6mBnoEdtGysAmtnbUc3Wmhs3bqiD5FKlSqEjkXD0WTgDPMqhUCo5Hh5J2bJFKyH6J6hUKoYMHMjLhw9Y37A2mXIFcw//jkgk4udFi7hy5QpnzpxBS0uLjh074uHh8d7xLl26xJjRo5latTK1baQcD4tkQL9+BJw7R/ny5T/5+UCesVPI3buEhYVhYmKiNmCqVq0aVlIpoy7fYKi7Ky9SUtnyKJT5Cxd+lnlp0PBfRBMk/8dxcHDg3MWL7N27l5SUFIZUq/bBwPRdzJk7FxtbW/yPH0dLT4uly5fTrVu3t7bLyclh34ED/NqkPvVK5TWbGWqL8b1wFb8sGYYm5mzfMauAXu67sLWx4UZsHK0d85rpjj2PQAAsqVeTNmXsSZfJ6Hf2MrNmzHhnecT7KF26NI0a1Gfk5Rt851me5JxcFt+5z5gJEwts9/DhQ6KioihTpgwuLi4YGRnRt2/fd467fPlyop485nT7lljp6dLp+BlcTIxYWLs6AM7GRoy8cIUHyakYSrS5/TqWFStXFsuc4syZM/Tt04datlboibTos20bP86bV6JZ3qtXr5KRlsaSFg2QiERUs7LkWUoaB/bu/eRB8o0bN4iOjuZwt3ZMuXITqZ4ux9u1xEhbzJKQewwdPJjbd+9+UIKtSZMmzJ4xg2nXg+hW1pHbcQkcD4tkx48LijwXPT09LM3MOBv1igr5Gdqzka8wNTZ+Z+16SXP+/Hl2bNtGdnYWjZs2Y+DAgQiFQsaNG4ezszNnAwIw09Vlavfu7Nyxg523bvF9UgqZcjkigYBFixe/1fz5+vVrunbqxLPnzxGLRGhLJGzbufOD1s7xcbFUMjFCqVJxNz4RpUqFUCBAplTyOiOrwGqIgYEBy5YvZ6SvL0cjX5GWm0uqQsmhX7d+istUgISEBC5cvsxhn2Z4mOfdN4VKyQ/791GhYkUmjB9PHTtbsuQK1q1Zw649e6hfv/47xzt+/DhN7O3o7+4KwFgTYy69juPMmTOfPEjOzMzk4MGDxMbG4uHhQYsWLQqUehgYGLD/0CG+HTqU3qfOY6Cnx+SpUzUW2Bo0/AM0QfL/A6ysrBg1atQ/HkcoFOLr64uvr+97t5PJZKhUKoy0/2ouMdLWRqlScfL06WItc85dsIDOnTrxLCkFqa4uJ8MjkIhEtCmT1xxkIBbTpnQpTjx48FHnJBAI+HXLVqZMmsTCc+eQSCSMmTBRfb1UKhVTp0zh182b0Zdok5GTy8SJE5k0adJ7x7135zYtStlglZ+dFgrAyfivYK5JaVt0xGIqN2lKmTJlmNeoEd7e3sWa+/eTJzPAzYVJ3pUAOPD0OTOmT6dXr14f7QT3vyiVSkRCQQEtXm2hEIVcXiLjvw95fnCnIxJxJz6RcV4VMJbkdfSPqOjOunt/8uzZswKNnGlpafz666+8evWKsmXL0r9/f2xsbNh38CC+w4dzyO8cZiYmLF22rFhZd4FAwNIVKxjQvz834hIQACExcfy6efNnqUk9duwYgwcNor2TA3YSbebNmsWL58+ZN38+AO3bt6d9+/YAHD16lP379rGrZWOqWVly43UsA89ewszM7K1xx48dg25aCte7tUNfS4t5t24zsH9/Qu7cUTdxFkZFryoc2/Ubv9Sqys5Hofiev0JdW2sCXkaTIRC89QDVuXNnXFxcuHz5Mtra2vj4+BR71eRjeKOI8ne9cm2hCIVCydTJk5lR3Yve5V1QqVTMC7zNpHHjuB4Y+M7xhEJhgXIGALlK9cnVI9LS0mjbujUxUZE4GhuxNDae7j168MvixQVef87Ozpw+e/aj+gc0aNDwNpogWUOJY2BgQM1qVZkffJefa1VFqYIFwXepW6tWsesA69SpQ4+ePfE7sB8HQwPGVq7A4pB7PE5KppypCSqVitsJiUjLfHydpaGh4Tuz0AcOHGDXzh3sa9UEL6kFl15GM2zJYqpWrUrjxu9u2LKUWvHgz4fqDJuTsRG/PniMkbaYhnY2+IdFIVepmDp1arGdx94QFR1NrXJ/OavVsrFCJpcTHx9fZEOVjIwMFi1axO2gQMwtLBk9dmyBJsoaNWogEGsz/XoQA91deZKUwm9PnzNv0McZehQHb29vtHV1mX4tEAOxFqHJqer/vfn5jUsg5BmYtGzWjJzEBDxNTTi2fx9+x4+z7+BBvLy8uHrjBjKZ7KN1llu0aIGfvz8nT54EYH6rVp9NxmzBj3MZ5unGuCp59dANStnQf+NGRo8Z81ZjZGBgIHVsralmlVd+VMNaSm1bG4KCgmjTpk3BbW8FMquyh1pO7LtKHuzYe5jw8PC3MqMqlYrdu3dz8+ZNdHV1MbErTd+ASxhKJFx8Gc39rGwqeXlx/Md5WFlZvXUOFStWfGeD7qdCKpVS1cuL72+EMKtaZbLkchbevk/Dhg056e/PybBIjj4Pp4a1lDo2Vuy+9P5Gwvbt29NxyxbW3n1ITRspJ8IiiUhLe29fRUmwdOlSMmNe4+/THGOJNnfjE+ixaxftO3QoNPP991IiDRo0fDyad5KGT8LGzVvo07sXTX8/iRAQCIUIE28ysF8/lq1cWSyXMh0dHWpYS5lfpzoqlYonySn08DtHOyd7wtIzCUlI4vimLQX2UalU7Nixg+2bN5Obm0PTFi2ZMnUq2vnBwN9JTEzk7t276OjoUKVKlQLb3Lp1i0albPGS5tVp1i9lg7eNNYGBgYUGyY8ePWL79u2kpqZyOyGJfmcu4WCoh194JEqlip8C7zDnRjACoZDVa9d+dIAMUNapDCfDo6hja4VQIOD4iwj0dXULDVAKQyaT0aNrV149fUI7Bzse33tFm1atOH7yJJUq5WWnpVIpu/fuZVD//hw44o+WSMSYsWM/yxKuubk5e/bt45uePYlPTiU0OZXk3BysdHX5LfQFnTp2LNCAun79emRJiRxp3QQDsZjojEx8Tpzh8OHDavvojw2Q31CpUiX1tfmcxCck4G7/l9qGm1meqUtCQoI6SH6j3mBsbExkRiYypRKxUIhMqSQyPYO6+c236jHj41HI5cy5EcTmh48ZUdEd4/zX/t8fPt4wedJE9u7aTbPStjzKzOJ5Shqz5s7F0NAQT0/Pf6UTnkAgYMv27Qzq358Ox08D0KZVK1q1aYOfvz9OxobY6Ovz26NQToZFYl/q/e/HWrVqsW79eqZMmsSSkHvY2diwa/eeElMMeRehT57QwFqqXkmpaGGOo6kJoaGh7y0P0aBBwz9DEyRr+CRYW1tz6kwAw4cO5dq5s8yoWgmJSMT869cYNmQIu/fuLfJY9erVY/DmzRx4+pxMuRw9LS0yZDIiLKwoW6MsPw0Z8lbWa+PGjcyZNYuh7q4Y6hmwaetWXr16xbr16wtsd/XqVfp98w2ZWVnIFQo83d3Zs3+/ugnQyMiIWxmZKJRKREIhOQoF0ekZhQb5wcHBdGjfnopmJtjo6iBQKkk2MuZFfDye5uZsbFIXPS0tfgq8w8HIl/84+7Rk+Qq6denCnRMB6Iq1eBiXwNp164qcrb98+TIht0M426E1Vnq6qFQqfC9eY+Xy5WzavFm9nbe3NyF375KQkICRkVGhDxqfiurVq/MqJoZbt27h7+/PuTNnCJfLGeQ7kjFjxhRYTo6IiMDLzEQthWajr4eLqSmR+frXRSExMZGJ48Zx+Y/L6OnqMmT4t4wYMQKBQMCdO3dY9NNPxMXE4FGxItNnzCiyA+E/pYJnBfaEvqBhKRskIhHb/nyCllDI48ePsbKy4jtfX85fuIBYS4uOnTqRrFQx+Nwf1LOWcul1LGkCIZ6enixduhQdHR2aN2/O4AEDsNWV8I2LG0+TUxh+7jL62hK6d+v2Vu3yo0eP2LJ1G/taN8HL0gKVSsV3l65zxt+fPfv3f5Zr8LFYW1tzwt+f5ORktLS00NbWpkmDBgxwL8fUankrAc1Kl6L1UX9Wzv9wnXqHDh3o0KEDOTk5n83RztbOjpshweQqFGiLRESkpROVmqZu2tOgQcOnQRMka/hkCAQC/Pz9WVyrKs3s8zI0RtradD0ZQEpKilpW7kN4eHggUyiYdvUWdgb6pMtkaAmFTJk6jRo1ahS6z5qVKxlf2YMB7nkqHpUszOl+6BBz5s5VZ94yMzMZ0K8fPqWs+aFaZVJyZQw+f4VJ48ezZft2APr27cu2zZsZfvEata0sOPsyBpm2pFBb3dkzZtCslDW/1KmOQCCgy+tYvjl1HhNDA/pXqKQO3oZVcGPzw8dERET8o2afqlWrcu7CBU6cOIFcLmdpo0bFWs5OTEzEVFdXXTctEAhwNTbkTnzcW9sKBIIiqR58CsRiMW5ubri6ur63tt7Z2ZmtfidJzM7BTEdCWGoajxMSGfYeoxrIe7jZtWsX2VlZBN66hXZaKnO8PInNzOKn+fMRiUTUrVsXnzZtaGhjRWMzE477+9ExMBC/06ffW7tbUixetoy2rVtTY+8R9MVapObm0tLBjm+HD8fDzY3cmNesb1iHNFkuc44cpmWHjqSnpHAqLAzHKlVpVa0avXv1oqKVJam5Mn5euJCc3ByudmmLSX6gly6Tc1sJy5Yvf+v4L1++RCLWorJFnpKHQCCghtSC/S+jPvm5lxQmJia8fv2aHl278uLFc/pU/8vh09E4r/nyfaZG/8vntHweM2YMLY4fp5P/edyMDbn8OpY6det+Nuk5DRr+v6IJkjV8UlRKJWLR35pm8n8ujsXwunXrEABTq3nR392VHIWCoWcvM270aK5cv17oPunp6dgZ/GVBXCr/5zVr1lC9enVatWrFixcvSExOZkzLRoiEQsx0JAwsX5aFN2+q97O3t+fkqVPMmTWLYxEROFXxZt3cuYUGjNGvXtLGzlqd3axmZYlAIEBfX58nySm0cMh7UHianALw0VnI7Oxs1qxZw4N797C0ssLX15fSpUsXe5wKFSoQl57BkWdhtHd2JDojk6MRL2n/TfHNMf4NDB06lBPHjtLmxBnKmZpyJzaOqjVrUrFiReRyeaF1mufPn6dXz57UtbXGWFtMWFg4/dxc1JrD2QoFO7Zs4f69e9SQWrCifk0EAgHdXZ1ofNiPgIAA2rZtW2LnoFKpiI2NJScnp0CW0NHRkY5dunB6z26Ge5TDW2pBaUMDIvzOc+f+ffzat6KsSb6jo1zBYj8/HuY7Aaanp+NWrhzTqlair5srCqWSCVducjbipbq8AsBWX4+XEr1Cr5OzszO5cgWnI17SwsGOHIUC/6hXuFQpXrPpl2bsqO8QJyfSyM6W3x6H0tTeDlOJNmvuPsRATw9XV9cvPcVCsba25sy5c2zcuJHY2FjGurur1U00aNDw6fjqguRVq1YRGBhIVlYWhoaGNG/evFAZMg1fHoFAQKuWLVnwx2WMtbWRiITMuHmbmtWqFStAjI2NRaFS0d01z7lOIhLRuWwZ5oTce+c+NWrWYP29e1SRWmAgFrMo6A7aQiGXD+5n88aNtGjRgh9mzgTyLH4rSPI6/8NT094qpXBxcWHHb799cJ4u5cpx8tGftHd2RCIScex5OEKBgJGjx/DD998Tl5WNibY2u0Jf0LdPn/fWDt+7d4+rV6+ip6dHt27d1FkruVxOz27dCL1/jya21gQH3qTpwYOcOXu2yM16byhXrhw/zpvH5O+/Z9GdhyRnZeHt7c3EiRM/vHMRUCqVxMbGYmRkVGJqG+9DT0+PYydOsnfvXl68eEHqhQtcuHiRmjVr4uTgwI5du94KgmZMm0afcmWZlr/s3rx0KUZeuMLwCu6Y6kgw1tYmNzeH5KQknAz11Q9AJhIJ5np6JCcnl9j8MzIyGD50KP6n82pnXZzKcOjIUXXpg46ODuZ6unRwdlTvIxDkKS1o//1BVChEqVSqf3/58iXZublqRRiRUEhrBzv8wyJZc/chwyq48Swlld3Pwug7rHBnNkdHR6ZPn87oH3+kopWUmMxMBLp6bPhxXomdf1HJyspi3bp1PH3yBBtbW7799tsir3Jcv3GTX2pWoYqlBQPOXKTO/iN5yhciLTZt3lxi5TNpaWlERUVhY2NTaH33xyCVSvn+++9LZCwNGjQUDYFK9T96Nv9yIiIisLKyQiKREBcXx6xZs+jZsyd169Z95z7x8fGfcYYlz6ewJf5cpKWlMWL4cPUXf63q1di0ZWuRrYpFIhH79+9n2LBhbG3WgDq2eQHDzOuBBMnhj3dkkmNjY+nZrRt3HzxAKBCgJRSwokGmKHs+AAAgAElEQVRtmpQuxdPkFLr6n2OY70g2rF2LWKlgqKcbCdk5bH30lCVLl9KzZ89in2tYWBjt2rRBmJONhZ4u917HMm/+fAYPHoyfnx/bt2whJyebhk2a4uvri0gkKnScPXv2MGb0aMqam5GSk4NQV4/Dx45RpkwZ/P39GTZoEP7tWmCjr4dCqeSbM5dwa9acJUuWFHvOkGf9/eDBA8zMzKhbt26JdMbfvHmTQf378zouDqFQyKjvvmPa998XW5JKJBJhampKUlJSsVYfRo0cydXTp1hRtzqmEglzboXwTCXkj2vXCtRUuzg5Mb9qRXU5UGJ2DjX2HmZ784YYiMV898cNWnTqhI1tKdYvW8auZg0oY2zIkedhTL5yizMBATg7O3MjXznDy8vro0xtAMaMGsVlv5Msq1MdE4k2cwLvECUSc+nKFcRiMbdv36ZVy5b4VnCjSWlbzkW+YuXdh5RxcMAsJ4sZVSuRmitj0rVAGvm0ZcmyZQQFBXH8+HHWrF7N4no18ckPlOfcDOFiajrxCYlkZmcD0M7Hh3UbNry3ufHq1avcunULIyMj2rdvX6isXElR2L3Pzc2lY7t2RD59Ql0rC+4kppAl0eHMuXNFMnWp6O7OoDJ29HPLW5Ha9SiU+YG3uXjxYok1Hu7cuZPJkyaRK5MhEgqZMXMmI0aM+KixvubP/n/Km/uvQcOX5KsLkv9OXFwcs2fPpn79+u/NJmuC5C9PWloaCoWi2FmVNx+UNWvUICQwkI7OjsRkZvFHdAx79+9/b2e3TCbj7t27LF++HMXD+6xu+JdBQp+AS9x6HUsPFyfSc3O5GRNHYnY2o8aN/6AG8vuIj4/n6NGjZGRkULNmTapVq/be7bOzs4mLi0MqlSKRSEhMTKSCpwfTqlSkd3kXchQKvr14DbFTWfYeOMC2bdtYu2A+/j5/1SIuuBVClK09v+3e/dHzLkliYmKoW6sWLWykDPEox6OkFCZdvcXsefPo379/scb62CDZo3w5Jrm70N7JEYC4rCxq7zvKlStXcHV1RaVSkZOTQ6f27TBPSmBp3RpoCYVsfvCYn4PuqLVwW7dsydr16xGLxQwaMAD/06cx1JGQkZPLj/Pm0bJlS7p26khEZBRikRCxtoQdu3ZRs2bNIs1TpVKpHxw8ypdjsrsr7ZwcAIjJzKLu/qNcvXoVFxcXAE6cOMHYUaNISk3F1MiIJcuXU7lyZQb06cPt+/cBaN+2LStWrcLPzw/fESOoYmNFZEoqsRkZNHMoTZpMTmBMHHv27cPDw4MnT55gZmaGi4vLv0ZXV6lUEh4ejq6uLpaWluoHyn379vH9xAn4+TTHQleHHIWCjn7naP1NH3744YcPjrts2TJ+XriQrmUdsTcwYNPjUJq0bs2q1YXbgReXW7du0dbHhxnVvWjlUJo/Xr1m4pWbbN+x453mSSqVihMnTnDjxg2MjIzo1auXutTmv/DZ/7FogmQN/wa+unILgG3btnH8+HFycnKQSqU0atToS09JwwcozJUsIiKCR48eYW5ujpeX13vr6076+bF27VrOnzuHpbk5xwcN+qD5hlgsxtvbm8qVK7Pr+jUyZXL0xFok5+TwJDEJqZ4uM6t7qQODQef+ICUlpUjnExcXR2hoKFKptIDVr4WFBQMHDizSGDt27GDq5MnkyGTo6eqwdNlyHB0dyZXJ6eLyV2lJOwc7lj76E4Dy5csTlpTM9egYatpYkZCVTcCrGDo2a1WkY34Obty4gUAhZ3aNKoiEQhyMDLkdl8DJo0eLHSR/DCqVCoVCyZFn4SRk5dDR2ZGUHBmQpzcb+uQJT58+ISMrG6m5OU9ycmh+7DSG2to8SUhkxapVeHt7o6enV8DwYtuOHQQGBhIfH0+5cuVwcnKiS8eOmOVks79bO3RFIubcCmFgv37cvnfvvSogp0+fZuqkSbyMjsbJwYElK1YgFotJy5Wpt0mX5f3898xumzZtaN26NWlpaRgaGqpfu6fPnSMxMZHQ0FCW/rKI5o0bExYexlCPcoyrUhGVSsXQc39wLT6Jnr17M7dbN3WTZ1ED+s9FYmIifXv35ka+qUcZe3t+27MHFxcXoqOjKWNijIWuDpD3/qhoakx0dPQHx71y5QprVq1CplCw6/EzjPX1+aZfP74vQnBdVC5evIiXtRW9yuVJwrV1csAv8iUXLlx4Z5A8d84cNqxbR107G15mZLJx/XpO+vt/clk5DRo0fJivMkju168fffv2JTQ0lOvXr6Ovr1/g//Hx8QWyx0Kh8KOXQP8NCASCdy7Nf63s3LmTcWPHItESkZkro0WzZmzdvv2twOLNeWtpaTFixIiPWrYcOnQoe3ftovOpc3ibmXItLgFdY2NMVcoCmTOt/J8/dK337dvH6O++Iyc/iPmmVy+WrVhRrCaaixcvMmH8eGbWqEL9UjacCo9kxLffsmPnTgCCYuOpbZNXsxwcl4CNtQ0ikYjatWvj6+vLgDVrKGtuxqvUNFzKl2fChAmf/TUil8v56aef2L97NyqVkjbt2jNz1izEYjE5MjlylYo3M8pRyImJiy32HN9sX5z9ZkyfTkpqKlnaWmz/8wkb7v+JnrYEXW1tQs4G8CI5mdGVK1DbxooTYZHsDn3BkOGjMDExoX79+nh6er5z7P8NKINDQlhU3UutXDKigju79h8lOjoaJyenQscIDg6mX9++DHJ3pY6HCyfDo+jRrRu9+/Rh8fbtiIUCTHUkLLv3Jw3q1sXJyemtDG9hGbbU1FR6dOtGHSsLultacCzVhIOhLxjgXg5THQmD3F25HHCJ+fPnvzNjnJiYyA/TpnEnOBgzC3MmTpn62XV4x48dQ2r4CwI6tsZALGba9SD69u7NtZs3KV++PL/EJfBnYhJuZqbEZmZxNTaeIeXLv/c1kpKSwoC+ffGxtWJy22a8Ss9k8IUrZGVloaOjU2Jz19HRITU3V20ipFKpSM6VoaOjU+j8nj59yspVq9jevCG1bKxQKJUMv3iV2TNnsGvP3v/kZ39R+f963hr+XXyVQTLkBY4uLi4EBQWxe/duBg0apP7fwYMH2bhxo/r3/v37M3LkyC8xzRLjc2rTfmoePXrEuLFjmVndix6uzoSlptE74BJr165l1qxZhe5TFPORkJAQnj9/jpOTUwGrYlNTU24FB/PLL78QERbGwHLlaNGiBQ3q12fF7fu0cizNtegYLkS94vvu3d+7xPfw4UNG+voyzbsSPcs58yAhiUG/H6Jq9eqMHj26yNfg4sWLNLC3U2ecBnmUJ+BVLE+fPmXsmDEMX7MGHwc74rJzuPo6llOnT6vntXzFCjp17szdu3eRSqV06NDhs8pRvWH8uHFsXr+OMRXc0RYJWb5rF1lZWYyfMAGZQsGoC1fp7+7K46QUdj1+hoW5+UcvnxbVfCYkJITVa9awo3lDalhLyVEo6Ol3jiiZHCcTIzyMDTERa9HByQFbA30qWZhxIz4RS0vLjyqzMTM14VlqKk3IWx5/npLnBOjg4PDOcz1+/Dg1bayYUCU/k2st5XZiMk5OToyZOJHla9aQk5NDs+bN2bBpU5Gv2Z49eyhnbMjKenkKHN1cnWhy8AQnwyLpXb4sF16+xqF06XfWEWdnZ9OlY0dyX0fTzcmeR4nxdOncmXPnz1OvXr3iXpqP5uLFiyyqXgUHo7zVpx+qVqLxoRNkZGTQq1cvTvv7033fXspZmBOWnIJnpcpMnTr1vcHu/fv3SUlLY0rV5miLRJQxNmRgOWf2/nG5RJf0+/fvz7Ili5l45SYtSpfij9cx3ItP5NchQwo9TmJiIjpiMbXyH4hFQiH1rKUcjohUb/9f+uzXoOFr46sNkt+gVCrfWmrr3LkzDRo0UP8uFApJSkr63FMrMfT19cnIyPjS0ygxLly4gNRAnx6ueWUKjkaGdHIszeXz50n6n0BTJBJhZGREamrqO2tSVSoV30+bxrr16zHV0yMpM5OhQ4awYOFCdcZMIBC8pdqwZetWfL/9lpV3HqCnq8uKFSvw8vJ672vl9OnT2Bkb0cctr0a0kqU57R1Lc+bUKfr27Vvka6BQKMiUywucQ6Zchkwm44fp03FydubihQs4GBiwYPhwypUrV2Bef7f4zczMJDMzs8jHLglUKhVr165lQXUvtWqCrb4e/bdvp0/fvsiUSl5nZjLgzEVMJNp0KuvIhYSUQq/tyZMnmT5tKtExsZR3cWHFmjXqbG5R7v/fuX37NmZ6etSwzmsMlYhENLMvxa6IVxiLhBx+Fk6uUkmDg8fp7urE7BreCAV5yhIf8xkxdsJEJowfT1xmNkbaYrY/eU7/vn0RiUTvHC8jIwOdv2XJBAIBEpGI9PR0xo0bx9ixY9X/09fXL/K8YmNjKa2nq37NS0QizHQkbH30lBORL7kTF89vu3a/c7zTp0/z+PEjLnZsg6lO3kNXplzOzwsXvje7XtLoSHRIyG8mBEjIzgEgJyeH5ORkli5fTotWrXjy5Am2trZ06NCBrKwssrKy3jmmQqFAqVIRn5WNua4OWXI5rzMy0dHRLbHvhuTkZM6ePcuwb0dw8thRfgi+R6lSpThw6BB2dnaFHsfc3JxsmYzLL6OpV8oGmVLJ+VcxlPasQFJS0n/us784vHnva9DwJfmqguT09HRu3bpFjRo10NHR4dGjR/j5+dG9e/cC21lYWBSQBIqPjy9W08+/jbway693/v+LoaEhyVnZatMHgBdp6RiVcXnneSoUinf+79ixY2zZvJndLRtT1cqSoNg4+m3dSvUaNWjfvv0759G8eXMeP32aZ6phaopIJHrrGDk5OUz/4QcOHzqESqWiYuVKJGVmkSGToZ+/xB6dmY2Jvn6x7lGHDh1Yv3YtCwPvUM/WilMRLwlLTcfHxwelUkmPHj3o0aOH+nr925p35HI5ubm5mOv8lcE2z8/kSaVSpObmeJgZs7dVE9JkMgafv0rNmjXfukbXrl2jX9++DPUsj7dLGX5/EU77tm259McfBVzf3nf//46dnR2JmZncjU+gooU5cqWSa7HxGJubc+PpU0ZW8mCAuyuPkpIZEnCZyNQMQhOTadq0aZHvX1xcHNMmTyYkOBhTM1OGDR/Ovdsh5ObkMHL8eEaOHPnesZo3b073TZvY/TiUOrbWnAyL4EFcPEsaNXprv+K896tVq8a0/fsIiYunsoU5pyKieJKSSrv27SldujQ/dehAhQoV3jleSkoKhhKJOkAGKG2gz73k4jVN/lMGDB7MwhXLyVIoMBCLWXn/ET6tW2NmZqaeR/PmzQvU+H5ofm5ubtSqXp32J86Qkp2DijypvCk//FAi5/bixQs6tmtHVmoqumIxCVlZbNq8We2q+a5jlClThnFjxzJsxQpqlrIhOiOTZJWKE7PnoFAo/nOf/Ro0fG18VUEyQEBAABs2bECpVGJmZkaHDh1o06bNl56WhmLQsGFDyrqUpfeZi5iJtXiZkUl0RiZ7F32chFlwcDC1bKyoapVXd+4ttaS2rTXBwcHvDZIhb5XhfRqrUyZNIuDYMaZX9kAoEPDz7TuoRCIGn79CpzL23E1I4nzUK46tG/TOMQqjYsWK7Ny1i8njx7P98RUc7e3Zu39/gSbAfzNaWlrUqVWLxXcfstzQALFIyMLge1Rwd8Pa2pptO3fSp1cvDu46hFKlonLFCiwqRKJu3969NC5dinFeFQCoY2tF06OnOHXqFP369QPyAozFixdz7NAhBEIhnbt3Z9iwYYXWgFeuXJlvevemz7591CtlTVhaBglKJb6Dh7Lq55/wreiOQCDAW2pJd1dndj19zuatW3FzcyvSeWdlZdGlY0e0khMZ7uzI05RU1q1dy67du2ncuGgmLA0bNmTRL78wbcoUcq4HYaCnx/oNG4rlllgYPXv25HZIMN22bkMi1iJXrmDGjBlFLjWrXLkyyVnZbHn4mH5urrxITePA8wj6Di9cO7kkUalUpKamYmBgwPjx49HS0mLn9u0oFAqadejI7Dlz/tH4IpGI6rVqcv/2bdY2roudgT5LQu6z9ddfGTRo0D/W8R43ejROYiFrO7VGWyhk1Z0HDB86lPsPH77VM/O/TJ02De+qVblx4wYNjIzo3r37W7bgGjRo+DJ8VUGygYEB8+Z9fvF6DSWLRCJhy/YdNGnYAJVCQZPStlyNiWfqpImcCjhb7CU2ExMTItIzyFUo0BaJkCmVRKZnUOsfivjL5XL27N3L6ga1aVzaFgBjiTYDAy5hUacOGx4+RCqVcuDgQapWrVrs8Rs1asTN4OB/NMcvyep16+jTqycNDh4HwNXZmV3bdyAQCKhatSo3AgO5f/8+urq6eHp6Fqq/m5ubi4H4r48hkUCAnliMTPaXysOE8ePZsmEDQ9xcUKhU/DTvR1JSUpgyZcpb4wkEAhYvWULNWrUIDg6mgqkpffv2JSgoiFxVXvnAmxWAuOxsGjdtSvPmzUlISGD2zJk8uHsXSyspE6dMLVQ95cqVKzx//pw/OvtgLMmrFU3LlbFpw4YiB8mQZ3fevXt3EhISsLS0fK82cVERCAT8vOgXBg4azKtXr3BycsLR0bHI+zs5ObFy9WpGjRzJouB7yBQKWrdsWaD845+QmJjIqlWriAwPx9nFhZEjR2JgYMD169cZNmQwr17HoCORMH3GDMaOHcuECRM+Sv7vDSqViitXrhAVFUXZsmU54+eHb0U3mpTOqx9fUq8GXrt/5/79+1SvXl29n1wu59ChQ4SFhWFvb0/nzp0/eH8ePHzAHC9PJPllNN+Ud2HFnQdERkYWyXr+fzPjGjRo+HfwVQXJGv47HDlyBCORiEOtm6In1iJDJsPn5Fl+++03vv322wLb7ty5kx3btqJSqWjfsRPdunUr0J3fs2dPNq5bx4Bzf1DfWsrl13GkIqBXr17/aI5KpRKFUomh9l9fkAZiMSqVinUbNnwwQ/Rfx9raGv8zATx79gylUomzs3OBYMLIyIjatWu/ZwRo1rw5Iw4dooGtNVWkFhwMfUF4coq6USwnJ4cVK1eyukFtmtrnBTel9PWYvno1kydPLlSlQSAQ0K1btwLa6Q0bNsTSyoohF67S3dmBR0kpHHsRzv6fF5OZmUnHdu0QJCXS3sGO+5F5JR8n/PyoVKlSgbEzMzPR0xZj9LfXhJWeLi8/ohxGIpFga2tb7P0+RPny5YsUmBVGp06dqF27No8fP8bMzAxPT88S0U5OSkqiRdOmiDMzqGpuyoHLlzh18iQbfv2VXj160La0DT2qVeJufCIzZ0zH2tqajh07fvTxFAoFwwYP5qSfH1JDA6JTUrE0NUVuoPvXNioVKpWKly9fIpPJEIvFyOVyenXvTtCtm7ibm/EoMYl9u3ez98CB9wbKluYWPEhIUtuZ309IBCiSwYkGDRr+vWiCZA1fhNjYWFxNjNDLzyLqi8W4GBsRGxtbYLvVq1czd/Zsupctg0AA48eMITY2lu+++069jVQqxf/MGebOns35F89xqFadtTNnvtf2uShoa2vToG5d5gff4+da3ggFAn4MukvtGtX/3wfIbxCJRG9ZPReHDh06EBYWxvgFC1AolRjo6TFqzBji4+Oxt7dHLpejVCqxM/jretsZ6pOdk4NMJity57+BgQGHjhxh4vhxLL57D3Nzc7Zt2079+vU5evQoURERXOjYCiNtbVQqFcNyr7Bh/XpWryloMlGlShUy5QpW333IUM/yhKaksudZGANH+H70Nfi3YW1tXeLL/Zs3b0aQkc7BVo3R1dIiJSeXVsfPsHTpUgy1RMysXgWhQICbmSl34hM5duTIPwqSd+zYwYWzZzni0wwXE2MCY+L45vQF1txPx1pPF1sDfZbdvodYKGTo0KGULePIzt17uHr1KrcDAznauimlDPSJzsiko99Zdu7cyYABA955vO9nzmTAgP68zMjERFubg8/DGT5s2FctPapBgwZNkKzhC+Hm5sZvW7cSmpxKWRMjnialEBgTS5e/1YaqVCoWzJ/HzGqV6ZavhOFuZsqshQvx9fUtUJNqZ2fH+r/J/pUUa9avZ2C/frQ+4g+Ad+XKbPh1c4kf5/8zY8aMYfDgwVy4cIHxY8ewYtkyli1ZQhlHBw78fhg3V1eW333IkrrVkStVrLz3iCqVKhVbGqtUqVLs2rP3rb+npKRgpqeLUf54AoEAR0N9XiW/rUZgZ2fHxk2bGD50KMtv5zncdWzfnjFjxnzEmf//ISYmBndjI3TzLc+NJdqUNTEmNTUVuULBjdex2Orr4WBkiOJvLoQfy927d6lvI8XFxBiAqlaWeFlL0XZ0YnpgMNnZ2Rhoi9nUpB7OJsZ8n6/F3KxlSypZmFEq/6HMRl8PL0tznj179t7jtW7dmgMHDrJz+3YSsrOZPWiouqZegwYNXy+aIFnDJ+X06dNsWr+OzIwM6jZsxPjx4xGLxfTo0YOzZ07T4eRpHEyMCU9OoXWrVnTp0kW9b1ZWFplZ2ZQ3+6u2uLypCdm5uWRmZmJgYPDJ529pacnREyfUMoM2Njb/Guve/xI6Ojp8P2UKjSzNmdu2OdlyBcMvXmWU7wgOHj5My6ZNqbzrECrAycGePSX4QFSlShWiklM4GPqCzmXL8CwllaPhUXzbqXCr+5YtWxJy5w5Pnz7FzMwMZ2fnEn1NPHjwgGPHjqFUKunYsWORmwo/B6mpqTx//hxTU1McHByKvJ+rqytH9+0lMi2d0oYGPElK5nZMLNopV0lNz6Df6QuogOpWlgTGxrN1xux/NE9zc3MC09KRKZWIhULSZTIi09KZ0LEjhw8fpoyDA4tqelPbNi9jPr1qZZr+foKOBgY8TEpWK++k5OTyIDGZBnZ2HzxmvXr1Poue9PXr11m0cCHxcbFUqFSZ2XPnaso6NGj4RAhUKpXqS0/iU/N3972vkX+jBFhROH78OIMHDaKbixNSXR12hb6gTuMmbNi0CUG+G1VAQAARERE4ODjQpEmTt4KN2jVq4CZQsrB2NQTAtGuB3M6VM3na92zesIHsrCwaNm3KpMmTv4ihxufga73/7yI1NZXLly+Tm5tLjRo1sLW1JTw8nKpVq3Kxsw+2+Vm8C1GvGHXlFplZWURFRRESEoJQKKRixYro6up+4CjFY9u2bUyeNAmJlhaZubm0bdOG9Rs3lkhDXXE4d+4cfXr3xtPSHLFQSGB0DGvXrftHpQclxenTpxk2ZAjp+ZrcXbt0ZsXKVWhpfTjXIpPJ6NOrF9evXcXRxITQhESUSiUypZKf61anvZMjQbHx9D9zgY5durJq1SpEItFHN+69fv2aJg0bYq+tRTULcy5ExyAzNOT02XMYGhpS3sWF8e4udM23f78dl0DXkwGEhIQwoE8fYiMj8DY3JTghCVPbUhz38/siJVb/+94PCgqirY8PbcvY425qzKEXkWBmjv+ZMyX+nvjSvLn/GjR8STRB8lfA1xokNWlQn5pCFRO985qfHiQk0eH4aa5fv15kqbMHDx7QrXNnZFlZCAQg0NZmwKDBLFu6lAFuLphJJGx98oyaDRux8ddf/5NZ3q/1/hfGixcv6NyhA8mJiWiLROSoVGzbsYMKFSrg6urKtuYN1XbcWx8+4dewKKJjYz9a4aA4RERE8PjxYywtLalUqdIXeS15VaxIS3NjJue/Z9bf+5P1j5/x9NmzL2rT+/LlS2rVrMEAV2eGV3DjSVIKwy5eZeio0YwbN65IYygUCk6ePElUVBQrli6lgp4OcdnZ/O7zl6rD5Cs3EXtX/8dBMkBUVBSLfv6ZlxEROLu6MnnKFLXb4IIFC9i4Zg3jK3lgINZi+f1HVKhZi207dpCZmcmmTZsIDw/H3t6ewYMHf7EehP997w8bMoT0kCBWN8xriE3JyaXh7ydZvWEDrVu3/iJz/FRogmQN/wY05RYaPhlJSck4O5VW/17WJE/aLTk5uchjVKxYkft//snx48dRKpXUrl2bdm1aM7KCG76VPACoYS2l07FjzIyKonTp0h8YUcOXZMx33+EghJOd2yARifgp6A6DBw7k3oMH9O3ThzEHDzCgXFkyZHK2PHrKnB9/LNb4KpWKbdu2cS4gAB0dHb7p25f69esXaV97e3vs7e0/5rRKBLlcTlR0NE0r/1Ve0dS+FL8E3yUxMbHEm8Cys7OZPHEix44cQalSUbN2bbZs3VpoRjIoKAgdoYgxlfPULipZmtOzbBkunjtb5CBZJBLRtm1bAJYtXoxUT5c/k5LJUSiQiESoVCpeZWbhaWhYIudnZ2fH8hUrCv3fpEmT0NLSYtP27cjlcpq18WFuvryonp4eo0aNKpE5lDSpyck4/q2J1ViijbGuDqmpqV9wVho0/HfRBMkaSpz4+HiOHDmCobEx6x88oXFpW4y1tVl95yGG+vqULVu2WONZWlrSoUMHdTYpLTUNe7u/uu/tDfNqk4v6RfFm8eRNpjA1NZVly5bx9PFj7OztGT169Du7+1UqFREREaSlpeHk5PSPTQj+v3H33j1+qVkFnfwl+oHu5fj1wWOioqL46eefsbW15Yy/H2IdPX5ZsoTevXsXa/wZ06ezY+sWOpVxICU3l65dj7Jly9avIsumpaVFKWtrzkdF4y3NC4jPR77CQE9PnQEtSUb6+vLH6VPMrFYZgHlXrtC8aVMuX7ny1ra6urpkyWSky2QY5jc4xmVloWf+cQoytWvXJuTmDVTA4IBLtCljz43XsdxOSOLnYti7fywikej/2DvvqCjOLg4/uyxLB+kgTUQQbNgVRbGAiNiw95ZorLHGFmuiJpbYjWIsWIhYAnYURewlNhRsgA0VkCq97u73B0rCByoIosZ9zvEcGd5yZ4bZvXPf+94fP/zwQxGp+s+dxs2a4blqFd2rWWKlpcGusIe8TE2jfv36n9o0OXL+k8idZDnlypMnT+jUoQOi3Bz0VJS5n/yKpnsOoqYkRoKATVu2oKWlVaY5GjdpwpZrV2lW2RAtsZgVwaHoamtjaW0IFjgAACAASURBVGn5zn45OTnMmT2b3T4+5EkkuLq48POiRfTp2ZOsuFhaGupzOfgGRw8d4sSpUxgYGBTqn5WVxcgRIzji7w+Ano42Xtt30KRJkzKdz9eErrY2D5KSCwQdHiTlryro6OggEomYPGUKk6dMKWhfmpSHuLg4Nnh6ssXZiRYm+S85ldVUWTB/3hfhJAMsW7GCwQMHciMhCUWhkCtRMfy+fn25p1rk5ORw6NAhNrZpgZOpMQBaYjEjAs9x8+ZN6tWrV6h98+bNsbCw4Jugi/Svlq80uC/iCTvmlS7S/4ZlK1bQr3dvwm7dIiEzi9sJSdjY2nLg4B+fxUbFxMREli1dyqPwcEyrVGHKlCmfhQre2LFjuR0cjNuBoygpipDKYPmKFWUqwyhHjpy3I3eS5ZQrP86YjpWSIhtdnRArKHDw0VN+uPA38xf9Qtu2bTE2Ni7zHEt++43ePXrgsOcgikIhampqbNu5871R3blz5nBg924WNLRHRSRiycUL9OnVi5fPnxHQ2RVNsZgciQSPY6fYtGkTAwcOZMa0qdy/ew9DQ0OMTU25ceE8+zu2w0xDjWU3Qhg0YABXrl6lUhnV/b4Wpv34I+PGjiUqPR0NRTE+EY/5bsSIcsk9fLP3oJbuP2PV0tVh99MQUlJSEAqFFVIRpSw4Ozvjf/x4QXWLhR4e1KpVq9znkUgkSGUyNMSKxKRn4PvwCRGvkpEBjx49KuIkq6qq8tf+/UydPJnlwTfR0dZh0+bNuLi4fND8urq6HDl2jDt37pCTk4Odnd1nc29SU1Nxb++KQmoKLY0MuHLvLq7HjnEyKOiT1z1WVFRki5cXt2/fJiEhgerVq2NiYvJJbZIj57+M3EmWU65EhIUxzKwy4teRr46W5kw5fwVLS8tycZAB9PT08A8I4ObNm2RlZVG7du33LkfLZDJ2++zipwb2uFvm553qqSjR/chJ6hoZFtTIFSsoYKelybNnz+js7o6ZEEZamHIzPpGDR28xuV4dar52wmY3rsde77+4c+cOzZs3L5dz+6/Ts2dPNDQ08N6xg7jsLGb2H8Q333xTLmObm5ujrqrKzvvhjLWvSY5Uyu6HTxAKBAUbRV1dXPh9w4ZSS59XJHXq1KFOnTpAyTdtxsTE8OLFC8zNzUvkyKmoqGCkp8ePF68Sl5mFvooyhqoqKAgEnD1zhu7duxfpY2hoyLadO0t/Qm9BJBIVUTQ8d+4c82bPJiYmGltbO/7YsqXCHVMfHx/SExLx7+iMmqIi2RIJHv6n8PLy+izSMwQCQZHrJkeOnI+D8P1N5MgpOZVNTLkSG1+Q93v1ZRwymazc5XfFYjFNmjTBycmpxPmaEokUlX8tW6so5L8j3o1P4HZ8AgCRqWmcj4lFJpORk5bKxlbN6GFdlYUODVEViUjMyiron5ydQ55UirKycjme2X+f9u3bs8Pbm937/mL48OGFRGHKgpqaGhs2bmTjvXBaHzxOS9+jXI+NR0dBiK+7C7vd2hJ+/RoTx3+aTVlSqZT169fj5uKMm4sLGzdupDyKCy1ZsoTatWvTvn176tSuzebNm0vUb5u3N5Fp6dTS1eZQZ1e82rVik3NL/ty1673iGR+D4OBgevfqRR1JDjNqVkfh2VOcWjgSFxdXoXbEx8djqaWB2uvyf0oKClhralS4HXLkyPn0yCPJcsqVuT/9ROdOneh/4gzGqioERL7gu+++e2++8MdGIBDQ3tWVxWfPoKuijJpIxOyrN6lXpw616tSmzy4fqmhX4nlKKo4tWlCvXj1Czp4p2GAG+dU5NobeR0UkwlRdjc33I6j3r6ifnE+Pq6srZ8+f5/Lly0gkEiZOnMhi55bU1st/kfqxfm1GHT+OVCp9q3OelZVFamoqenp65VoGbtHChWz29GSYnTUymYyF8+eTlJTEtGnTPnjMQ4cOsXL5cja0ccSxshFHHkcyY8YMatasSdOmTd/Zt379+liYm9NWXxvR62vhWNkIJUURT58+LXGZxvJix44dNDM2ZG6T/E1o7cxNcDkUwNGjRxkwYECF2VGrVi1+X7OG2/EJ1NHTJeJVCudjXjKvdu0Ks0GOHDmfB3InWU65UrduXU4GBrJjxw7S0tL4bZIDPXv2/NRmAfmbhUaOGEHPoycBqG9vj9f27RgbG+PRrTvh4eGYmpri7OzMnTt3mDtnDrseRNDTuirBcQncjkukiqY6nqH3kAJtnF1YvnJlsYITT58+5fr166ipqeHo6PjJ6qx+jVhaWmJpaUlqaioTJ04kTyot+F2uRIpQULxzLJPJ+PWXX1i1ahUSqRQTYyM2b/WiQYMGZbYpLy+P33//nWXNG9GhSn66j4WGOrPWrOGHH35AKBSSnZ3NiRMnSExMxN7evkRL6ufOnaOtuUnBRshu1SzZ++QZFy5ceK+TDGBlbc2Ze3foW90KkVDI+agYsnPzSqWmV15kZWaiq/SP1LhYQQEtJSUyMzMr1I6OHTtyuk8fev/pjYmWFtEpKbi1d6Nfv34VaoccOXI+PXInWU65Y2Njw88///ypzSiChoYG3rt2kZSURF5eXqFI4f9LytauXZvfli/nhylTmHP5OgB9bKryU9OGZOTl4X7kJE2bNUNZWZk7d+6gra1dkFJy9OhRvhs+HA2xmIzcHCqbmOJ74MBnsTv+a0JDQ4N2zs7MuHKdH+vXJkcq5afrt/Hw8Cg2iuzl5cWGdetY0aIpNtpa/HHnAX179+bCpUtlzovNzMwkNy8Pi3/VALbQ1CArO5ucnBxyc3Pp1rULEQ/C0FdX42liErNmz2bmzJnvHFdNTY24rGxkMhkCgYA8qZSEzKwSlyac99NPdGjfni7+pzBRU+XCi2gmjB9f4VFkAKdWrZi0348OFmY0MNTDN+Ix4QmJxeb7x8TEsGfPHlJTU2nSpAnOzs7lZodAIGDZb7/RvUcPHj16hJmZGS1btvxPChXJkSPn3cgV974A/kuKa6WlrKpbZSU2Npbp06eTeOMaXs7/iFJ8E3QBnfoNOXPqFEmv6zP36dWLufPn06BePUbYVmN0nRqk5ebxTdB5TOo1YOv27R9kg/z+f/j9T0lJYcK4cRwLCEAoENCtWzcWL11arGBGj65dsX6VwLSG+RHcPKmUJvsOsXr9Btzd3d85j1QqJTY2FjU1NTTeIobh6OCAeV42KxybIJXJGH/uCvFqGpw6e5ZZP/7IiX17+dOlJbrKyhx/+pzvz1zk76tX3xnVDQsLw7ltG9qbVqa5kQHHn0dx/VUqp8+eLbRRNjg4mGlTJvP4yRPMzcz5ZckSGjVqBEB0dDS7du0iNTWVxo0b4+bm9t7r+jGQyWQs+PlnVq9ZA4CSoiJ/bN6Mrq4uS3/9lcT4eOwbNGDwkCH06dkTLQEYqalyJSqaSZOnfBab6sob+bMvV9yT82mRR5LlyHkHBgYGtG3bltknThD+KhnrSlrcS0ziakwsAn9/eltVYXSdNjxKTmXU4cMoisVkZGXxbS1bBAIBGmJF+lhVYW1w8Kc+la8STU1NtmzbhkQiQSAQvHOToIJIgVzpP464RCZDKpW9d2PhvXv3GDxgAI8jIwEYOGAAi5csKZKGs2nrVnr37EH9XX7IACNDQ/Zs2QJA6O1bdDCrjO7rTaCuFqboq6sTGhr6TifZxsYGv/0HmDNzJsvDH1O1qhUHdy4t5CA/fvyYbl270tbYgKH1anHmRQzdu3lwMvAUNjY2GBsbl1g172MiEAiYPWcOw0eM4OXLl1StWpXo6GicWraks6U5DpW02Od/lCOHDlJDQ52NrZujKBRy+nkUw5csoUePHp9874McOXL+W8idZDly3kPfvn0JOnkSjyPHMNXS5FlyCo2bNOHW9WtMb2iPUCCgvoESA2yqcjb4JpAvklFHTzf//6+S0dEtf8W0x48fM2HcOEJDQ9HT1WX6rFl4eHgUapOeno6Pjw8xMTHY2tq+NdXgv05JxDh69unL92PHYqmpgXUlLbweRKBZSYtmzZq9tU9aWhp9evWkjooSGz068DwtnSl+vugbGDBjxoxCbW1tbTl/8RI3b+b/jdSvX7+gNrCBoREhN64VpE08T0snKTOjiKBNcTRo0IAjx4+/9fe+vr6YqamwuFkjhAIBruamRKSms2/fvvemc3wKjIyMMDIyIiIigonjx+NqbsLi5o0B6GJlQYu9h7Aw0kfx9d+xk4kxYgUFnj59KneS5ciRU67InWQ5ct6DUCjkjy1bCAoK4tmzZ1SpUgWJRMLA/v1J/5dMb1JWNlq6BvTs0Z1vjx6lt1UVXmZmceDRE3bsKL/6sgDJycl4dO5MVUUhixvX425iEiO/+w4NDY2C/MzU1FQ6urmREPUCa20tNr2M59iRI2zcvPmzy6/ctm0ba1asIDUtjSZNm/LbihUVXh+3R48eJCUlsfTXX3mVmkrtGjXY673xnQqRd+7cIfplLMf6dUNFJKKKpgbf2dmw//ChIk4y5C+ft2zZssjxiZMn4+bqytDAc9hoaeD/LIrmzZrj5ORERkZGkfYymYzMzMwS5R5nZ2ejJRYjfH3PBQIB2kqKZP2rnOHnxpYtW5g5YwbKIgWG2FoXHNdVVkZdrEhwfBISqRQFoZBLMbHkSCSYmZmVed60tDS8vb2JiYnB2tqa3r17l7vaoRw5cr4c5E6yHDklQCAQ0KZNm4KfMzMzsaxShW+DLjK4elUevkrhz7CHbNo8k/bt27POdh3ngoJQM9Fgz69LcXJyKld7Tp8+TXpKMr97dEBZJMLZ3IQX6Rl479hR4CSvXbuWjNiXHO3ogqZYTPirZLodPcbx48dp3759udpTFnbt2sXM6dOZYF8TU3ULNgXfoE/PnvgHBBSbO/wxGT58OMOHDycvLw+R6P0fjyKRCJlMRrZEgsrr9lkSCQrC0jlWdnZ2HD9xgt/XrSMqPp7BnTwYN25csQ6aj48Ps2bOIDk1DVNjY9Zt2PDOaLeTkxOrVq5kb/gj2pmbcvpFFGefRTGyVatS2VgRSKVSFi1axPo1a6ihrYWFhgb7Ih7jYWWJuYYa3g8iSM3NIzIrm27HgqispsLZ51GMGzu2zJsN37xUJkVHYatdie2xcfgfOcK2HTu+ytUXOXLkyJ1kOXI+CBUVFfb5+TF54gQW3LiBlpYWa9aupWPHjgCMHz+e8ePHf7T5c3JyUBaJUPqXE6UlVuR59j/RwUcRETjo6xaoCVpX0sJKR5vHjx9/NLs+hG2bN/ONnTXDa9kC0NhIn6a7D3Dr1q1CZcyuX7/O4kWLiHv5kpp16jDvp5/Q09P7KDaVxEGG/Jq6ttbWjD5zidG1bIlKS2fDnQfMnDOn1HNWr16dVatXv7NNUFAQ47//nukN7GloqI/vwyf069OH02fPUqVKlWL7NG/enF8XL+bHmTOZefEqCkIh8+bPL/TS9ymJi4tj06ZNxMbGEhERwe3r1xloZ82r7Bz8Ih5TQ1cbZ78jKCkoIBMIWLlqFc2aNWPXrl2kpKTQr0mTgueuLKxfv560lzEcdndGUyzmaUoqXY4GcujQIbp06VIOZypHjpwvDbmTLEfOB2JkZIT3Lp9PMnfTpk1Jycnlt5shDLaz5l7iK/Y8fMLsQcMK2phZWHDswnkycvNQVRQRmZrGk1fJ5bIsXZ5kZ2VRSeOfiLGmWIxIKCQnJ6fg2K1bt+jSqROu5iY46FTi4JnTdOnYkYDAwAqvQX358mVOnTqFkpISXbt2Zfe+fYwZOZIRQRdQV1VlwpQpjBgx4qPMfWD/flwtzBhaszoAtXS1uRAbz8mTJ/n222/f2m/o0KF069aNFy9eYGxs/NlUDXj58iXtnJ1Ry83BrpImdyJfYK2lwQ/166AgFGKspsrhR09pbGSA0LwK6z09MTU1BWDq1Knlasvjx49poq9T8FJpoamBjY42T58+Ldd55MiR8+Ugd5LlyCkjoaGh7N27l+zsbNq0aUO7du2Ii4vjzJkz5OXl4ejoiKmpKfHx8Vy7dg2RSETTpk0LNm19CGZmZmzdto3vvv0Wz5B7AIz87juGDfvHSR43bhxHDh6ks38gtpU0+ftlPA7Nm3+yEl9vo7WLC5u9vKhvoIeZhhrLb4aipaVJrVq1Ctp4bthAMyMDljVvjEAgoEc1S1rt9+fkyZMVGuXbuXMnkydNorGJMak5uaxZtYp9vr74HTxYsOnu38hkMmJjY8nLy8PY2LjMy/YymQzh/6WTCyhZfrmWltY786s/BatXr0ZbksdutzYoKSgQmZpGxwPHOP08mrbmJthqV2JTxn1isnM4vHNRgYP8MbCwsOCvwJOk5uSiIVbkWWoaYQmJ/LV3L4f8/GjYpAk/zppVpudWjhw5XxZyJ1mOnFISEhLC8mVLiXv5Eh19AwIDA6mnr4eWWJFBW7fy3ciR7PXxQZaTjaJQSGqehFlz5rD4l1/IzcoiTyrF0NCQfX5+b10iLwlt2rTh9p07vHjxAh0dHXR0ClfQ0NbWJiAwkK1btxIdHc1MOzsGDBjw2W1EmjZ9Oi+ePaPngQMAGOjqsvPPXYUcupTkV5irqxY4oRpiMToqKqS8rlFdEaSlpTF96lTmNqlPv+rVkMlk/Hj5Oj9MnEjQuXNFHOTk5GSGDxtG0NmzANSuYcd27z/L5Oh16tyZAbt3s+NeOA0M9fB7+JSYjIzPJnWitDyPjKSBnnZB2pC5hjrGaqq8SE8nMy+PHffDqaStzU4fnxIpEJaF0aNHc/jAATodPYmdthZXY+LIycvDLi8bKzUl9vj+xZ2QEHwPHChxOo4cOXK+bORiIl8A8oLyH19MJCsrCyUlpfdWfbh79y7tXV1xNNSnlk4lNobep0tVC+Y1qY9AIODQo6dMPncZZ3MzVjk1RSQQsOBqMD5hD/GwqsL8JvXJlkgZc/YSeUaVOeTv/17bvpb7Hx0dTUpKChYWFii/rhf85v7Pnz+f1UuWsNO5JdUqafJXxGNmXb5O4KlT1KxZs0LsCw8Pp1mzZlzq1QU9lXz7Tj2LYvLl6zwuZkn+26FDuXPxAsuaNUJVJGLW3zfI0tblZFBQiauLFHfvd+7cyayZM0nPzMRIX5/fPT0LqUV+Sfz8888c2rGdva6t0VISE5qQSI8jJ1FXUkIK6Orr43fwYKlfLHJzc7l69SppaWnY29tjaGhYon5paWls27aN6OhozgSdooY0r6D8XEx6Bq18j+Dr5/fOjZLlydfy7BeHXExEzueA/HVYzlfNhQsXGDtqFM+jo9GpVIlfFi+mW7dub23/+7p1NNbXYZ2TAwKBgD9C79OislGB09O8shEyoK2pUUEdV1dzE7bfC+O7WrYoCIWoCoUMs7Vm1JmLRcaXSCTIZLKvMlJlbGxcSATj34wePZrgGzfocPAgyoqK5EmlLFm6tMIcZMjPQVcUiTj9PIoe1lWRyWSciYrGzNSk2PYBJ0+wolkjaurmf9HPb1QPtwP+xMbGlthpK44BAwbQr18/0tLS0NDQ+OzK+ZWGCRMmEBgQQPvDAVTV0uJ2bBydO3fG1c0NFRUVunbtikQiKdULclJSEr179OB2aChKIhECBQU2bdlSIulqdXV1xowZA0B7Z2eqKvwTQzJUVUFVLK7Q1Qs5cuR8Wr6+b2I5cl7z8OFD+vbpTU9LCzrVq8mVmFhGjRyJoaEhzZs3L7ZPUmIC1f7lmFTV1ODIk0jamFVGKBDg/yQSoUBATEZmQZ9nqWn58yWnYKahXvD/SlqaBW3S09OZPHEiB17ntrq5urJq7Vo0NTX5EomPj+fq1asoKCjg4ODwVqnmkiISidi4aRPjQkKIjY2levXqFb4BUUNDgwULFzJzxgyOP48mJTeXu4mv2L1nT7HtxSJF0nPzCn5Oz80FKKLE9yEIhcIv9m/j32hoaHD0+HH++usvYmNjGWNnh5ubGwKBAAUFBTQ1NUlKSirVmLNmziQz6gUXenRCR1mJFTdDGPHtt1y/ebNUkcmGTZqwZ89uOlmaY6ymysbQe2Tn5WFra1va05QjR84XitxJlvPVcuLECUzV1ZnVqC4CgYC6+rrcjE/kwIEDb3WS6zdsxJa1V+hnWw1zDXVczE1YGRzKveRUtJSVuBUTS99+/VizaxfP0tJRVlBg38MnNGrYkEkXrjLIpmp+ruWDhyxYtKhg3MkTJ/J30Ck8WzdHKBDw85XLjBk1ih3e3hV1OcqN69ev07d3b/Kys5BIZejq6bHPz4+qVauWaVyBQECdOnXKycoPY9iwYVhZWXHq1CnEYjGrund/q9PUp39/Fu3cgUwmQ0UkYumtO7Rzdi6SO/61o6qqysCBA8ttvGt/X2GYtSW6r1NixtWtxfqQe4SFhdGkSZMSjzNj5kzuhIbQ2vcIIqGQXIkEGdCubVt+9/QsUWRajhw5XzZyJ1nOV4tUKkXh/5aqhQIBUqn0rX3GjRvHtStXcN3vj5aKCkmZGUycNAl1dXWys7NZ6OREw4YNcXNzY4+PD5l5eSwbO56ePXuyYcMGjh85gkhdkdVrJ9KjRw8gP8XiwMGDeLZuTkuT/HSDhQoK9D0WQEZGRpmjsBWJRCJh2ODBOBvq8VOT+uRJpYw9d4UxI0fiHxDwqc0rF5ycnN4qDiOTydi8eTNHDx1EKBBSt0lTFl67Rp4kj3btXFm2fHkFW1s8165dw2vrVtLT0mjh5MSQIUP+M4IZWlqVePJ69QbgaUra6+Olq+yhpqbGPl8/Vq9ezeJff2WxY2Pq6+uzL+IRQ4cM4fSZM2UWMKkoUlNTCQsLQ1NTk2rVqn3RKTpy5FQkcidZzleLs7MzvyxcyLIbIXSuas7lmFgCI5+zp1Ont/YRi8V4+/hw+fJl4uPjsbOzw9raukg7V1dXXF1dCx0bM2ZMQb7jv5HJZK9Le/3zxfXGef/S9tXGxsYS9fIl3zVriEgoRCQUMsy2GsNOnuXy5cvExMRQvXp17Ozs3jnOvXv3ePLkCZaWljg6OlaQ9WVnwc8/s3mjJwOsrUjPzWVX2EPMKlfGwtKSXn36fBblw86ePUvvXr1obVoZQ2Ulfg4M5P69eyxZuvRTm1YujJ88mW+GDSMrT4KRqgre4Y9p7+JC9erVSz2WgoICEeHhdLY0x8PKEoBJ9WoTEPWS06dPfxFO8tmzZ/lmyBBevd4A6OrszB9btlS4mqUcOV8i/43QgRw5H4CNjQ3bduzANyqGjgePsyLkPitWrnyvhLRQKKRZs2Z07ty5WAe5tIhEItxcXfn5+m2uvYzjZmw8c64G08bJqdyEMjIyMvDy8uKXX37Bz8+vULT85s2b7NmzhwsXLpTZKX+zkSwiObngWFjSK8QiEV27dGH6xAk4OTnx27JlxfaXyWTMnzePli1bMmbECFq0aMGE8eO/iJeFzMxM1q5bxxKHRkyqX5tnaenoqyjTw1AX49ho+vXty4kTJz66HTKZjC1bttDF3Z0u7u54eXkVun4L58+nt3VVfm/VjLlNG7CxdXO2enkRGRn50W2rCNzd3dm2fTtPdfQ5lQfdBw3ijy1bPjh6KhKJyJL887xIZTJyJJIvYnNtQkICQwcPwsOsMqEDenC0S3tC/r7CooULP7VpcuR8EXz+T7kcOR+RNm3acPf+A5KTk9HU1PxkS86r1q5lzKhR9D2Wn5Lg6OBA9169CAgIwMXFpVRf8FKptNB5pKWl0alDB2KfP6NaJS08Y+M5duQIG/74g/nz5rF+/XqMNDWITU3DvUMHPDdt+uBayurq6owaNYopmzcz0CaBLImEbffC0VAS49vJlWqVNAl6HsWopUtp1rw5Dg4OhfofO3aMjZ6e7HRtTRMjA669jGPo+vXY161Lp3dE+D8HUlJSkEqlWFfS4l5iEmdeRHPSwx0LzfzosaJQyJoVK3BxcfmodixdupS1q1YypHo1ZMCcH38kPj6eKVOmAPnR/j7VzAva19HTKThubm5e3JBfHMWt5HwoPXr2pIePD7/f1qK+vi6+j56SJpF+9PtYHoSEhJCVmcW0BvkKhtaVtBhsY8XhM2c+tWly5HwRyJ1kOV89AoGASpUqfVIbNDU12eHtTXp6OtevX+fboUOZMWUyeRIp+gb67PnL970b3wIDA5k6eTLPo6Mx1NdDp5I2KSkpKCgqIk1J5qi7C1pKYsKTkul29ChLly5lo6cn29u1oomRAeGvkukbEIinpyejR4/+4HOZO3culStXxv/wIUQiEQ0bamGZnEC1SvnVGFqbVsZWX4/g4OAiTvLVq1dpWtmIJkYGADQ01MfRxJirV69+9k6yvr4+lY2M2HjnPh0sTFEUCjDT+GclwFJTg2ulrNRQWiQSCatXrmRh0/p0qVoFgGpamsxasYJJkyYhFAqxq1kD3/v3aG9hhopIxK4HD1EWi8u8sfK/SosWLdjg6cncWT+y6tYdbKys2OvrS+XKlT+1ae9FTU2NXKmUxOxs9F+nV7zMyEBN/cuvjCJHTkUgT7eQ89mTkZHB5EmTsK9Vk0b16vHbb7+9c3NdaTh27BhTp05l1qxZhISElMuYb5DJZCQnJ5P7uvRXSVBWVmbsqFG0M9Ln7x6duNKzE1UEMHbUyHf2u337NgMHDKCdtgYLmzYgPi6earlZjKlqRmZ8HM0M9NBSEgNgra1FNV1tbty4QR1DgwKH1LqSFk7GBsydO5dJEyd+sHiLUCjku+++Y/+hw+zz208de3sepqYjfb3kn5qTS0xaWrHluCpVqsTztHRyXs+dJ5XyLC39k7/ElAShUMgWLy9OxSUy7twVpDJYf/suMpmMuMxMdj18QsPGJa+u8CFkZmaSnZuL1b/KC1bV0iQrJ4fMzPyyhIuXLuOFTEDr/f60O3yCJTdDWLl6tbzqxjvw8PDg9p27REdHc+7iRerWrfupTSoRdevWpb69PUMCz7M3/BHLb9xm2/0Ivh357s8TOXLk5CN3kuV89gwaMIAAP1++r1aFgZX1WbdyBUvLYZPRmjVrGDpkMNGnAwk5fJD2APBONwAAIABJREFU7dpx7ty5crA4f5mzaaNGVKtWDQtzc3799dcS5dW+fPmS6NhYRrwWHlEWiRhiW43g2yHv7H/gwAHqGugxrYE995Je0cBAj6WOTehezZKOlvmbEjPz8mv2Pk9L53HSK0xMTHiWmkraayc+TyolLCkZTbEie312sXLlynK5FsOHDycsNZ0RQRdYd+sOA06eRcfQiI4dOxZp26dPH9KFCnxz6gKb79zn26ALJMnyBTS+BBo0aMCFS5dY/8cffD9hAhvuhlF/9wFa7DuMlrkF83766aPOr66ujo2VFZ53HpAtkZAtkeB59wG21tYF+e1mZmYEnT3LgmW/MWbGTE4FBdG9e/ePatd/hZKmY4WHh+Pu6koVc3Ma1avHgdeS6xWNoqIiPnv3Yt+qNZ5PozifJ+P39evp0qXLJ7FHjpwvDbks9RfA1yxNmpSUhI2NDbvat0YkVCAjL4/wpGQ2RDzhXljYB4+bnJxMdRsbljZvTKeqFgD89PdNruXJOHuxqBJeaW12dHCgsZY6I2pW52FyKjMvXWPeggUMGzbsnX3T0tKoWrUq61s3p61ZvpKb190w/ngUyZ3799/ab968edw+uJ8tbRyZfuEKD5KSsamkha6yMo0M9Bl/7hJ6qirU1tXhSmwc9g0bsXHzZtzauUBiIu3MTbj6Mo6I5BQ2tW1Jr6MnqVrVkguXr5TpWrwhPDycxb/8QkzUC2zsajBr9uy3Ri4jIyP5ae5cnjx+TJWqlixfuQptbe2PKkv+sYiOjub27dtoaGjQqFGjQkIiAQEBrFu1ipTkZBo3c2D2nLlFql98yLN/7949evfowatXSchkoKOjze59f31xIhgVJUlf3iQkJODk6EgtNRV6WVUhNCGRdbfvsnvPHlq1alXicW7fvs3iRYt4HhmJja0t8xcs+CJSPMoLuSy1nM+BUuckJyQksH37dqKioqhRowZ9+vQpUkrm0aNHLFiwgC1btpSboXK+TrKysgBYeDWY0IQkFIVCxEIhkmIiOn5+fmzZ6ElmZhZObdowbfp0xGJxsePGxMQgkUppVvkfeeBmRgYc+PtmmW2+evUqaampLHZrjVhBATsdbe4nvsJ727b3Osnq6uqMGjmSKVu2MNAmgYy8PP4Me8TCX355Z7927dqx/vff2Xb3ASHxSUSnZ2BdSYszL6LZevcBeTIZMRmZVG9szQ/fjWLQoEEoKipy2P8YDo0bc+RxJPUM9Fjs2ARTdTXUFEWU59uztbU1m0r4eWBubs6mrVuBwo7Sp+DVq1ccO3aMjIwMmjZtSo0aNUrV/21S2wEBAQwaOJB+1a0w01TDe/9+Htx/wF9+fh+8afINdnZ2nLt4katXrwLQqFGjUtcIlvPhnDp1CklWJqvbt0KsoEAbs8o8TU1j15/eJXaSw8LC6OTujpOxId31dfC/9jcd3dw4debMF5F6JEfOf4VSOcmRkZE0btyYuLg49PX1iY2NZc6cOezYsaPQwx8XF8e2bds+GydZLBajpKT0qc34YEQi0RclKFGeqKmpoa2pSXpuHhd6dkZXWYlfr93CJ+IxUqm04Mt/x44djB41isG21dBVVmab11aiXrxgh7d3sZUhbG1tURaLOfI4kkF2NkikUvwjn2NjbV3ma62mpobktTrXGyQyGQ8fPkJNTe29S7bLfvuNqlZWHNrvh0ikyNYf5xYIj7wNV1dXNnh6MnbMGKR5eRzr6oaFpga5Uin9jp3CWksTA1UVtp4/z4YNGwqiuBoaGvQbMIB9W7cyoW4tKqursfN+OKk5uUwZMhQlJSUUFRU/mfjAm3nV1NQqvAzckydPaNe2DZkpKWgpKfFj0is8N26kf//+ZR57/dq19KtuxZzG9QFwNTfF6a/DhIeH06hRo4J2H/rsa2hoYGpqWmY7PyUf895HRUWxaOFCnjx6RLXq1Zk1axZ6enrlMrZQKERZpIjiv55zTUVFUvMkJb6X3t7e1NapxKoWTRAIBPS0rorLwQACAgL45ptvysXOzx254Imcz4FSOckzZszAwMCA69evY2JiQlhYGN9//z2urq5s3LiRwYMHfyw7y0ROTg45OTmf2owP5mtItwgPDyc0NBRtbW0cHR0LapAqKCigoa7G8CqmGKjmr1hMaVAHr3th3Lhxg4YNGyKRSPh5/jx6WFVhQt1aKItEOBgb4OHry4y7d99a1mrZ8uWM//57Dj+LIiUnl/jsHHw3bi7zta5RowZSmYyJZy4xvJYtEckp7LgfRrZEyqNHjzA0NHzvGIMHDy54nkp6/z08PEhOTmbtooVYaOZ/GSsKhTQy1CcsKZmFzRrhHfGY8+fP4+7uXtDvh6lT+fvyZVr7HkFJQUi2RIpzu3bs9fFh9uzZqKuqMmHSJL7//vsyf3GFhoYyecIEIiIiqGxszM+//PLO6JqCggJisZj09PQKX3IfO3o0psjw7OyKskjE9nthjB45kubNm6Orq1umsV8lJmKm+U/lCyM1VcQiETExMYXu9dfw7L+Nj3Xv4+LicG7dGn1kNNXX5UzobY4fPcqJU6fKJeJev3594jMzWREcSv/q1QiNT2Tfo6f8Ompsie9lfFwcpqoqBc+bikiEgZoqcXFxX83fw5v7L0fOp6RUG/fOnj3LnDlzMDHJz5W0sbHh2LFjTJ8+nWHDhrFo0aKPYqSc/zbbtm2jhaMjsyZPYkDfvnTr0oX09PSC3+vo6PIs9Z+fn6fl/19DQ4O4uDjc2rUj8vkLfMIe4nbgGOFJyVho5Od2Jv9L1OL/6d27N/7HjtFh2LcMHj+B0+fOUadOnTKfj7a2NqpqaoQmJNLLP5CFf9/E2cwEBaHwoy+V2tra8iIlheuxcQCk5OQQ9CwKKy0NUnJyyczNRVVVtVAfVVVVDh45ki+NvWUrp8+c4W5ICLqpyfi4tWFm3ZosW7yYHTt2FDvny5cvOXLkCAEBAaSlpRXbBvKjd926dME49RWLG9ejqVhIv759CQ4OLr8LUI7cu3uHrpZmKL9+YettY0V2bi6PHz8u89iNmzngHf6EqLT8qh9rbt1BJBKVKp0jPDycnt26Ub9OHbq4u3Pr1q0y2/U1sH37dlRyc/B2acmUBnXwcWlFdvIrfHx8ymV8S0tLtmzdyp+PI3Hce5BRpy8waswY+vXrV+IxmjRtyvFnUdyOT0Amk3H0SSR3XsYWWmWQI0fOx6dUkeTk5ORil6Tmz5+Pqakpo0ePJioqqlyWI+V8HURERDBt6lQWOTSkWzVLYtIz6H/yLEuWLGH+/PkATJ05k4EDBpAjlWCoqsK2sEc4t2mDjY0NA/v1IzcmmrM9OqGuKGLahb8ZFXQeRxMjdCpVem/t13r16lGvXr1yP6/5P//M5EmT8LCyQFlBAd9HkUyfMeOjp/00bdqUYUOHMcjLixp6OjxKTEIsVMBMQ51hQeexqmpVpDYx5EdtmjZtCkBQUBCxcXH49+6CskhEAwN9nqaksW+3D4MGDSrU7+LFiwzq3x8kEnIlEgyNjNjn51ds9P7w4cNoiRT4rXljFIRCnM1NeJiSho+Pz2dZUsvQ0JDg+MQCOeLguISC42Vl9py5PLj/AKe/DiMWiRCJRPyxeTMGBgYl6h8TE0Mnd3fsNdUYU9WMCzGxdOnUiZOnTlGtWrUy2/f/JCUl4ePjQ0JCAnXr1sXd3f2LXQ6Pi4ujmpYGSq9zv1UVRVhqapCQkFCkrUwmw8fHhwN//QUC8OjRk969e793DhcXF0Lv3uPFixfo6emVOkI9YMAAgm/coLu3N0qKInIlUubNn0/jxo1LNc7HJisrizVr1hB6+zYGRkaMGzfuPyNIs2LFClasWMGLFy/o1KkT+/fvL/OYwcHB7N+/n6lTpxYJVpQHjRs3ZvDgwYwZMwaAIUOGcO3aNUJDQ8s0bpUqVejYsSNr164ts42ltcnb25sFCxYQGhpa5v0aH0KpnGQrKyuuXLlS7PLo8OHD0dPTo1+/fuVWRkvOf5+QkBB01FTpVi3fETFSU6WLhSnXr10raNO3b18yMzPxXLeOy8lpdOzVmx9nz0YgEHD+wgWWOzTEWC3/A2dGw7q08T1C0rNotnt7l5usc2np378/Ojo67N29mxSplOXjJ9OrV68KmXvBokW0btuWkJAQYmJi+PviBbZERlOvYWOmzZz5XudGKpUiFAgQ/qudSChA9n+1qXNycvhm6BAaamti/PoD/3ZiEuPHjsXv4MEi42ZnZ6MhVkTh/3I1P9dUqNnz5tOrZ09eZmRhoKzEwafP+PabbzAzMytok5OTQ15eXqm/8NTV1fnLz49bt26RkpJCjRo1SuwgA/j6+qIpgHUtHRAJhXSzqkKv40F4e3szd+7cUtnyPmJiYujg6oogIx0LTQ02/P47AwYO4NfFS8p1noqidu3a7PHeSVjSK2y0K3E7PoHrMbF8U7t2kbarV69m6eLF9K1miQwZkyZMID4+vsAJeRfKyspYWVl9kI1CoZDlK1cyYdIkIiIisLKywsLC4oPG+ljk5eXRu2cPnty9h7OJISHBN3H28+NEYOBnZ2tpCQ8PZ/LkyUybNo1OnTqVW756cHAw8+fPZ+zYseXuJPv5+fHkyZP3bg7/0ujTpw+zZ89m+/btDB06tMLnL5WT7OLiwubNm/nhhx+K3Xzk4eGBv78/Xbt2LTcD5fy3yMrKIiwsDLFYjLW1NTo6OiRnZhKTnoHRa0c3LDkV3ZpVCvXz8PCgc+fORcZTVVEh9rVIAlDw/+MnT36UiFppcHNzw83NrcLnFQgEODs74+zsXHDszp07DBs8mObNmyMUChk5ciRz584t8hzLZDJCQkKQSqVMOXeFsfY1eJicyrYHD5k2a1ahts+fPyc+MYnTSa9obVqZjLw87sYnIkq5UaxdLVu2ZNHChWy984DOVhb8HRNHQORzNrZpU/4XoRxwdHTk8JEjbPPyIj0tjfkjRhVE0rOyspg6ZQq79+5FKpXi0LgRGzdvwcjIqMTjKygoUL9+/Q+yLSMjAz0VZUSv759AIEBPLOaYvz9z5swp1yjv4l9+QUeSy053Z5RFIm7GxtNnqxc9e/WmQYMG5TZPRdG3b1/Onj5N10OHMNLUIDolhX79+hWp2y2RSFi2ZAk/Na5X8BJfXbsSC379ldGjR1dIJL1mzZqfbWT2xIkTBN+4yfHOrhipqSKRShl48iyrVq1i+fLln9q8MvHgwQNkMhnDhw//rJUoMzMzC6qLrVy5kr59+xapNvalo6CgwJAhQ1i9evUncZJLlZM8adIkVqxY8c68w1atWnH58uXPprKFnM+Hu3fv4tC4MW3btqVFixZ06tABOzs7GjZoSP+TZ1kdHMrYM5c4/SKa7ydMKNGY3373Hb/euM2m0Pv4hD1k4oWreHTp8skd5M+JlJQU+vTsiZ0QjnZuz5qWDuzYspn169cXabt7926WLl7MMDtrguPicT94nPFnLjJg6FBGjBhRqK2KigoC4GeHhqxv48i2dq0YXMMGwVvUEO3t7Vm7bh3LQ+7RdPcBJpy7zLQZM4oVFflcqF+/PqtWr2bTli0MHjy4wDGaO2c2QUeP8EcbR/Z0aEtW5FMG9e9fbkqQ78PBwYHrUTEcevSUPKmUM8+jOfMimudPn7Jnz55ynetRRAQtjQwKcrPrGehhoKFeLrnZnwKhUMiGjRvZvXcvU+bNx9dvP8t+W17E6c3IyCArJ4fq2v/sI6iurUVGVlaBeuHXzMuXLzHWUC8IbigIhdTS1iI2JuYTW1Y2hgwZQqdOnYD81XOBQMC6desYO3Ys1atXR1VVlSpVqjBy5Mhi97xs376devXqoaysjJ6eHh06dODp06d4eXkVOHn6+voIBAKqVKlS0C8kJARXV1fU1NTQ0tKiR48eREZGFhpbIBDw66+/Mm3aNIyMjApWnx4/fsy5c+feWwXp/0lPTy/xeQEsXboUExMTVFVV6dKlC9HR0YV+n52dzcyZM7GwsEBJSQk7Ozv+/PPPd9rw6tUrhg8fjomJCcrKypiZmdGnT59CbXr27ElwcPAn2XdRKifZyMgId3d3NDXfrftua2tbqNKFTCZj2LBhRW64nK+H3NxcBvXvTy1lRa739SCoe0fSIp8ybcoUdu3ZQ8d+/bmupIa4Zm0OHz1a4hzViRMn8sOMmfgmprDleQydevVmdTnkTX0pxMbGsm3bNjw9Pd+a43Xjxg0Sk5JY3LwR1tpatLMwZaitNUcOFM2x27PrTwZWt2JyA3vO9OjEuR6dEItEODk5FYk65+bmIgOaGf+To+tY2YjcdziK3bt35979+1y4cIEHDx4wfvz4DzvxT8zB/QeYYl+TlibG1NPXY4lDQ27evs3z589L1D8gIIBmTZpQzdKSjm7tCSulME7z5s1xbNGCyecuY7djL98GnmVELVtamBhz5MiRdwYySou5ZRUuxsYXSIXfSUgiLi29UNrJ25DJZNy6dYsjR45w/x1iOBWNQCCgRYsW9OvXDwcHh2KjwhoaGlS1MGfrvTDypFJypVK23ovAumrVj5JP+qVRo0YNniS94mL0SwDiMjM5GfWSGrVqfWLLysbs2bNZvHgxkJ/WdOnSJXr16oVEImHhwoX4+/uzYMECzpw5U2TVfOnSpQwePJgGDRrg6+vL5s2bsba2Ji4uDnd3d2a9Xo07duwYly5dws/PD4Bnz57RsmVLEhIS2LlzJxs2bODGjRs4OTkVqWayatUqwsLC2Lx5Mzt37gQgMDAQkUhU6pz1jIyMEp0X5Kdz+Pn5sX79etavX8+VK1fo1q1boTa9evXC09OTyZMnc/jwYdq3b8+AAQPw9/d/qw2TJk3i8OHDLFq0iOPHj7N06dIie3fs7OzQ1tbmxIkTpTq/8qDUYiIfglQqZdu2bYwdO/azXTqS83F59uwZT58/Z0ePTmiKxWiKxYytZcvMc+dQVVUt2KRXWgQCAWPGjClRjuB/jfDwcLp07IiiJA9NJTHz5s5l7bp1hSSGc3NzuXv3LlKpFIlUBq/3PeRKpAjFRTdB5OXlFWxoEggE+Uv6CsJiI6SGhoaoqahw9Mkzhteyfb0L/xlWlpbvtFtdXR0bG5synPnnR2nK+F6+fJlBAwcyrIYN9RvVxfPOfZzbtmXYN98wdOjQEudzOjs7ExF8k1+b1MdCUwM9FWXcDvjz4vhxWrVowV5fXyzfcy9KwvQZM2l/Koiu/qeooqHOxegYevXs+d4vZJksP4d3559/oqWiQnJmJpMnT2b69Olltqmi2Lh5C7179sDhr8PIZCBWUWH3vn2f2qzPgsaNGzN27FiGrV2Lla4OUSmp2NWsyYQSrgJ+rlhZWRV8PtWrV68g2vvvlbe8vDwsLS1xdHQkLCwMGxsbkpOTmTdvHiNGjMDT07Og7b8lwN/kqDdo0KBQnvOKFSvIzc0lICCgoIZ9vXr1qFGjBl5eXowbN66grY6ODr6+voVe7K5evYqNjU2pN4br6+u/97zekJqair+/f8EmVDMzM9q2bcvx48dxdXUlKCiIgwcPcvz4cdq1awfkp+hGR0czd+7ct6Ye/v333/Tr169QYPX/I8kAderU4cqV8lGALQ2liiSXha9A/VrOO3gTeYn71zJlXGYmqv+x/KnyRiqVcvjwYTZs2MCxY8cKOatTJk6kjoYaJzu7csitLVPr12bC99+TkpIC5Fej6ezuzk/z5iEUwKig81x9Gcfe8EdsvR9Oj2I+iDp06sz2Bw85GfmCx8mpzLx0HRVVNRo2bFikrZKSEitWrWJ5cCi9Ak7TyT8Q/xcxrFi9+uNdkM+Ert26sfTWHU49i+J6bBw/XLpGfXv7Egl4/OntTVszE6Y2sOd+0itC4xJooKPFSZ8/aduqFXfv3i2RDX369EGkocmy23fZE/6IfsdOkZUn4UQXNywEMkZ/911ZTxMAExMTTgYF0X34CKq4uLL4t+WsWrPmvTm5u3btYv9ff+Hr7sK1Xp3Z4tySVStXEBQUVC52VQT29vacv3iJ5WvXsWLdOs5dvEjtYjb4fa3Mmj2b/QcOMGzyFFavX8/+Q4f+s1H2HTt2UK9ePdTV1VFUVMTR0RGgYBXo0qVLZGRkfJDYy7lz52jTpk2Bgwz5K/L29vacP3++UFs3N7ciz150dDT6+vqlnhfef15vaN26daEqLW/sfeO4vnHw27RpQ15eXsE/FxcXbt68+dZa5/Xr18fLy4tly5a9s+KFnp5ekfSOiqBCIsly5BgZGeHu5sb35y8wpmZ1UnJyWH37HpOmTv3Upn22SCQShn8zjJMnTlJVuxKPkl7Rpm1bNm/dioKCAg8ePGCufY0CZa/u1SxZdDWYyMhIatWqxbw5c0h6+phzPTuRnpPLkBNn6HfsFOqqqkyZNq1Y8Z8RI0YQHR3N6PXrkclkmBgb8efu3YU+vP+Nh4cHVatWJTAwEEVFRTp27EhkZCRTp05FKBTSpUuXYkvOfenMmz+f7KwsRu/ahUQqxdHBgQ1//PFeNUWA7OwsKokViU7PYFVwKBtaO9LW3ASpTMb35y4za8YMfA8ceO842traHD1+nPlz5/KHnx+tTSuzplVzjNVUGVHDhsEnzuRXKimBTe/D0NCQyZMnl6rP9evXaWViRG29/L+dFibG1Dcy4saNG7Ru3brMNlUUenp6BTmqcorStGnTgvKR/1X8/PwYNGgQI0aMYOHChejq6hIdHY2HhwdZWVkABSUEK1euXOrxk5KSik0xNDQ0JDExscix/ycrK+uDyouW5LzeUFz1HQMDgwLHNT4+nsTERBQVFYudKzo6utggwpo1a9DR0eG3337jhx9+wMzMjBkzZjBq1KhC7ZSUlD7JXgC5kyynwljv6cm8uXPYcDwAsVjMtB9/LPIgyPmHvXv3cjrwFH4d2mKlpcnj5FR6HD+Fj48P/fv3x9jIiGux8bhVyc8NvfYyHvjnQ/R0YCDDqlVFX0UFfRUVTnXvSI2de/Havh0nJ6di5xQKhcyfP59p06aRkpKCrq7uWz/03mBvb4+9vT0Af/75JxMnTKCtuSkSmQyPrVvZ4On5n6t4o6SkxPKVK1mybBl5eXkoKyuXuG+bts5MPnwEM/X88oStTI0BEAoEtDI2ZMPTpyUey9DQkGXLl7PP1xePalUKSiE+Sk5BU10doVDI5cuXOXDgAFKpFHd3d1q2bFmKM/1wtLS0uJmWgUQqRUEoJCsvj+dpaeWiaidHTkWyd+9e6tatWyiN4syZM4XavFHhjIqKKrUkvI6ODrGxsUWOv3z5skhqWnErODo6Ojx58qRUc0LJzusNxdkXGxuLsbFxgQ36+vocPXq02P5vK3GppaXFypUrWblyJSEhIaxatYrRo0dTq1YtWrRoUdDu1atXZVY6/RAqLN1CjhwVFRUWL1nK9Vu3uHT1aoWVUfpSuX//Pg0N9bHSyt8oa6mlQSNDfUJCQli5ciUGlSvj/SCC4afOM+3C33x/7jITJ0xAX1+ftLQ04uLjeZScUjDes9R0JFJZiVT/7t69S7fOnalcuTI1bW3x9fV9bx+JRMLM6dOZ2aguv7dqhmfr5oy3r8mM//BqgUgkKpWDDPmbW8aMHctvN0MACHwWBYBEKuVU1EuqlDKPWFVVle9GjOCHi9dYExzKsuu3WXj9NhMmT+bAgQN07dKFiIBjRAaeoGePHuzatatU438oQ4cO5XlWNiNOX2Rj6D0GB55HQU29UM7810Rqairbt29n5cqVnD59+lObI6cUZGZmFpHI9vb2LvSzg4MDqqqqbN269a3jvBnj/6O0jo6OBAYGkpSUVHDswYMH3L59uyD94V1Ur179g6rNlOS83hAUFFSo6sWpU6dITEykSZMmQP4eibi4OMRiMQ0bNizyryQS47Vr12bFihUA3Lt3r9Dvnjx5QvXq1Ut1fuWBPJIsR04JSU1NRSAQoK6uXiHzGRoa4vcqmbTcXNQVFUnPzeVBUjL3Dh9GkJVJIz0d9FRVuJWSRus2bVg5eWqBA/Ls2TOyJRJ2hT0kVybFTF0d7/sRKCuK3ptT+fz5c3r37EE7YyPmt2/D9dg4Ro8ahZ6e3jujkK9evSI9MxMHo38iBk2NDFh+M4ScnJwSfUh+DQgEAlzateNPb29iYmMZd+YCjQz0ic/OIUEq49CO4r+k3sX8n37C0MiIY4cPIRAL+WXxYgYMGECN6tX53r4mo+vky11vuxfG9GlT6dWr10dXrzIzM8M/IIBFC34mMPIZVs0d2TZvHtra2h913s+R+Ph4OnVwIyU+HlMNdRa/jGXs2HH8+H+1x+V8nri4uDBmzBh+/vlnHBwcOHr0KIGBgYXaaGlpMXfuXKZNm4ZUKqVLly5IpVKCgoLo27cvDRs2xM7ODoB169bRtWtXVFVVqV27NhMnTmTr1q20a9eOH3/8kaysLGbNmoW5uTlDhgx5r33Nmzfnp59+4vnz50Wi2CkpKewrZrNp69atS3Reb9DQ0MDNzY3p06fz6tUrpk2bRuPGjXF1dS24Rp06daJ9+/ZMnTqVOnXqkJ6ezp07d4iIiGDTpk1vtd3Dw4NatWqhoKDA9u3bEYvFhaLI6enp3L9/v9yFkkqC3EmWI+c9JCQk8N2333Lm9QYK5zZt2LBx40dfNh4wYAA7vLzoefw0TfR0uBKXQK6iIpL0NI66u6CtrERqTg4djwZSx96+UI1MY2NjFIRCvq1RnbuJSTxITEZbWYlKJibvzVENCAhAW1GRhQ4NEAoENDLU505iMn/t2/dOJ1lbWxudSpU4/OQZEyvlX5vDT55hVrmy3EH+F/fv36dz585I8/LY6uKEVCbj+NPn3HocyfeTJmFra1vqMYVCIWPHjmXs2LEFx7Kzs4lPSsLB4R/BEgcjAzL+vklycvJb88zLEysrKzZv9fro83zuLFq4EHFaGgGd2qGmqMiFqBj+x955hzWRdXH4TUKvUhRUVBD7igUbiroqAooNexex7rr62XsXbGtbe+8Ve0cEsWCm31enAAAgAElEQVQXUSxrF0RQitJbKMn3B25W1wYYBHTe5/GRTGbuPTM3mZy595zfcV22jDZt21KtWrX8Nk/gKwwePJjnz5+zfPlyFixYgKOjI7t27fooFnvcuHEULVqUJUuWsGXLFnR1dalfv74i1KBmzZrMmDGDDRs28Oeff1KqVCmCg4MpVaoU58+fZ8yYMfTs2ROJRIK9vT2LFy9GV1f3q/Y1adIEIyMjPD09GThw4AfvvXz5ks6dO390jJ+fX7bPC7LyT8zMzPjtt9+IiYnB3t6eNWvWfLDP/v37mTdvHqtWreLFixfo6+tTtWrVLxYBsbW1Zdu2bQQFBSEWi7GysuLYsWOKBwoALy8vNDU186c4l/w7yU6cP3+e2rVr50uZ4Ddv3nz3PpWJrq7uR1qJPwsSiQQDAwNiYmI+mx2b13Tu0IGIB3/jVrcmMrmcSdcCqFC3Llu378jzvuPi4lizZg1PHj2itLl5VsVCL082NLVV7DPk/BXM7R2ZM2fOB8cuX76cObPdsSttRqw0ndtRb/DYtw9bW9v/dvMB69evZ+OihXi2aq4IhxntdxWtOjYs/4oGtbe3N64uLlgaFCFTLickIYHdezy+2ufnyOvxj4qK4sCBAyQkJFC3bl1FrHZycjIeHh68fv2aSpUq4ezsrJQEOIApU6ZwcvcuDNRUOdDKXrF9wqXrSGrWZuWqVYpt3/rdr1mtGnYGukyunZUUtOT2PTxCXvHw8eMCH+pUEL77yqJNy5bUzUhlWPVfFNtsD57AfdFi2rdv/9njhHv/z7fqkFtGjx7NrVu38PX1zW9TlE7nzp3R1dXNlyJ13zSTfP/+fdzc3Lhx4wahoaFcuXIFa2trJk+eTMOGDT/w+j+XKCQgUJBJTEzknJ8fe1vaUb1oVtLA1NrV6Xfam4yMDFRU8nYxRl9fH3d3d8UP5a5du9i7YwchCYmU1tXhdVIyAVFvaP6JCoPDhg2jQoUK+Pr6UlZdnXldulA1G0L/zZo1Y9bMmSwMuEvHcubcjHzDyRcv2TTDTbFPcHAwjx8/xsTEhGrVqikcLnt7e86cPYu3tzdisRhHR0eFNmhB48WLF7Ru2RL1jHRMtLRYtHAh48ePZ+CgQTi1acvLiAj0y5Xnzbr1nPA8xYZ1a5XiWCYnJ2OgpkZYYiIJaenoqqmSKZPxOC6ehu9ppyqD5atW0aN7N65FRSMRi3gaHcumLVsKvIP8o1GydGn8r11RJDE+iYnjbVKyIulJQOBbGTNmDOXKlSMwMFCRSP0jEBQUxIkTJ7h7926+9J/rX3hvb29atWpFrVq16NmzJ+7u7or3VFVVWbVqVb5MjQsIKJN/Zg/fryKXninLNyejS5cuHDtyBOeTPlQ2MuJhdDQ1rGvRu3fvT+7v6OioiBn7B7lcTkJCAtra2p+MS7W0tGTrtm38Pngw6+49QF1VFTf32Yrv84YNG5g8eTKaqiokSdPo0K4dq9auVbRVsWLFfEmwyCnTp06hrJoK6x1/RU0i4UxIGL/Pm0dkVBSv4uOwP3QSNX194p49wbNbB7y8vGjRosU399uwYUM8du+mqIYaPU75Yl+6JNfCI3kUHUvlN2+Ij4//qKqpVColOTmZIkWK5Oiz17BhQ3zPnlNobNvb23+wjCnwfRg/YQKO9vZ0OX0OSx1tfF9F0K5NG0XSk4DAt1K8eHG2bNlCVFRUfpuiVMLCwli3bl2+TbbkOtyidu3aVKlShW3btpGRkYGamhr+/v5YW1tz5MgR/vjjj2yXaM1rhHCLwktBWHLt26cP969eYWqtamTK5czyD8TGrjmr35PNyUv+O/6ZmZkcPnxYEcvWoUOHbM9oBwQEMKh/f16EhqKhrs7ESZMYMmTIJ/eVyWRERUVhaGiokIELDAzEwd6eBQ3r0bZsGR7HxNLL5wIjJ3ysa6kM8nL8G9W3oYuhPr0rlweyHh6q7jpI7Xr1CC9uRp3p/z74n+3Wnj+6dP7stcoJcrmc2e7uLF22DBGgJhFjpKGBYxkz/MKj0ClRkuOnTqGuro62tjZjx45lzerVZMpklLMwZ+OWrVSpUuWb7SjoFITvvjJ5+fIlmzZt4u2bN9SoWRMXF5evJk8K934h3EIgf8n1TPK9e/eYO3cu8LFuX5EiRQq9Yyog8A/LV65k1PDh/ObpiUgE7dq2Y8GiRflmj0QiyZWMVkREBN06d6aZiTFLWzvwd3QMM9zcMDEx+WR7YrH4I+F6f39/yhkb0bZsVunkCgZFaFWqJDeuXSt0mtdmpctw+dljelYqh1gkwj/yDWkZGViWLcuDS1fISE5GRUuLpLBQ4oKDc6x9+jlEIhFTpk7FtV8/Ro0ciezpY9Y1tUUkEhGdKsXusCdnzpzBycmJv/76i20bN7CscX3M9XRYcfcB3Tp35tLVq9lK6FE2t2/f5vDhw2RkZODo6PhBBrrAlylVqlS+ZOcLZJ+8eiDJj++qgHLItZNsaGjIq1evPvne48ePhVgrgR8GXV1d1m/apJjNymvprLzi0qVLSGSZzLaphUQs5hcjA+6/jeHIoUPZdrr19fWJSkpWxNLK5XKCk5Iwz4b2ckFj2owZtHZyorPXWcy0tPANfcXgQYMYPWYMF1q04EyXduhXqkLUjWvY1KtLq1atlNp/yZIlEYugrJ6uYqLBUEMdIy0thV7q4f37ca1UHocyWQ76Atu6WO8+REBAwHfP8/D29qaPiwtFrWsjUddg3fr1LF60iF69en1XOwQEBAS+F7lO13Z2dmb69Ok8evRIsU0kEhEeHs7ChQt/WsF4gR8XiURSaB3kf5DL4f34Kjk5i7Zq0aIFxqamuJzxY9P9R4zwu4Z/VDQDBw1SrqHfgcqVK3Pm7FmadO2OSZNm/LV8OW7u7hgYGODj5cVv3bvRrIQJU8eOYfeOHXky9ta163AsJJSXCYkAHA8KITQuTpF4IxaLyXwvHl4mzxoxZSlt5ISxEyZQvrcrjTdsw3blOmpOnMb4CRNJS0v77rYICAgIfA9yHZMcFxdH8+bNuXPnDlZWVgQEBFC9enWeP39OxYoV8fX1/W5FF75GYQ/9EOLSfpy4xNygrPGPjIykka0tjY0N6FXBkgcxscy6fouVq1d/UYbqv0RFRTFz+nQe3LtHMVNTJkyenGfZ1Moaf5lMRlBQEFKpFEtLS9TV1XPdVlBQED4+PgDY2dlRtmzZXLcllUpx6dWL8xcuoK+pSUxKMm5u7gx699Cxc+dOJo4bx7Ta1THX02XN/UcEy0Wc8/P7rvdXuVyOqakpjddvxaRuloZq4ssXnHBqTmBgICVKlFB6n8J3X7j3f++YZCHcQuC/fJNOcnp6Ojt27MDb25s3b95gaGhI8+bN6dOnT4EqHiA4yYUX4YdSueMfGBjIbwMG8DQ4GG1NTSZOnszgwYOV0nZeoIzxj42NxaVXLy5fuwZAGTMzdu7Z85ECx5EjRzh16hSqKip06dr1k+VgL126RI9u3TDV0kIkgtdJyezcvTtbpWM/h0wm4+rVq0RFRVGlShXKly+veE9HR4dZs2ax7K+/SE5NpXrVqqxZvz5fMr1r17NBrW59ak6ahkgk4sGmdTxdv5qnjx8rEjuVSU7GPikpifnz5nHL3x9DY2P+N2IEtWrVUrpN3xvh3i84yQL5S66c5NTUVLp06cKYMWO+WIGroCA4yYUXwUnOm/FPTk5GU1OzwOvlKmP8B7i68uDKZVY1tkFXTY0pV2/yVC7i8rVrClWQZcuWMW/OHFqblyIlM5PTL0JZv2EDbdu2VbQjl8upYWVFc0N9ptTJKs4x2/82p9/EEnjvXp5cy3/GXi6Xk5GRkSfOaHa5fPkyXbp1Q8+8LBINdaLu3mHtmjW0a9fuq8fevXuXDRs3Ep+QQP169ejfv/9Xw1eyO/YZGRl0dHYm9NFD2puX4mlcAt6hYRw9drzQO8rCvV9wkgXyl1wFtmloaHD+/Pmf1mkRECjsaGlpFXgHWVlcuHCeYVaVKKOni6GGOlPr1CAoJISXL18CWQ8Mc+fMYV6DOvzZsB7Lf23A0GpVmD5lygftJCUl8Soigg6WZRCJRIhEItqXLcPryEiSkpLy9BxEIlG+OsgADRo04JyvLwPbt6OvowOnPD2z5SD7+/vToqUT50JCeaipi9v8+QwbPhxlFXu9cuUKN/z92dm8MUOr/8JfjW1oblaCZX/9pZT2BQTyitjYWLp06YKuri4lSpTgL+EzW+DIdfaHg4MDp0+fVqYtAgICAkpHQ12DtylSxeu3qakAaGpqAhAdHU1GZibWxf6tdlezmDER/xHl19bWRldbm+sR/26/EfEGXW1ttLW18/IUCgzlypVj5MiRjB49mho1amTrmNnz5lHC3pGGK9dTa8oMGq3fxj4PDx4+fKgUm6Kjo9HT1MBUW+tfO/X1iC7EK4hyuZy1a9dSvnJlKv7yC4N++424uLj8NktAyQwdOhSpVEpYWBheXl7MmTMHT0/P/DZL4D1yLQHn6urK4MGDSUhIwMnJCRMTk49mpqytrb/ZQAEBAYGcIpfLuXLlCmFhYbRo1YoFu3eRLpOhp6bKivuPaOHgoNCANjExoYiuLvuePGdEjapkyuUcfP6Ciu9KfcfExDB6xAjOnjuHWCRi7o3b3Ix8i1gkwuvFS5b89ddPMyufG15HRGBo20RxjQwqV0GiqkZERIRSqv9VrVqVuJRU9j15TufyZQlPSuZw8Etadev+zW3nFxs2bGCmuzu/DB1JSWNjzq9fQ68+fThy6FC+KJsI/ItUKmXr1q0EBwdjbm6Oi4tLrhKBk5KS2LdvHzdv3kRPTw8rKysGDhzIpk2bhGrFBYhcO8mtW7cGYNWqVaxateqDHwm5XI5IJBLCMQQEBL47mZmZ/D54MMeOHaOojg7h8fHY2NiwKywUaVoadq1b4+Y+W3HPUlVVZeWaNfR3deVUWDjSjEySgf0HDyKTyejbuzdvnz1lQT1rYqRS5ty8w2v9IlSzqsbu+W1p1qzZdz2/Z8+ecf78eVRUVLC3ty/wmvRVK1fhyokjmLdrj6qWNsFHDoJc9kGC4rdgaWnJnwsWMG7sWBbd+ZuE1FRq16rN+AkTlNJ+frB+82Yq/zaUii79ADCqVp0TTs15+vQpFSpUyGfrfl6kUimtnVry/MEDrIwM8XgbzX4PD46dPJljR/nx48fIZDKqVq2q2FajRg0OHjyobLMFvoFcO8lnz55Vph0CAgICSmH79u2cOe3F0dYOlDfQ51p4JK4+F9i2YwfNmzf/5DEODg6cPX+eCxcuoKKigoODA6ampgQFBXH52jW8nFtSVl8PAGlmJptCXrMkH+IHvb296evaD50SJciUSpnp5s7B/fvyTIJPGbjPmknrdu041aIZmkZGxAQ958/58ylZsuQ3tSuVSnn58iV6enr07t2bBg0acO/ePQwNDalfv362S7UXRKRSKcaGhorX6gZZf6ekpOSXSQLA1q1bef7gAUec7CiqqUlUSgrtTp5h27ZtDBw4MEdtJSYmoq+v/8G2IkWK/LSJmgWVXN9Fvne1JwEBAYHsEBgYSNMSppQ3yPoBqmdajOqmxQgMDPyskwxZ8bbl3oVY/EN6ejoAOu8lzemoqpKRkZEHln+Z9PR0Bv8+hHJ9XKk6bCRymYwbk8fxx/DhXDx37rvbA1nXetykSYS8CMHcwpw/58zBysrqg31MTU056+ODl5cX8fHx1K5dm2rVqn1Tvzdu3KBv795Evn0LQLcuXVj811/5Io2XFzT99VeOr1+D4S/VSI2KJHDxn+jo6v00se8FleDgYKyMDCn6Lp+hqKYmVkaGBAcH57gtHR0d4uPjP9gWFxcnKGEUMITgJoGfBqlUypUrV7hw4QKxsbH5bY5AHmFoaMiT+EQy3lWqS0pP52V8AkZGRjluy8LCAkvzMky+FkBIQiKBUW9Zdu8hzR0clG32V4mMjCQhLhaLDp0RiUSIJRLMnTvy9NEjpSlF5ITnz5/T1tmZ6KKmlBs1jigDI9o4O/PixYuP9tXV1aVTp07069fvmx3kmJgYevXoQVOjIlzu0pbdLZrhfeI4ixYt+qZ2CxKz3dyoVbECXh1bc/73/ojEYlSMjLFv0YI7d+7kt3k/Lebm5tx9G03Uuxn9qJQU7r6NxtzcPMdtVahQAZFIxP379xXbbt++/UH4hUD+k2snWSwWK8r0fu6fgEBBITw8nGb29rRzdqZLt27UrV+fgICA/DZLIA/o378/ERmZ9D3jx9Lb9+jhfQEdI2M6duyY47ZUVVXZuceDMBVV7A6eoNNJH6xs6uM2e3YeWP5lDA0Nkaio8ObWv5/bN7cDKPqJpOnvwd69e9EuY0HduQsp49SGevMWo1m8JPv378/Tfm/fvk1iYiIz6llTVFOT2iZFca1YDt8fSG1JW1ubDevWoaqmhvXEaTjsO4L94ZMYN2jEyLFj89u8nxYXFxfKVq5Mu5NnGHzuMu1OnsGychX69OmT47a0tbXp1KkTkydPJiEhgXv37rFhwwb69euXB5YL5JZch1ssXrz4oxtzTEwMp0+f5tWrV4wYMeKbjRMQUBbDRo4kTl0T5wvXUdHS4qbbNHq79OXWTf8CVR1S4NspUaIEXt7e/Dl/PgEhL1AtXoJXwUFUqVyZxo0asnT5CoyNjb/e0DssLS3xu3yFV69eoaGhQdGiRfPQ+s+jqanJ5EmTmD19IhFXL5GZkkLomdOsX7cuX+xJSUlBw8hY8TsgEotRNzLK87hZNTU1MmUyktIz0FfP+u7GpaWhrvFjhSKEhoaSnpZG6ZatABBLJJR0bMmd6ZPz2bKfF3V1dY6f9GTbtm0EBwfTytycPn365LrM/cqVKxk4cCDFixdHV1eXCRMmCMoWBYxvKkv9Ofr06YO5uTmzZs1SdtO5Qqi4V3hRVsU9c0tLarrNp2SzrJjUlMgIjto15OrVqwU+jlEY/9yP/+LFi1mxZDGTrKthrKnBX3cfoFmyFMc9PQvFatenxv7IkSOc8vJCRUWFrl26fFNJ7G/hzJkz9OjZE5v5SyjeuAlhZ324Pmksez08lJKz8rmxT01NxcHODs34OPpXKseLhESW3L7HX8uW0aVLFwC8vLzYtWMHaWlpOLRoQd++fQudTF9sbCwVK1ak3vzFlG7RCrlczq05sxDdCeDS+fP5bV6eI1TcEygI5En6b69evejdu3eBcZIFBHR1dUl8GaJ4/c/fenp6+WWSwHdgz47tDK9WhU7lywJQrog+TQ8c59mzZ4VWSqtdu3bZqnSX19jZ2TFl8mTcx41AJpMhlkiYOWNGnid1a2hosPfAAUYOH87kGzfQ09Vl7vz5Cgd53759DBs6lA6W5pioqjBjyhRCQkKYPn16ntqlbIoUKcKsWbOYNnEMYd6nSI+N5U3gLfbu2ZPfpgkI/DTkiZP86NEjZO+SZgQECgIjhg1jyrRpSONiUdPV5enWjXTp1i3fls4Fvg/p6RlovScFpqmSNXucE3WK9PR0tmzZwqNHjzAxMWHAgAHffYaroDJs2DC6du3Kq1evKFmy5Hf7PpmamrLbw+OT781xc2N49V/4vVoVIEvd5PeVKxk5cmSheygeM2YMZcqUwdfXF/Wy5nSZ97F6iICAQN7xTTHJ/yUtLY0HDx6wb98+evTo8U2GCQgok379+qGpqcmWHTuQSqUMdnFhzJgx+W2WQB7j6NSS5fv3Y6Gni7GmBnNu3qFsmdIfSb19jszMTLr36sWN24EUrVef+At+7PLwwMfLK1dqGZ8jPj6emJgYSpQogep7cnOFgWLFilGsWLH8NkPBm+hoKlf5d3yrGBogl8uzylcXMicZoEWLFrRo0SK/zRAQ+CnJtZP8KQdDXV0dMzMzhg8fztSpU7/JsM+RmJjIypUrCQgIQFNTk/bt2xeIpUeBgo1IJKJHjx7Cw9tPxoyZs4h+G033I0cAKF+2LDt37sx2subJkye5cu0aDgeOo13SjIzUVM717MSKFSuUsnwvk8mYNm0aa9euBcCwaFG2bNxI/fr1v7ntn5XqVlXZ+SSI+sVNUBOL2fLgMYZFilCiRIn8Nk1AQKCQkWsnOb/CKdauXUt6ejqbN28mMjKSqVOnYmZmRq1atfLFHgEBgYKLhoYG6zZsYP6CBaSmpmJiYoJYnH3ly9DQUIqUMUe7pBkAKhoaFKlZi5DQUKXYt27dOrbs3EXjVRvQL1+BhxvW0rN3H65cuoiJiYlS+vjZWLpiJR3atcP2wAnUVSQkZ8rYun27oGIjICCQY3Ktk7xt2zbevqt29F+io6PZtm1bro36HKmpqVy6dInevXujpaWFubk5Dg4OeHt7K70vAQGBHwcDAwOKFy+eIwcZsuTfYp49JfbxIwCkcbG8uXKRcmXLKsWuk6dPU7Z7L4o3+hUt0+LUmDiVDOT4+/srpf2fEUtLS85fvMii5cuZtWAhfpcu0bhx4/w2S0BAoBCS65lkV1dXrly58sm4vKCgIFxdXXMlsP0lwsLCkMvllClTRrHNwsKCK1euKLUfAQEBAQB7e3vatGnD8d5dMK5ajfigZ5Q2MWXYsGFKaV9NRZWMpETFa1laGpkZGYUuLrmgUaRIESEMTyDHCFJtAv8l107yl+SVY2Ji8uTDlpqaipaW1gfbtLW1PxKvf/PmzQfayGKxuFCrGIhEokKh6ZoX/HPeP+v5gzD+7/+fH6xfu5YjR47w4MEDinfrQpcuXT66D+WWPr16MmjwYLSKl0DfsjzPdm6lqJERtra2SCQSYez5PmN/9+5dVq9aRVxsLHVtbPjjjz9QUckT8accIYy/gED+kqO7gKenJ56enorXixYt+ihuLjU1FV9fX2rUqKEcC99DQ0PjI4c4OTkZTU3ND7YdOHCA9evXK1737duXoUOHKt2e78nPHk9XGLPSlYkw/vk7/q6urnnSbr9+/ZDJZEydMYOH0dHUql2bbb6+H6yWCWOfs7HPyMjAzc2NowcOoKKiQt+BAxkyZMhni4ncuHEDRwd7bIoVxVxHmxUXL3Lvzh32HThQIAqQ/Hf8PT09OXr0KCoqKvTs2RMbG5t8skxA4McnR07y48ePOXbsGJD1hOvn5/dROUY1NTWqVq3KnDlzlGflO0qWLAlASEgIpUuXBrJCO/75+x86duz4gaC9WCwmJiZG6fZ8L7S1tUlKSspvM/IFiUSCnp4e8fHx2a64JpVKUVVVzXH8aX6SmZnJwkWL2HvgIHLkdGzXjvHjxqGiovJDjH9qaio+Pj7ExsZibW1NlSpVsnVcbsa/sNGxY0c6duz4wbZ/7lc/wtjnltyO/agRIzi6fz8DK5cnJTOTsaNGERUVxfDhwz+5/6QJE7ArWZwlDeshEonoWsGSlocO4evri7W1tbJOJ1f8d/w3btzI+AkTMGvWnMzUVFavacT2bdt+SIm4f8b/eyJU3BP4LzlykocPH6640VhYWHD48GGqV6+eJ4Z9Cg0NDWxtbdm+fTsjR44kKiqK06dPf3TzMzY2xtjYWPH6zZs3hfoHVi6XF2r7/yExMZG4uDhMTU1zvJSWmZn51WsQGhpK/8GDCbh+HVV1dQb278+0adMKxbLd1GnT2LprF5V+GwoiMavWrCA2NpZ5c+cW+vGPjY2lbfsOPA8KQtPQkPhXYfw5fz4uLi7ZbiM74/8jUtjHXhnkZOwTEhLYsm0bm+1/pWEJUwCKamqwZOlfn11NjAwPx8mwiGLWuFwRPXTU1QkPD8/3a//++KempjJpyhSsp87CsmNWdcG7yxYzZvx47O3t89NMAYEfllxPtQUFBX1XB/kfBg8ejEQioW/fvkybNo2OHTsK8m8FHJlMxqTJk7GwsKBGjRpUr2nNzZs3ldpHWloaXbp357VcRLNte6gzewGbd+5k0aJFSu0nL8jMzGTDxo3UnOpGhV59qdCzD7VmzmHz5s2kp6fnt3nfzMxZs4hMS6Ol11kcT56h9sw5jBs/nqCgoPw2TeAHIzExKwmylI62YpuZjjaJSUmfzaOpWq0aR1+EEZ+WBsCRZ8GkpKdTsWLFvDc4B7x9+5Z0qRSTuv+GVxSra0P4q1dfzBESEBDIPd+cmfD06VMeP35MamrqR+916NDhW5v/CB0dHSZMmKD0dgXyjpUrV7J9924arVyPnkVZHqxfTbcePbh6+bLSqpY9fPiQJw8f0u78VTQMs9pMiYpg3wEPxo0bp5Q+8or09HQy0tLQNDFVbNM0MUGWmYlUKs1Hy5TD7bt3MWvdDnX9IgBYtOvAnfnuPHz4EAsLi3y2TuBHwsTEhDJmZiy5fZ/5tnWQZmay6v4j6tSq/dn44mkzZuB88yZND3tirKXFi5hY5s6bh7m5+fc1/isUK1YMbV1dXpw8xi+D/0Auk/Hy1AksLC0LROy0gMCPSK6d5Pj4eNq3b8+5c+eAf9Uu3v+y5vdSlcD359y5cyxftYq4+Hjq163LpIkTOeF1GstefSnRuAkAtaa5caShJzdv3sTBwUEp/So+f+/FIYvEkkIxw6KhoUHN2rW5v3wxNguXgljM/aWLqFq9Ojo6Ol88ViaTIRKJCvSPZDFjY549uK94nfAiGGli4gchUQICykAsFrNl+3Z6dO1K9V0HkcnlVLC0xGPNms8eY2RkhJePD6dPnyY+Pp6aNWtiZWX1Ha3OHqqqqqxYtoyBgwYR6etNpjSNlIjX7N+7N79NExD4Ycm1kzx+/HjCw8Px8/OjYcOGHDp0CAMDA3bs2IGvry+7d+9Wpp0CSiYhIYH58+dz7+FDSpiYMHrUKCwtLb+pTV9fX7r36IG5cyd0qtVi1/49/P3wISoqEjJSkhX7ydLSkGVkKFViydjYGA1tHS6P/h/VR08gJTKcB2uWM7hvX6X18SlkMhn+/v5ERkZSuXLlXF/DjevW0aV7dw43rgeARbnybN6967P7x8fH87+RI/E6dQqxSEzHTh2ZP3fuR0ov2UEul/Pq1SukUimlS5dWuvTVhHHjaKu7GMoAACAASURBVNWmDZeG/YaOhQUvjx/B3tFRCJMqYKSlpXHp0iViY2OpXr06ZZVUMOV7U7VqVS5fu0ZgYCAqKipUr14dDQ2NLx6jpaWFs7Pzd7Iw97Ru3Rofb298fX1RUVGhZcuWBW7GW0DgR0Ikz+VUm4WFBbNnz6Zr166oqqpy7do16tSpA8Do0aMJCwtjz549SjU2t7yvmVwY0dXVVWrWbWpqKi1ateZVYiLF7RyIuRtIwoP7+Hp7f9Pyd+t27XhbypxaU2YCkPgyhBNOdowdO5YlS5diNWocehaWPNmyAcnrMC6cPfvVmVKJRIKBgQExMTFfXJno3K0bgSEvkQFxTx6DSIShkTH37gTmWWGG9PR0XFxd8fH2RkNPj9T4eGa7uzNw4MBctZeWlsaDBw8AqFSpkkI55lPj371nT24+eYrV2EnI0tMJnDeLNnZ2LF2yJEd9JiQk0Ld/fy6cPQtkOee7d2z/5gem/xIYGMjqNWuIiY2lbu3aDBs2LFvSZtkd/x8VZX/3P0d8fDwdOnfm/v37aOjqkhoXx19LltC1a9dct3n//n2mzZzJy9BQKpQrx2w3tw+k7b7Gzz728P3GvyDyz/h/T763usWKFSvYsmULd+/epX379gXGZxL4l1xPGUVGRlKqVCkkEgna2toflKh2cnL6SNJIoODg6enJs+AgWpzwQb2IAXKZjPOuPVm9ejV//vlnrtuNiY1Dt9G/Tra2WSlU1NSoW7cubjNnMmf+fBLj41HX1qZJo0ZKS0rLzMzE7/x5Gq7agGl9W9ITE0h48QLvbu1JSEjA0NBQKf38lxUrVnA5IICWR73QLWPOi5PHmDxxDDY2NrlarlVTU8tWMmxCQgI+p09jt30vxjVqAlmzwfvHj+KvxYtzFHoxeuxY7ga/wHH/MVT19LjlNo0evXtz2c9Pqaog1atXZ83q1UprT0C5zHJzIyQ2nlZe59EwMuLJnp2MGDmSBg0aUKpUqRy39+zZM5xat8a4vi1Fu/bkro83LVu35ryvb6Eu7FSQuHfvHsNHj+bZ06eYmJoy182NZs2a5bdZAjmgRIkSTJkyBR8fn0I/mfejkmt1i1KlSikGtXz58hw9elTx3pUrV766vCWQf7x58wYd0+KoF8l6SheJxeiWr0jUew86uaFe7VoE7/MgJSoSuVzOg41rkYjFVK5cGQsLC5ISEijXvTe/jBjLjWfP6dC5C2nvMsq/BbFYjKqaGmlxsQBINLWIfZQ1IyuTyb65/c9x/eZNSrZojW4ZcwDKOLWhSKnS3L59O8/6hH9j/cXvzcRK1NSQyWU5jsE+c8aXyn+MoEjFSmgXL0HNqbN4/uQJISEhSrVZoGDi5eXFuHHjOH7iBEVtG6HxLpG2fLeeSNTUFSsbOWXHjh3oWJbDZuEyynXtSYNV60hXVePgwYPKNP+n5fXr1zh36EBcseLUdP8TVZuG9OjZk4CAgPw27YdHKpWybt06Jk2axLp1674pubpDhw44OzsL+RkFmFzPJNvb2+Pj40P79u0ZOXIkLi4uXLt2DTU1Na5fv87o0aOVaaeAEqlWrRrRz57y+uIFijdsTGLoS8J9vek6KHdhAv8wY/p07nfrxnGHX1HV0ISMdNasXo2JiQm/DxuGRYfOWE+YAoBZcweON2/E9evXadiw4Tf1KxKJcOndm+1zZpEcEcGzvbtIDHkBQDN7ezx27aJy5crf1MenMDIw4N7TxwQfP0pmagr65SuQ/PYtRYoUUXpf71OkSBHq1W/Abbdp1Jg6C1laGncXzsWxRYscF1BRVVcjLSFe8TotPg7goyJBAj8ey5cvx33OHMya2iEubc6TXdsp2dSOYnXqkRj6krTkpFyvwiQkJKBZoqQikVaiqoZmMROFRJvAt3HixAlEunrUnbcIsURCyaZ2JAY9Y8+ePfleAOVHRiqV0rJ1ax48e45hVSui93jgsX8/J48dE+6ZPyi5dpLnz59PcnJWMlbv3r3R0dFh//79pKSksGLFCgYPHqw0IwWUS7169Rg9ahQL/xiIXvHiJEW9oWGjhgwZMuSb2tXT0+P4kSNcv36dhIQErKysFFUSExIT0bKqqdhX3cAQVQ0Npf1ozpgxAzV1ddavXoZ6STPaeF9AVUcH/2mT6NmnD9evXFF6Qlp7Z2f29enD23t3UdPTI/n1K4qXKEHz5s2V2s+n2LRhPf0GDMS7a1ayUXMHB5blMB4ZoG+vXqxckhVio6arx4OVf9HEzo7ixYsr1V6BgkVsbCzus2dTb+5CSrdsjVwu56b7DC6P/h/luvUk5PB+Gjdt+oHDFR8fz+PHj9HV1aVChQpfDOuxsbFh18iRRPpfp2itOoSdOU3E7QDqTZn0Hc7uxyctLQ1VbR3E74VEqejqIVXCypzA59m6dSsPnj3Hbt8RNI2LkvImijOd27Ft27Zc56IIFGxy7TVoaWmhpaWleN2+fXvat2+vFKME8p5x48bh6OjIgwcPMDExoXHjxkqJQVVVVcXW1vaj7Y0bNGDTnl2Y2dmjU9qcv9evRp6RobSCNCoqKkybOpWNmzZhNXQkWqZZTl61MRM47tiEsLCwHCUNZYd1GzdSrHpNbFeuR0VTk0dbN/H38sWkpqbmSmUiJxQrVozjR48QGxuLWCzOdfnWsWPHArB1zQrS0qQ0t7Nj4Z9/FmhJufwkPT0diURSqEqef4rXr18jy8zExKYBkLUaY9rAlpCjB9G5E4Brly6MHTNGcZ5+fn64uPYj4V1Ik529PZs3bvzs57xjx47cvn2bta49kaiqIsvIYOrUqd+8aiSQRaNGjZjl5sbDrRsxb+1MlP91Qr1PYfcFqTuBbyc4OBjDqlZoGmfF1WsaF8WwqhXBwcH5a5hAnvHNU2sPHjzA39+fly9f0q9fP0xNTXn69CkmJiZCvfICTvXq1b9b1cRxY8fy8NEjPNu1RCQSoaGlxcb165U+Y6mhpUVKVITidUpkJADa2tqfOyTX3Lt/H4uhI1F55yiU69aT2wvn8vz58+8mb/atoR0SiYQJEyYIBXq+QkREBIOHDOHKxYtIVFXp3asX7m5ueaackteYmZmhqq5OiJcn5bv1RC6TEXb6FJWrVOH44cMf7BsdHU0fV1dKtu2A1fDRJIW95NLvA3CfPZvZ7u6fbF8kEuHu7k7fvn0JCwvDwsKC0qVLf49T+ymwsrJi9apV/G/4cAIXzkMsFjNx4kTatm2b36b90JibmxO9x4OUN1GKmeToe3cxb9Mqv00TyCNy7SQnJyczYMAA9u7di0gkQiaT0aJFC0xNTZk4cSIWFhbfpJQg8GOhrq7Ojm3bePjwITExMVSsWDHb1fZkMhl+fn6EhYVRoUKFzzr29+7do17t2vgsmEdGUhIq2jo8Xr+atu2ylxiRkZHBhg0buHX7NkaGhgwaNOiLGqQmxYoRc+8O5m2yQh6i790BsmZ5Cwq3b98mKCiIUqVKUatWrTyfIZbL5bx584bMzExMTEx+iBlpmUxGj969eZ0h49cN20iLi8XDfToaGhrMnDEjv83LFbq6uixasIARI0fy6uRR0uLjSXsTxYYDBz7a9969e6QkJ1Nt9HjEEgl6ZctRtpcL508c/UTLH1KuXDnKlSuXF6fwSVJSUpg6fTonTnoikYjp1qULE8aPV3qoVUGgffv2ODg4EBYWhomJCfr6+vlt0g+Pi4sLe/bt40zndlkxyffuUqWcJX369MlVexkZGYp/MpmM1NRUJBJJoX34/hHJ9Z1jzJgx+Pr6cvLkSRo1avTBTJ2TkxNLliwRnOSfiISEBF6+fEmxYsU+65CKRKJsJ9C9ffuW+/fvo6mpyYrVq/E6dQptI2MSIiMYPWoU48eP/2D/rVu3Mm78ePTNSiFHzoO1K9HS0KBksWLUq1uHxMTEL2oyy+Vy+g0YwPnLVzBtZk/ijZvs2WuPt9epz2oGT5s8mW7du5MSGYF6URNeHj1EX1fXXElmKRu5XM7kqVPZsG4d2sbGJL19S7fu3Vm6ZEmeOa6xsbH0GzgQv3dVOKtbW7Nj61ZMTU2/fGA+8+jRI2bPnUvY69dUqlCB6VOnfvCg8+LFC+7cukWrk2fQKZU1G5qWEM/+1csLrZMM0L17dypUqMD58+fR0NCgTZs2n/zsamlpkZmejjT6LZpFs65LSmQE2u+F2xUU/jdiBGeuXKHy/0YhS0tj3dJFpKWlMWvmzPw2LU/Q1tamQoUK+W3GT4O6ujqex4+zbds2goODMW/Tij59+uQ6ac/d3Z2Z73029+3bh4uLC1u2bFGSxQLfSq6LiRQrVowFCxbg4uJCZmYmqqqq+Pv7Y21tzdmzZ2nXrh3x8fFfb+g7UNj1Bwu6oPyBAwcYPmIE0tRURCIRo945sbl1xi5cuEAfV1dSU1LITE9HTU+f5rv2o1vGnNeX/Lj4x0AOHjiAra0tcrmckJAQ6tarR+0Zs7Fw7shL71NcGTcSeUYGACIVFYyNjLlw7uxnHfhLly7RoVMnHA+eQM+iLHKZjIu/9aNecRPWrV37WVuvX7/O5i1biImNo1KF8vTr10/py8q5Gf+TJ0/Sf+AgGq/fQlHr2kTfv8f5/r1Y8uefdOnSRan2/UPvvn25/ugxtWYvQKKuRsCMKZRUEeN18mSuPwtfKygRFBREQEAAOjo6NG7cOMex4M+fP6dZ8+YYWNfG0Lo2r7290EpO5KyPjyJc7NmzZ9jY2NDa6xzaJbISUYOOHOT58iU8uHc3V+eVXQrCdz8jI4NWbdsSHBuHZe++JL18ycNN61i7Zk2eVqnLaTGRxMRELCwsaLppB8XqZFWufHHiKHfcpxP8/HmhXNUoCOOfX/wMxUQECj65zj5JTEz8bDxpUlJSrg0SKFzcvXuXP4YOpfKwUbS/6I/t0tUsXb6CQ4cO5aq9+Ph4XPr1w8y5Ex1u3KVks+aUcmyp0CIubtsI44qVCAgI4H8jRmBWqjT1bOojkkgo0cye5Ihwrk0aS0WX/nS8Fkjz3QdQ1dYhKjKCsePGfbbf8PBwtA2N0LPIKsUrEosxqGFNWHj4F+2tW7cuds2a4XfhAitXrqRWrVpMnDQpx3rFyubWrVuY1K5NUevaABj+UhXT+rbcunVL6X1dvXqVVatW4e3lRdXREzCs8gv6luWpMWUGt/z9iYmJyXGbgYGBOHfsSK16NrRt356XL19+tM/hw4dp0LAhY6ZOo9+gQTR3dCQqKipH/WzcuBFty/I0WLaGyv0G0WjjNt4mJHDkyBHFPubm5lSuWhX/yWOJvn+P8Mt+/L1sMe3atsnxeRVGVFRU2Lt7N81q1uDVxrXIrlxk9apVBa6Mc2pqKpClnPMP6gYGpKWl5fv3UUBAoHCSaye5WrVqHPhE/BpkaTjWrl0710YJFB4uXbqEYbnyVOzjipq+PiWb2mHWwokzvr5fPE4ul/Ps2TNu3rz5wYrDo0ePSIyLw2r4KMQSCVqmxYl99BD5u6IgafHxJL5+jbePD8d9fan75xJsl61Go5gJl0YMIfpuICKJCtWGj0ZFSwujqtUo37MPqjq63A68o+jn6NGj2LdsSb2GDRk9ZgylSpUi8U0Ury/5ZfWTkEC4rzdVKlb84nk8ePCAocOG8cuI0XS8cZemm3awbdcutm/fnu1rKJPJSExMVOoPuZGREYkvX5L5Tuhelp5OYnCQ0qsPLlq8mHbOzqzY7UGmTEb4lYuEX76ILD2dzJQUgBzHgz569IjWbdoQpq2HYbee+L8Ox9HJiejoaMU+UVFR/DF0GL8MG0kr30u0On2BGLEKEydPyVFfMbGxaJtbEOrjxY0ZU7i7dBFq+kWIi4tT7CORSNi9Ywemchne3dpz4bf+ODVryszp05FKpdy6dYuAgACFk/Yjoq+vz+qVK7nt74/fWV86dOiQ3yZ9hJGREZWrWhE4353k8NckhLzg/tJFNG7cuNCrkQgICOQPub5zTJ06lY0bN9K7d+8sYXORiOvXrzN27Fg2bdrE5MmTlWmnQAFFXV2dtIQEZO+VmE6PiUbzCxUX09PTGThoMDY2NrRo0YJqNWrg4+MD/LsslRQWBkCFXn2JffKIcwP6cG/lUs737U5Jk2LcvHmT6hOmUbJZc4o3+hWbuYuIunGNZwf3IUuTkv7esllKVCRyWSYG7xJbjh49yoCBA4ktWQrNZo4c9j3LgEGD0Tc05NLwIZxo3ohTrZpjgJxJEycSGRnJH0OH0rxFC7r36MGdO/8621euXKFIGXMq9OqLioYGxerUo1Srtpy7cCFb12/z5s2Yly2LhYUF1a2tuXbt2gfvR0RE0LZ9e8qULcsv1aqxZs2abDnTXbt2RUsu40K/ntxfvRy/QS6I4uPo3bt3tuzKDn///Tfz583DdukqLHq5IBKJCDp0AL+hg/Dq1Bb/iWNo4eSUY3m6rVu3UuQXK+rOX0y5Lj2wXbmBZJn8g6qejx8/Jj09jQq9XQFQ09enVNv2XL9xnaCgoGw/cNSuVYuXnse5Mn4UGclJxD17SvTzZx859iVLlsT71CmeP39OSEgIK5cvJyIigsZNm+Lg4ICjoyMNf/2V58+f5+hcBZSHSCRi+5bNaMe85Zh9Y062ak5pbS1WLl+e36YJCAgUUnLtJLdq1Yo9e/Zw8eJFnJ2dkcvlDBkyBA8PD3bu3ImdnZ0y7RQooDg5OSGWpnJ1zHBenvbk1jw3Iq5epkePHp89ZvHixfhc9MNh72E6+d+jdLde9BswgNevX1OxYkWaNm/Opd/783jHFp567EImlWIhEaF79xbtf23M8SNHkMnliN/LAP6nRHNFFTGaWlqcG9CH4GNHuLN0Ec8P7CUzJRV3dzcA5i9ciIq2DsFHDnF/9TLSUlN5m5SI5W9D+WXIMFLjYrGzbYCPlxeBgYFUr1WLk1eukmZdl1tRb7F3dGTTpk1AVlKTND5OMWMLII2KylZS08mTJ5k4aRJVRo7FYe9htBs0omuPHoSGhgJZDxNdunfndugrrN3/pKRLf2a5u2crqcPAwIDTnp40q/oLGgHXsbUwx/vUKaUm0T1+/BhtIyP0LMvjP2MK1hOn0uHyTVqfPk+mNBUjDXVWr1yZ43YV1drexZBK1NXRLFr0g8IzxsbGyGUy4p8+AeDt3UDuLFvM69BQ6tatS/eePRXFjr5E69atyUhLo8HCpdT/cwlNN2yjXOdu7Nzj8cn9dXV10Xj3ADhg8GBSDI1xvniD9pduklHCjL79B+T4fAsjycnJBTJWtkyZMvidO8fVq1e5fv06nsePCyV/BQQEck2O1kGrVavGrl27qFq1KgCdOnUiNTWVChUqkJGRgaGhIZUqVcoTQwUKJiYmJhw7fJiRY8Zyf/YMTIsXZ/euXV8sjXrW7yIWXXpgUPkXAKyGjSTIYye3bt3CycmJrZs2McvdnQvHDqOjo43Hnj00b978g+QdxxYtuLxwLqq6eojV1LjtNo169Ruwf+9eIiIi6N23L/4zpyBHjo6ODqtWrKBBgwakpKQQFBSEaRM7ak2aRsqbN1wYMgDjKtaU69oTyKo8d3HVUs6cOcPvvw9BpK6O/a4DqOnrI8vMxKdHJyZOmkSTJk1wdHRk9rx5XB46mFJtnYm+E8irC2fpuGfPV6/d4SNHKOXURtGv9eQZnLp4AXd3d+78/TfxCQlEvHpFK09fdN4ljKXHx7N5+w5cXV2/2r6pqSnLly796n65xcTEhOSYGF77nUeiqak4D03jolh27gYXfL+oKPI56tevz8GJE4nq1BXjGtaEeB4n8t5d6s6do9inQoUKtG3nzJnBfTFr055ne3dhZudAzfFTSI4I5+rw35k2YwYLv6KwExkZCXI5xerYKLYVq2vD3z5eXzxOKpVyy98fu+0eqOtnaVVXGTYK767OJCQk/LCJOsnJyfxv+AiOHM7KOahtY8Pm9es/+fCVkZHBoUOHCAkJwdzcHGdnZ6UULPoaKioqn1WkERAQEMgJOXKS792798HsTGZmJi4uLty4cYO6desq3TiBwkHFihU5eezrmqn/oKOlRdybfxOs0uLjyEhNVVRw1NTUZO7s2bx+/Zrbt2+jp6dHSkoKz54948yZM4jFYkYNH450/nx8emcpNdS1qc+mDeuBLOfttKfnJ/t+8uQJ6amp1J46CzU9PdQNDLH6Yzh3V/yl2EfTxIS4mBgG/f47menp6JUujdq7UA2xREKRipVIDH7OjRs36Nq1K8ePHGHMhAncXjSfhMREZJmZdO3albFjxzJmzJgcXcu0xEQOHztGlcF/oG9gSNzq5dyaM4uGy9cgEolQ1dMjJb1glJ61sbHBsWVLfJcvJiMpiaRXYQr1h/hnT7HIZfxz9+7dCbxzh019uinK7s6ZPfuDe4xIJGLN6lUsX76cE6dOkZGcTK2ps1DR1ERNX5/y/Qbhu33zV/sqXbo0qurqvDhxlPLdeyHLyCD01Aksv6Ltq6qqiqq6OsnhrxXbUsJfIxKL6d3XlYioSKpUrMRst1kFXgIvJ4yfOJGzN27QZON2VLW1CZw7i959+3La0/MD9Yj09HQ6d+vGzdu3MShfkZjHD9m7fz+7duz4Lo6ygICAgDL4ZoV1IWtYIKcMGtCfXr17o6Kji15ZS4L27KRc+fLY2Pw7m3fmzBlc+/dHJhKRnpqKjo4OSUlJGJargCwjnbnz57N3zx7Wrl6NTCbLVuW5zMxMpk2fDoA0Nga1d7Gy0phoMlNTSU9KJCMpibvLlqBZtBhOJ30Iv3yRS//7nYhrVzCpV5+EkBe8On8WeWamQhu8TJkyzJo2jWZ2dvzyx3AsnDvx5pY/C8eNwtLS8rPl2ts7O3PE1RVDq+oYWVUn6IAH6VIpVYeNpFLfrGV7Q6tqnO7cjrd3biOXyXiycR0uXfNGwi2niEQiNq1fz9q1a1m5Zg1n+3TDvGMXEoOeEeZzmuUHD+a63fnz5jFwwAAiIiKwtrZGR0fnIxkwVVVVRo0ahaOjI02aNEEaE42KZpaTnhr9NltycHp6eixeuJDhI0YQduwQ0rg4SExgx3+qzv0XsVjM4IED2eA2jeTw14jEEh6sWY5YIiFUWwcj21+55nkcpzZtOHfmTK7Lhhc0jh0/TvXp7pjUzfqu1po1F892LQkPD/9A7Wj79u3cuncf+wPH0TItTuLLEHy7d8DDw+OLoVgFAZlMxrp16zjv54eOjg79XV0/uDcJ/Lj8qCtAArnnxytDJFDgcXBwYNPGjfy5aDEhp09S19qaBfPmKWI9ExISGDBoECZ2DoSd9UGzeAkSw19TyXUgVsNGIpfLuTVnJn/8738E3LiR7X537tzJzbt3Mapeg4vDBlNl0BBS37zh7vIlSDQ0OGhTE8jSVW62eRcSVTVK/tqMUo5OnBvogmYxE6TRb1HV0aVEyZI0adJE0faFCxcoYm5B5f6DATBr7kjplq3wOXPms05yy5YtmT9vHtNmzCAlKYkSpUqhra2Flsm/M4///H2mV5Zj3KFjRyZNnJj9i53HqKio8Mcff9CvXz9mzXLj2JEDSKVS6tvUp2jRot/Udrly5dDT0+P8+fMkJSVha2v7yVnZSpUqUcfGhst/DKR8/8GkRITzcN1q5s2Zna1+unXrRsWKFfHz81MU1chOufQpU6agp6fH3oMHkcnlVCpblkhNberNzyrYYuHckVOt7Dhx4gTdu3fP8fkXRMQiMfL3HlZkGVl/t+nQgTrW1rjPmoWRkRFPnjzB2LoWWqZZ11GnVGmMrKrz9OnTfLE7J4wcPZqDR49Sul1HUqMiOerszJ7du2natGl+myYgIPCdybGT/ClB9sIo0i6Qv7Ru3ZrWrVt/8r1nz56RGB+P6O4dzJo7YjVsJEeb2VKmVVsg6/NWyqkNvnt2smfPHszMzGjQoMFXZZ4ePHhAsTr1qDVrHgFzZ3F70XwyU1JQU1FBt1JlKvTsgzQuDv/pk0mL/1cCrGjtOrw87Ul6TAyamprY2tRj4fz5H8Tbqqurk5aUhCwjA/E7ZYT0+HjU9Ut80aa+ffvi4uJCUlJS1qzVwEFc2rAGoxrWqOsXIXDBXExKlODA3r0YGhpmy/FMSEjg+vXryGQy6tSpk61Z9k8hl8vx9fXl8ePHmJqa0rp168+WS83MzOTMuXNk6uljZufAswB/7B1b4Ovj/cXS3l/i5s2bdO7WDdTUkSNHnJbOPo89H8W7SyQSdm3fzrgJE/D7ayFa2trMdpuVo1KxNWvWpGbNmjmyTyKRMHLkSFq0aEFoaCibtmwhQc9AcT9U0dJCRU8/x9rNBZmOHdqzf+E8JBqaqGhrEzBnJpomphh26s65Iwdx7tiR056emJmZEXvyJGkJCajp6iKNjSH20UNKtnbK71P4IkFBQezasQO77XsxrpH1eQiYOwu3uXMFJ1lA4CckRxX3xGIxWlpaHzgjiYmJH22DLEfmfa3R/ESouFe4CA4Opk6dOiAW03TDNoxr1uJg/ZpUHz2B8t2yksPur1nB32tXoVO0KElvorC3t2fzxo1f1ORdunQpK7Ztx27fUVS0tEhLSMCnQysG9ezBqrXrSEnMusbaZqVIi4ujoks/MqVSnm7bxJRJkxgyZMhn2w4PD6dRkybo1apD6VbteHPLnyc7tnLs6NGsc8kmMTExdO/Vi5vXrwNgbGLC0UOHKF++fLaOf/LkCR06d+bt27cgEqGnq8u+PXuwsrLKtg2Q5SCPHD0aD4+9GJYvT3zIC6r9UpUD+/YqZvzfZ8eOHUydMweHY6dR1dZBLpNxrk9XOtS3wc3NLUd9/0PN2rVRt66D9XR3AG7OmEx6YAAB765NfiOXyxk7fjxbN29GVVOT9JQUVDQ1abplNwaVqxBy8hhXJ47h1yZN2L93b676KGjffalUyoSJE9nj4UFmegaaJiY47D2MuoEh0rhYTjr8yqZ167C1tcXRyYmIxCQMalgTffMGpYyN8Tx+LNtVEXNacU8Z3LhxAycnJzoF3EeimqWYE3TkICFrlnM31UZ9qQAAIABJREFUDwrxfI2CNv7fk/youCcg8F9yNJM8/V08p0Dh5ebNm0yaNo3Q0FDKlyvHgnnzsu2AfS/KlClDh44dOXLsOFE3b1CsTj1qTpjKzVlTCb/shzwzk9d+56kyaAhWQ0eQEBzEOZfubNiwgd9+++2j9jIzM1myZAmHjh0n5e0bfLp3oGgdG95ev4KJvh5Dhw4lISGB3ceOY/PXSvTLV+TS8CE82LCGKpUrM3/uXHr16vVFm01NTTl66BDDR43i1tTxmJiYsGP79hw5yJAl3Xbi6FEePnxIamoqFStWpHjx4tn+oew/aDCZRU2oPXI8Br/8wt/LltC3f3/8r13L0YqPj48PHh57abptN4a/WJESGcHZnp1Zs2YNI0aM+Gj/mJgYtE1LoKqdNbsuEovRtrDk7XsFQHJCYmIioS9eYP/nUkXynmW3XngfPkBSUpIiHjw/8fDwYLeHB3Y79mJcvSahvt5cHjUM767OSNTVkWVkYOHckQBfn/w2VWmoq6uzZPFiFi1cSPv/s3eWAVFtXx9+hhi6pBsEG0xsRVHBvCqiYnf3FRO7G7D12oUdKIpSol4VOxDELhqUroGZeT+gc/UvtrfeO88XHebsOPucmVl7nbV+q0sX0stVklW4U9HRRVVbh6ysLDQ1NTlz6hQbN27k1atX2PTvx+DBg7+5bPhfjZ2dHSqqqjzy30XFvgMpysvl5bFDOL5VdJIjR85/C7mR/B/iwYMHdHB3x8y1FbYdu/Ay5DRtf/mF8xER/6gMfIFAwJrVqxEXF3N83WrSY6JRUFFBKgVRRgZFeblomFvgOKrEWNOyscXEpTl37twptT/vadPYe/gw5foPxjYzk4c7t2KqqkKf9r8wZswYNDU18fb2Jio6mtDuHgjV1JEUF7F+9epPxhOXRqVKlT6pqvEtvHnzhrS0NLS0tL7JqEhNTSX2QSxIJGTM9kYiFlN1rBe3ggLJyMj4Jq/MgwcP0K9QgTJVSjzQakbGGDZsTGxsbKnH16hRg7SFC0m8eAHTho3JfPKIpIgwak6e/NVjvo+6ujqqamqkx9yjTOUSqcD0mHuoaWjIVFD+bq5du4Zpk2YYVCt5LG/RzBWdChXRsrLGtmNntG1sSb4aScaFiL93on8CCgoKODdowOrNm7Fp3xEtWzse791N3us0WTiMpqYmXl5ef/NMv40yZcqwetUqRowaxfO9uxHlZGNYpgzLt2z+u6cmR46cvwF54t5/CH9/f3QrO1B7/hIEAgFWrdsR2rE1x44dK9UD+1cRHR3N6dOnAWjZsiUODg4oKyuzefNmIiMjCQgIIOLcOQQCKEpOIispEaGWlizeUSIWk/PoAapVHVm5ciU5OTk0aNAAFxcXcnNz2bplC87rNmPauAkAmlbWPPBdxvTpf5Qw1tDQ4Ojhw1y/fp3MzEyqVKmCubn5X74WoaGhDBw8mMJCEeIiEfUbNuT4F5QW3jFn3jw0zMxpvn0vKvr6xGxYw13fZSVe3W/0vJqampL54jn5aamoGRgiFhWSeS8KU9fSiwQ1atSIX8eNY8XwgWjo65OXnk67dr98lZ5zaSgoKDB92jRmzZnDm+gokMLzgMPMnzv3H5MDIRQKeX37JndX+aDvUBXjBo0QpaWRlpyMVcs2pFy7wj2fJQz6htjofxNjxozh7r17nOrQGkVlIQIBrFq58l+vUezu7o6joyNXr15FQ0OD5s2bf5fetxw5cv79fFNM8r8VeUxyCRMnTuRsYgr1lv9RYOJ83270dXP92zw+ISEh9OnXD/2KlQF4HRvDjm3bcHNzAz6MS7x06RLPnj3D0NCQGbNn80YixdilBem3b5IVE42CogLK+oaoGRmReDUS76lT6d69O1WqVKF1wGm0y5b8eCdfucyFYQNIiI//YrLfX0laWhq1atfGpntvHEaNIz8lmQuD+uDh5vZVSg11GzZEt0sPWdy2RCzmYM3KeLi7s2HDhm+ai0gkor27O4/i4jBs6MybO7fIefkSO7uy9PD0ZOjQoaWu3b1793j06BGmpqbUrVv3hw3agIAAAk+doqioCPcOHejQoQNQolSyev16cnJyaNSgAUsWLULnrZb1j/LixQsuX76MiooKLi4upSY+JiUl0dzNjWyxBE0ra17fuYWagQEaQK2aNTl/4QLKysr07tkT76lTPxsr/zn+6TGpUqmUe/fu8fr1a1lo0M/i74hJ/qfxT7/+fybymGQ5/wTkRvK/gJ/1RRkQEMDQ4SNo4LcW43r1eXn6FNdmTOF4QMBfpgP6/PlzAgMDKSoqwsXFhW49e2LUvhNVx5YY6VGrfXmxbzerfH1p1qwZOjo6pf5QZmRksGjxYmIePMDSzIznL1+SpKZBPZ81KCgpERcWzMVxIzG3tiYzIwPdWnWot9QXsUhE5LgRWCgIvqkAyl/BhQsX6Ny1Kx7X78nicB/u2Unu8SNcPBfxxfYt27Qlp3xFakyZAUD282ec+sWN8PDwb07cA8jPz2fdunUcPnKEp8+eUa7vAJRU1Xi0bTMjhw5h6l8gRVeaobR3715+9fKi0pARqJua8Xj7ZsrqlyEwIOCrClVEREQQFBSEoqIinTp1wsnJSfZeSEgI/QcOREVXj6L8fNSUlfh1zBhcXV0/8JCOGjOGszH3abx5F0qqqqTeuEZ4/57479mDq6vrTzt/uZEkN5L/69dfjpy/E7mR/C/gZ35RLlq0CB8fHwAUlZRYuGABAwYM+Cl9f4kbN27QqXNn1EzNUFLXIPXeXSRiMa77jlKmSkliTPr9aIK7dkRFUxMTIyNOHDuGo6PjZ38oQ0JC6DtwEOLiIrTt7HGaNR+9SlU4WKMS5Xv3I/lsGPmv0ygqKADApqwdhw/sx9LS8qO+YmNj8Z4xg2fPX2BrY83CefP+slLrt2/fxtXVlXZnImSV624vXYj241hOHf+yQR8cHEzvPn2wde+Mhrklzw7soXaVKuzds+e7PeZFRUVYWllRd6kvlq6tAHhx8jg3Z03j1csX39xvXl4ekZGRiEQiatWq9UVJu9IMpSbNm0P9xrKY9LykRE64OjN+/Hj69+//2fj6Xbt24TVhAhZNmyMRFZIUeYltW7fSunVr8vLyqOzggHW3XjiM/hWJSMSFUUNKCrmIRKxYvpyePUu89C3btkNUpz5Vho6U9X3SpT4+Cxfi7u5ORkYGx48fJzMzEycnJ+rXr/9N6/QOuZEkN5L/69dfjpy/k3/Os2Y5fwlTp07lzp07BAUFcffOnb/MQAYY6+WFSYuWND90gqa7D+AwbgIKSkokXTwvOybp4u8ItXVoE3qBwjL6jJ848bN93rhxg959+lDWsweNVm1Ap1wFzg3px/Pjx0AqpXzPvjTauBVRXh6+Pj4cDwjgXHgYjx8/plHTpthXqEDb9h149OgRr169ok27X3iuoIxJv0E8V1CmTbtfePXqValjP336lAkTJtC3f398fX0RiX6sXLSjoyMNGzfm98F9ebhnB7eWLOCR/04m/vrrV7V3c3PDf88ezNKSEVyMoI+HBzu2bfuhkJKCggLExcVoWvyxodCwsERUWPDN5xsfH0+TZs3p2acPg4YNp279Bly+fPmb55SXl4eqwR/GtUqZMiAQsGHHDho3aUJ0dDRSqZQ1a9ZQoUoVLK2t6dK9O3FxcUyZ6k1N75k0WLmORuu3UHHgUCZMngLAw4cPyc3OplzPvggEAhRVVCjXvTcCRSVqTJvNeC8vjr/drNhYWZJ25TKSoiIA3kTfI/fNGywtLUlMTKRp8+bMXrqMjceO09HdnfFeXjx8+PBvr1AqkUg4cOAAc+bMYcOGDf9ZA0yOHDlyvga5J/lfwP8Xb4K5hSX1/NZi2sgZ+MMDqKCoiHHtuojFYlJvXqfeYh+sWrXh+YkAnq32ITkh/pPepAkTJhD8+CnOG7YCIJVIONm2BbkJ8VQZMgKHkWMRiwo5VMuBkydPUqdOHa5fv067X37BrlsvDGrU5FVgALn37tLD05N9IWG47D+KgqIiErGYcM+ODHbv+FHM9uPHj3Ft2RKN8hXQKleRpNAz1HJ0YL+//1c98pdKpbx58wZtbe0PCnTk5OQwZ948LkZGoqOtzZgRI+jatevfev0bOjuTZ2JG3SW+SKUSrkwYi15WBmdDPy1tdvr0aWbMnk1KSgoVKlbEpXFj1mzYgFb5CjTZsBVFVTVuL1lAWkgQUbdvo6KiUmo/77xJe/fuZdGyZaSnZ6CspMjr/AIarPkNdVNTbi9bTHx4CK0DTnNr4Ry0EuPo4enJ7HnzcPSajLqpGQ82rkWnSMSj+/dpExiClrUNACnXrhAxsDdJSUnMnj2b9evX47x+i+wevbd2Jc+OHeaXkPMcrlsdcUE+w4YNY9DAgbi2agW6emja2JJ06XecatSgmqMj586fJ1VBCeetu1FSVSUuLISL40o0trt268YqP7+vukfg5372pVIpAwcPITgsDKOaTmQ+fog6UswsLMjKzqZOrVrMnT37p8V2fwvBwcFM8vYmKT4eW3t7Vvv6UrduXbkn+f/Jd//3IPcky/knIPckywFKPIZeEyZgXbYsVjY2DB85kpycnB/qUyQSkZCQQNFbb5upuTnJkZdk7ydHXkJJWZmDBw7QopwdKdeuUNN7JlatSqpyZTy4j76B/if7Lyoq4mRQEIrvSYIJFBRKqoGpqWHb0QNxkYg7y5ego6cnC5vY4++PSSNnakyehqVba+quWEWxkhLR0dGoGhvL4oEVFBVRMzImNzf3o7F9fH3RquxAky27qeU9k6a79nPhwgXmzJkjO99PERkZiUO1alSsWBFrGxvWrFkje09TU5NlS5Zw6dw5gk6coHXr1qX28eTJE1asWMGiRYuIjIz87Hg/ytZNmxA/esDR+jU4Wr8mCnEv2fLbb588/uLFi/Tt1w81F1dqLlzGywIRPr6+iCVSKvUfgrKGJgqKilQaMpz0tDROnjz52fFPnz5Nr969ETnWwKTfILIUlZDm5HDavQ1H6tUgPjyYRqvWo6Knh3V7dx49eMBO/71UGDQMe8+emDm7UH/VRh7dv4+ahgYvgwKBEqPx1ZlTWNraoqCgwMu4OHQrVuaS1xhuLVnAlWmTiN64FqN69clNiEdcWED1Sd78tmkTT5484Vx4OAM7dsDVyoKaVaty7cYNAmNiefEmncxXLynKzgLAorkrSmrqVJ80jRNBQWzatOnnXZxvIDQ0lNOng3DZvZ8Ga3+jqvdMkhITybQui1aHzpyOvEKnLl1++InIt3Ljxg369O2LtmtrGq3bjLSyI527duXFixdf1V4qlRIcHIyfnx/+/v7k5+f/yTOWI0fOfwW5BJwcAKZ4e3M8OIRqM+ejoKxMyIrFjB47lm1btnxXf/7+/kyaPJnCggLUNTVZ6evL0kUL6dmrF9kPYlHSUCcuIpz58+bh7OyMs7MzEuDwyhXkxr2iIDWVl0GB7N6165NjnDlzhozMLMThYTw/cQyj2nV5cfI42U8fg6IiJ9u2AIEALU1Ndu3Ygba2NlCSkCZ8WwABQFFZiFBTCwsLC87t3Ut8RBhmzi4knD9LwuWL1Bs25KOxE5KT0XOshuBtKIOGuQVCXT0279jB3ehoDu7bV2oJ59jYWDp16YJUocQAN6hZi/kLF2JqaoqHh8dXre21a9fo1LkzWja2KGtq4evnh6+Pjyxe9mchlUrx8fHB18+PwoICtPX0qF2zJpMnT6Zs2bKfbOe/dy/mzVxlyZjPA45gU9ad1OtXyXr2BHNaAJD19AkA48aPp0aNGtja2pban8/Kldh07Ez1iSWJghbNXTnRrCFLly5l8pQpVJswFYPqJdq8abdvYmhigqhIhNp7sndK6uoIBAImjB/PosWLSTkXjkQkIifuFQf27Svp18wMxcdPcBzzK8mRl5FKJCgoKSHOyye8f0+M6tTDvlsvEk4FEhUVhYuLC5MmTeLy5cts27GD5rsPUqaKA+LCQsJ6e3Jv3Spqz5rPm+h7FOfnYVS7Drlx7bkUGfmR5GJ0dDT79u2joKCAJk2afLJk+4/w/PlzdKxt0LErKR705MBebNq74zSzpCKiVau2BLo6ExkZibOz808f/1McOnQIk3oNZPeLcd36hN25TWBgINWrV/9sW6lUyoSJE9m7bx/6lauQ9eIFv23ZQmBAgFy2TY4cOT+M3EiWI4tTrLvUD/NmJQaMUEeHwP49v6u62cWLFxn366/UmDwdk0bOxIWeYdjw4ZwOCuJ0UBCHDh2iqKiIFrt306JFC1m7FcuWUaFcOcLPn0dDTQ2fgwdp2rTpJ8dJTU1Fx8ICS4+uXJ05FWlxMQIlJRSEKjjNmoeyhiZRPktwsLL8IHGqmYsLAePHY9HCDYPqtXh29BDpz54ycNNvmJmZsWT0MAQCAVKplMmTJ8vk6N7HsVIl9p85Q/ne/VDRK0PihXMUvk6j0ZqN3PCexL59++jdu/dH69xv4EBUjU1wGDWOgtdpRK30QbdyFY4HBn7WSE5KSsLPz4+XcXFcv34dkxZu1Jm/FIFAwOP9e5g4eTIdOnT4qYbBtm3b8Fm5kuoz5qJtY0vMb+s4d+ky59v9wpHDhz6piFIoEqH8dkMCJVJ0SuoaVB46gutzZ5KflopQW4eHu7ZTtrMnmbducvr0aYYPH15qf5lZ2ajbVZC9FuroIlRXx8jIiKlTprB09nRSr0ZSnJtD/Nkwtm7ZwvUbN9i2ZSO6FSqhYWpGlN9yDE1MGTBgAM2bNyc0NBRFRUXatGkjM/hHjx7NseMneHn0ENoVK5P8+3lUVVVJvnKJsp26UmXEGIpzc8mJf4WBgYFsPi9evEDL2FiWfKqoooJp4yY8ObgPcWEh8eEh2Hbqgm6FSuQnJKBlbPDB+V2+fBmPLl0wqFYDoV4Zdg0ZwkQvr58uy2htbU3myxdkPX2Cdlk7RJmZ6Ff9wwhVKVMGoYY6WVlZP3XcL1FcXIzie0VzBAoKKKqpUlxc/MW2Fy5cwH/vXppu90ffsRqFGelE9OzCypUrmTZt2p85bTly5PwHkBvJcpBIJIj/54dKSa0khOF7YgHPnDmDWcPGlOtRYiRWGjCE1HNnCQkJYeLEiVSrVq3UdoqKigwfPvyTxtL/UrlyZdKfP8PBvjzuF6+T+fAB4f174TRzLjbtSvR01U1MCO7akZSUFIyNjQHo0qULjx4/xm9kiYdYRVWV9evWUaVKFapUqYKnpycvX77EysqqVAUMgOHDhxMQGEhgKxfUDI3IiXtFlWGjMGvclGcOjjx79uyjNk+fPuXJw4cfxMRKi8XEbF6PgrXVJ88zOTmZFm4tkZTRR6+mEyI1dVJv3kCcn4+Sujrmzd24MX82ycnJP2QknzhxgvPnSwzD7t27c+DIUex79cO2fUnVwQYrVnO0YS0M69Rlsvc0zoWHfdA+Ly8PNTU1XJs355SXF2bOLuhXrY5AoMCTg3upv9SX6hOm8nDXNgpep1Gue28cx3oR0d0DiUTyyXm5ujRl5W+bMG/mirZtWWI2b0AiElG9enXatm2LjY0NwSEhKGsY4Hn4MA0bNsTV1ZWk5GQO9S/xrptbWbHffw+ampqy6/y/GBsbEx4awsaNG0lOTqbS6FG0a9cO15YtSb97m5gNa0iOCMfC2JiOHTuSnZ3N6tWruXLtGpkJCSRFXsKkXgPEhYWkXPoda2Mj4iPCUNPTR69yFa7P8ibp0gUG/094ydTp07Fu707NGSWFUuLCglny6yj69u2LlpbWd1/P/6VFixa4uroS3qsLhk51yHn2hMfxcVi1boempRWx2zZRnJ//yc/nn4Wbmxs7e/fm6dFDGNepx8ugk7x5EEuzZs2+2Pbhw4foWtug71gyZxVdPQwbN+HBo0d/9rTlyJHzH0BuJMtBSUmJ5i1acHP5IlTmL0GgpMydhbNxqldPFqLwrf1JCgtlr6VSKcWFBV+drPS11K1bl7Fjx7Jy+EB0rW3ISU5CQQBK7xv76iVe8PeNfYFAwDRvb4YMHkxKSgpWVlYfGCOWlpafNI4B0tPT6dDJgxyxBKGmFvmpKTRavRGzxk0oSEsj/X40lu0/flxe8FaCTvhecQqhri7Fefl07tSp1LFycnLo378/GXl5VOrTH3vPHlQZNopT7Vx5fjIA+y7dSbwQgZKysmwT8L8EBAQwb+EikpKTUBGqUK9OHRYvWvjBOS5duhRfv5WYN2tB4es0tm7bjm3Zsii+r4whKLmWOpUqE3/4gOzPV69eZeiIEcS9eIGmtjZzZs1i9MiR+I4bUaLmoKCApoUll7zGglSCQEkJ2w6dKOvRlZiNa0l/8uizBtHMmTO5ffcuJz1K1lRNQ4MtmzbJKiK6u7t/VD5cKBSyfu1aFsybR25uLmZmZl91/xkZGTFjxowP/hYWEsLyFSt49fQhzi2aMXHiRKRSKa3btSM5Nw/9eg3QsUnkwojB6NeoSe6rlyjk5XLg3DkUFRWZPNWbO7u2YWZqxsrDhz8KIYiPj6dS74GywitGdeojlUp58uTJJ0NQsrOziYqKQkVFBUdHR4RC4RfPTUFBga2bNrF//37u37+PfoN6XLh4kVNtW6CoLERJUYH1a9d+9t7/M3B1dWXB/PnMnDWLIpEIdU1NNm7Y8IG2t0Qi4eDBg9y/fx8jIyN69eqFtrY25ubmZMXHkRsfh4a5BeIiEem3b2LRoHTJPZFIxNy5czl49CgA7u3bM2f27E8mjsqRI+e/jVzd4l/AX5HhnJ6eTv9Bg7h4vkSOrWbt2uzYuvWzmrOf4s6dO7Rq3Zpyvftj3LAx8aHBvDx6kPCwMMqXL/9NfX2NVurVq1eJiooiMzOTsLNniY2Lp84yP5Q1NLk1fxZ6eblEhIX+tOp6s2bNYl9wCE33HEQgUCCkuweF6W8wquVE+u1blLex5vjRox/98BYUFFCnfn2UKztQfepMCl6n8fuooTjaWBN44gQAly5dYta8eSQmJmJvb09CfDwp2TnoVnEk7fZNdMtVwHn9ZsL6dKMwLRW9chWIv3ieJYsXl1oC+p12csUBQ9ApX4FHe3aS+fgh2urqnD97FiMjI5KTk3FwcKDRqg2YuzRHKpVyY850ci5fJPV1GnXnL0HLxpaYjetIOBeOTrkKWKurEhIURFxcHI2aNMHUrTU2Hl15fec2d5YtZNfOndSpU4fU1FSeP3/OnAULSIiLx9rGGtdmzVi7bj2iwgK0dHRYt2YNrVq1KnWt313/sLAwfp0wgYTEROzs7PBZupQKFSqU2uZbKCoqYtOmTdy9exdDQ0OGDh2KhYXFF9tt3bqVectX4HosCKG2NsX5+QR1bIWiihp6FSuRFnmRXl27Uq1qVcZPmEBhfj6q6uqs8vPD3d2d3NxcMjMzMTY2pl3HjqRo61J3iS8KSko8PrCXG/Nng1RCtx49WL506Qf30q1bt+jWsycZb94gEYupUrUqB/buxcjI6JvPXyKREBUVRXp6OhUrVvyuz/vPIj8/n7S0NIyNjREKhbJr/+bNG/oNGFiiylHLiazHj9BTVSE4KAhtbW26du/OjagoDBs0JvvBfRSzMgkLDi71XLwmTODwqVNUGTsBgYIC0X7LadeiOatXrixlRn8/cnULubqFnL8XuZH8L+Cv+qKUSqWkpaUhkUgwMjL6oZLCoaGheE2aRFJ8PBY2Nqzy8aFhw4bf3M/XGMk5OTl06daNmzduIFRTQ5Sfj+RtPGMlB0f27NzxU71jvfr04am+ETUnTwegOD+fEy4NUFZSRElJiRbNmrF08eJSvfAxMTF079WLhLfay81atGDLpk1oamrKNhdW7TthWMuJ6PWrkYhEtDx6CqGWFnlJiZzx+IVyvfrwYMtvtHJ1xcrKiubNm38y0cqzRw+e65Sh9qz5ABTl5hDg0hBVbS28hg5l9OjRsiImHlfuoPRWKeTFqRPcWziXYgGIcnKRFBehXdYO7bL2JF2I4MypU1StWpVdu3YxZ4UPLU+FyZIYI6dOwElVmQ3r139yDUUiEW/evMHQ0PCzHl5FRUVSUlKoUasWxk2aYdSgEYnhIWTfvsn5iIgfKoMskUjo0asXkTdvYty0OdkPH1AU/4rQ4GCsra1lx4WHh7Nl2zZy8/Np5uzMyJEjWbx4MfsuRdJkyx+JpZe8xiDU08Np+hxenDzO7bkzKMzPp9rEqZg1bkpceAhRK1fQpUsXDh08iEQiwdDEhFnTpzNtxgwE2joI1NRJfxiLw4gxGNZ04vrUCXh2aM+iBQtk61bTqTbqtetSa9Y8inJyuDRyCNUtzPD/TJLrv5F3n/0DBw7Qq08fmu8/io5dOYrycono1ZXubq7Mnj0bkUjEli1biImJwcjIiKFDh5a6YRCLxVhYWlJvxWrMXZoDkPj7eX4fOZhXr159lTf+r0ZuJMuNZDl/L/+JcAuhUPivfpympKT0U2ITc3JyCA0NJS4uDgcHBxo3bvyRgfI94RWl8e4RuEQi+SEP7jtDXUND45OFGLynTedJSirtzkSgamjEg+2bub92JRFnz1K9evWf4kFOSkoiISEBGxsbKpQrx/UzwRTn5yOVSri32o+i/DzKDxuFmokpZ3dsoVefvoQGn/lofevWrUtsdDTPnj1DTU0NS0tL2Tlu3boVfac61J5dYtAmX7mEVCxG+Pbaq5uYomltTcyGtfTvP4C1a1Z/cSPzJj0dVRt72WsldQ2UVFVQ1StDXl4eWlpaVK5cGSVlZV4EBWLn0RVJcTEJwacxMTUhOT2dNsHnQCxGWVOLS16jaduqtWzDIxQKP5qDQEHhq+5ZfX19nj17xv379zE0NMTJyenjvgQCtm3bhrZ9eeosXoFAIMC6bXvCPNpx8uRJfv3KQiulERISwrnz52l59CSaltZIxGIuDOrDqtWr+W3jRgCOHz9O9+7dse7QCVULG5avXs2TZ8+4evUaKS+ek/HoIbrlypPz6iXJVyNxGDm2ZJ3V1BEVFmJQqzYVepeQ6gHAAAAgAElEQVR4+CsNGEJcyBkOHjxI7bmLUFBWJj4shKnTphFy5gwHDhzAx8eHxus2Y9a4CQAVR4zh5Ob1rFm1CoBHjx6RnJhA+3ETUBSqoFhGhfKDhnJlzvTPrrdUKkUqlf60pylfQ2RkJD5+frxOT6dhvXp4T52KqqrqV7d/dy8kJCR8oMqhrK6Bfp16vIyLk53zpEmTvthfYWEh4uJihO/pQAt1dJBIJKioqPyj1DBu3bpFVFQUpqamuLi4oKT0n/ip/oAfcdLIkfOz+E988kQi0V+u/fkz+RnehOvXr9OlWzdyMjMBUFBWplatWhzavx/193SG/wqysrJITk7GzMzsi8oZioqKCIVCcnNzP+lJ/v3yZaw9PFEzKonJrdBvEDHrV/PixQvKlSv3Q3OVSqUsWbKEFStWAKAkFDJn1izUCws41cqFgswMBIpKVBo0jCrDRwMlElaBLZty9epVHBwcPugLSr78zczMAD7Qor54ORL1ajVkr7VsyvJoz04KM9JR0dUj59VLcp48YeyYMXh7e39RxzopKYn796KRxMZi0rgJOvblZclZ6Y8f4+joSHZ2NkKhkKVLluA1YQJxRw9RmJGONDuLndu3M2DwYK5N8cK6gwevo+4QHxbC6sOHZfdj/fr1EWWkc2vRPGw9uvD67m1enjzO3G3bvnjP7tq1i4mTJqGoooIoN5dWbdqwdfPmD6TzFBUVyc3NRVFbi+TIS6iUKYNu+Yqo6uuTnp7+Q5+Lp0+fomlkjKZliddYQVERvWo1ePb0oazf6bNnU6HfIKr+WlL50axJM/x7d0WtjD6mjZwJ7d4JLWtbsp4/RUlFBcNaTryJjiLabxnaWlqyJxpQcv0lxcUoa2lzY8FsxAUFIJWipKrKnTt38PDwwMfHBx37P+5ZcUFJLP+7+bwzHHLj41EzNJL9X11Do9S1kEqlrFixgrUbNpCfm0vtunXZuG6d7P77s7hy5Qod3d0xb+6GRkUH1u/YydXr19nv7//Vhvq7z76ZmRmZL56T9fQx2mXtKc7L4/XVSCxdW3zz9a/XsCH3VizGaVHJhitq2SKc6tVDKpX+Yzy2Pr6+LF68GG1TM/LS0qhdpzb7/f2/aYPx/4F311+OnL8TeTGR/wC5ubl079kLw2aueFy9S9tToWiYW3AnOobFS5b8UN/Z2dnfpICxdu1aypUvT4MGDahQsSKHDh36ofEB9HR1yH72VPY6LzGB4oICdN9LkPteAgIC8Fu1mkarN9Dpym2qTZ7OjJkzGTZ4MAUZ6dScOgN1U1PU3nu8q2pggEAgkBUhycrKYsCgwVhaWWFTtiyTJk/+5KbtZVAgyVcuIxYVoqSmiigzgzMdWnNx2ADCurnTuGEDpkyZ8lVeloiICJS1tTFv0ZLwPt042qAmsds2IS4oYNjQIR8UKunduzenTp5kYLs2eA0exPmICOrXr8/xo0cxys3m1ozJ5J8NZcf27R+EzVhZWbF3zx6yzoUT3KUD0SuWsGjhwk8WQXlHbGwsEyZOpObMubhH3qb18TNcuHqV1atXf3SsoqIiiRd/5/yIQQR3bk9Yr64k3rhOgwYNvrgGn6N8+fJkxseRcu0KAKLMTJLOhlH5vbj5N6/foFP+j9hn3bf/163iSEPftTTwWY1Nx05om1ugo67OmU7tCOnWiRp2ZWnTpg1v7t7mts9SUq5f5fayhWQ+jEWUnYVBtZp0unKHVkdPoaCiyqlTp7Czs6NqjRpcGT+apEsXeH7iGDFrV9Kja1fZ+MbGxrh36sSV8aN4sGsb99au5N7KFYwZMaLUc9ywYQO+a9ZQyWsKjddv4VmBiM6enhS+l1j7Z7DMxwfL1u2ot8wPx1HjcN66m3Ph4dy4ceOb+2rRogUtW7bibK+uXBo9lFCPdmiJixk7duw397VpwwZMlRQ51bYFJ9s0x0BczNbPFMb5q7l58yaLFy+m0ar1tDp9llaBwUQ9fsyqt08S5MiR89fyn/Ak/9d59OgRGW9e02zKdJTU1NC0tKbigCHc8VnKtZs3v6vP27dvM2DwYF49f45QRZUpkycxatSozxpvp0+fZu78+dRZsBTjug14EXSCkaNGUa5cuR+SnfIaN44uXbsilYjRtLLhxeH9NGjcmBo1any58Rc4d+4clq4tMW9aEsNo37U7L48cICgoCJOatbD37Enmo0fEbt+CUe16qJuacWf5InT09KhUqRIAg4cO5daTp9RZvpLi/AIOLJ2PQCBgyeLFH4xVs2YNUvPziRjUByjx9kuKihjapzcSiQR7zy507dr1q1VCJBIJCkqK1JmzEMeRY0m9fZMnB/dTWUOVObNnf3S8k5MTTk5OH/ytXLlynA4M/Ow4DRo0IOrObbKzs9HU1PwqT+HNmzfRNjWjrHsXALRty2L5S0cir1374LjHjx+zdt06qk/yplyPPmQ9eUx43+40c3H5rhj393FycmLkyJGsH9ofgwoVyY6Px8rM9INH91WrOnJl5QqeHD6AUEsLJQ1NBIqKZD55hLigADNnFwpev+bhb+uZO3eO7NG4gYEBiYmJHD9xgif7/XmwfTMKyspoWFhhXL8BCWfDuDh6GM4btlCuR2/ibl5FUVGRvbt3M2LMGC6OHoaKigqjhg1j/PjxH8x7zerVLFy0iODAY6gIhSxdvIhevXpx8eJFzp49i4qKCp06dcLOzo49+w9QcdBwyrp3BkC3YiWONa5DdHQ0NWvW/KH1+xxpr1+jXaO27LWmpRVCdQ3evHnzzX0JBAK2bPpNpsph1KQxffr0+a7QMGNjY4KDgnj58iVQssn71P0qlUpZv349O/fupUhURJuWbkyfNu1PDd2LiopCz9oGsyYlai/qJqaYtmjFrbt3/7Qx5ciR82nkRvJ/gHfhFAUpKSjblEhK5ackIxBAme/wtqamptLF0xO9Rk1wW7aSjAexLJw7EyMjIzw9PT/ZLjQ0FItmrli3bQ9Ahd79SQw6SURExA8Zyc7Ozhw6eJCVa9eScfE53X9px9QpU2TG5NmzZ/n9999RV1enS5cuWFn9oUkcFRWF16RJPH36FEtLSxYvWEDdunVl76upqVH45hlSqRSBQICkqIic1FSi4uNQNjZBKpVSbfwkcuJeEtShRKFBV1+f3Tt3oq2tTXp6OuGhobTwPyTTcgUp++ZMZ/GiRR9sKqZNnUpEq1YIy9qjamTEm6g7dPTwYNGiRd9VItzZ2ZniadO4tXg+dp7dkRQW8ubWdXquXfsdq/xpJBIJvr6+7PT3p0hUhJtrCxbOn//ZMB4dHR3y09MpzMxARafkHsx5/hy9MjofHHfz5k3UDQwo37NvSTv7cth17U7h49ifMvdZM2fi0rQpUVFR6Ovr0759e9m8pVIpSoqKFOXmYli9JrmJCbwIDKBCv0G8PHmcMx7tMHSqw+srl6hgb0enTp0+MKBMTU0JDwtj+syZ/H7xImpl7Wi2Yx8KiorkDRrGqfYtSbxwjrzEBEzeGnxCoZDZ06dz6tQpYmJjyczIwN/fnzMhIeQXFOLazIUhQ4Ywe9YsZs+aJRtr+/btTJo8GbN69RFlZbFqzRqOHj5MsbgYNZU/HlkrClUQCARfVajjR6hVvTqBx45g84s7qvr6PD7gj1hUKNs4fisKCgp07979p8xNQUEBGxubLx7n5+fHipUrqTBkBMoaGuz+bT0pqals/ExC6o9iYGBAbkoKBWlpqBoYIJVKyXoYi5H9pytcypEj589DbiT/B7C3t6dRkyacG9qfSkNGUJCaQvTGtQikUsaOHv3N/V26dAmRRIrTnIUoKCmhV7Ey6fejOXLs2GeNZKFQSHH2H9W8JGIxRbk5P8Uz07hxYxo3bvzR39esWcO8+fMxrVufgtdprFm/nsCAAKpUqcKrV69o7+6OQYPGVOneh+RLv+PRuTNhoaEyebEePXqwvWVLrs+ZjnHd+rw8fRKxSIRYTY2858+4PmMKZs3d0DS3RFlZyJo1q3Fzc5MlAb0zRhRV/9BuVlRVLTVExdramoiwMLZv3056ejrVu3Wle/fu353AYmFhwd49exg4ZAin9+5CWShk5vTpH2kK/whJSUnMmzePo4GBOIzxQllLixPrVvFmxAh2bt/+yXbNmjXD1saaCwP7YPlLRzLuR5N08TzD/6fQhpaWFoVZWYgyM2UJV3nxr7DV1CQgIECmaODp6fndiVfvyqL/L48ePSL49GncDh1Hr0KJcaesrU3azeu0PHyCkE7t0HryiO79+jFs2LBS72OhUEjM/fuIiouxrF4LhbcbN3UTU9QMDHm4eztpN66xbP9+1q1bx+w5c0BBAWV1Daza/MLFsLNkbN6MbUcPVEzMWbB0KU+fPWPpe2FS2dnZTPX2xmnWfMp26lIi4TfLG69Jk/mldWt+27wR7bL2aJiacW/VCkzMzUstpvIzmTVzJrc7d+ZkyyaoauuQn/4GXx+fDzao/3TWbdyIo9cU7Lp0A0DHvjxH+vVg8cKFf5rqgqurK5UrVeRc326YurUmM+Ye2TH3GO3n86eMJ0eOnM8jN5L/AygoKLBr+3ameHtzauUKxGIxFcuXZ/myZdSpU+f7O35fbUIqhS8Yc56enmzb3ppbSxZgVLce8WeCEL1Oo23btt8/h8+QnJzMvHnzqLvEF6tWbZBKJFyZNI7J3t4EBgRw9OhRVAyNSlQTFBSwcG1FztMn7N+/n5kzZwLg4ODA1ClTWLBkCQnnI9C2LUuz7XtI/P08WccOofr0MTfDQzC3sODgwQMfhQAYGBhQrWZNbs2dQY0ZcxEX5BPtsxQ3t5alGr9mZmZ4e3v/tDVo0KABMVFRvH79Gh0dnQ+S4n4Uf39/vCZMoFgsBomE9Jh71J67CG0bW4J6diE1NRVDQ8NS26qpqXH86FFmzZnD7TMnsTY0YH1AwEeFNpo2bYpd2bJcGNIXq46dyXwQy6vg09i5uDBi9GgMq9Ug69lTNm3dyplTp9DR0Sl1vO/h9evXADJVBQDdchVIungBBSUlkEoYMKA/PXv2/GQfEyZPptjIGLumLYgPD6HigMGoltEn5doVcuLiMFFXw2/XLgoLC5kzdy4VBw0ldusmXPcdRtPSmqAOrag8eDiOo0tUPEwaOrNtUB9aurnRvHlJCFBCQgLFRUUyWTOBQIBp0+bcDg9h0sSJpKWlsXvYAABs7Ozx37v3m0vNfyva2toEBQZy4cIFMjMzqVatGnZ2dj+tf4lE8lUhEz9Cfl4easZ/aC2/SwzOzc39rJFcWFjIwkWLOBMWhopQyIA+fejTp89XbXaFQiFHDh5k+fLl3I2JobqNFaOXL8Xe3v6LbeXIkfPzkRvJ/xE0NTVlMlI/SsOGDVFRUuTa9MnY9+5HxoNYnh3az/gvCPJXq1aNvf7+TJ42jZvHDlHWzo5Nhw//aRW+Xr16hUQiwbzZW+NBQQGTJs14tsYXKPkxE+rqyvR9BQIBQr0yssp476hfvz4SkYgWuw+gYVZS5e3hzm2Ym5tz9AuJhwKBgF3bt9Onf3/OvK0Y19zVFT+fFaUeX1BQwLVr1ygoKKBGjRoYGBh8/wK8N4ef0c/7xMTE8Ov48dTwnoVdZ0/S78dwbkg/HvnvxNylBcBH6/i/6OnpscrPjwsXLnD27FnCwsLQ1dX9wCBQU1PjXHg4w0eO5ObhfRjq69Nr+nQWLFpEs90H0KtUhaKcbCJ6eeLr68vsUmKtvwWJREJsbCzZ2dmYmpqioqZG7PbNVBo4lKKsLB7v24Oiigrn+/fCSFePDh06fLa/6JgYrIaMxMKtFak3r3GqnRuq+vrkvnqJu3tHli5Zgq6uLlOmTMGiaTN0ytqjWkZfprhRmP4G3QoVZf29+3+Pnj1Zv24dTZs2xdjYGCVlZRLOncW2owdSqZTE82extLRCWVkZXx8f5s2dS15eHoaGhn+ZtJZQKJQZ8j+TpKQkevTuTdTt2wA4Vq+O/65dP70QSoOGDYnesAa9SpVRUlcnyncpVra2X9TmHjl6DGEXL1JuwGBEWVlMnTaNwsJChgwZ8lXjampqyu7j/7JOshw5/wTkRrKcb8bAwIBD+/czaOgwQrt7oKquzszp0+ncufMX2zZt2pQrFy/+BbMsCTcQCAQkno/AokVLpBIJSRcisLG2AUpCNJYtX87TIwexaNGSpEu/E3/+LE0H7vignxo1atDQ2ZnzA3ph7dGVnBfPeREYwPKDB79qHqampgQHBZGWloaSktInvVBJSUl06tKFp0+eoKCkhKpQhd07d9CyZcsfWoc/g+vXr6NraYV915I40TJVHLBu157kyEukXbmMrX25r5IZ27JlC97TpmFWrwGizEzWrFvHkUOHqF37j6QvAwMDvKdM4ebNm+jo6PDo0SN0rKzRq1QSMqCsqYVB/YY8evLkh84pNzeXPv37c/7sWQC0dHQZO3o0fitX8XTPDkQ5uaipqWFb1pZqDg5M8/b+YoiHoaEh6feisO3oQbPt/tzf8hvR60o2q8eOHiUkLIwdW7eiqqqKKCsTbTt7CtJSSTgXjlmTZuiUr8gj/12YNmqCopoaD3ZsRVlLC7OmzRg+chSS4iJU1dXp0L49R2Z5k3DmFKLMTDIfP+TIexs4TU3Nf5QO8I8wcMhQkhHQ9lQoANe8JzJwyFBOHg/4qeOsWbkSzx49Od6s5OmQqYUF+/39P5s4m5SURMDRIzTffQCDt3KOyhqarF6//quNZDly5PxzkBvJcr6LqlWrcvXyJfLy8lBTU/tHCr+bmJgwbdo0Fk4ch3mDxhS8TiXv5Qu2HjsGQL169Vi+bBmTp0zh2ixvFBQUmD59Om5ubh/0o6ioiP+uXSxavJjLly9go6ODz6FDNGrU6KvnIhAIPhl68I5xXl5kqqrRPiISJQ0Nbi9ZQL8BA3j6+PG3n/xXIJVKkUgkX62W8T5aWlrkZ6RTlJeLsnrJo/ucuFckXjiHta0t/nv2fLHfzMxMpk2fjtPsBTIP6I3Z05gweQrnwsNkx+3evZv+AwagoqVNQXY21tZWZL56RfbzZ2jZ2CIuLOTNjas0bfz116M0Zs+dy53HT2gTGIK6mRl3fZaxfuNvBJ06yZMnT9DQ0KBx48aoqal90C4nJ4etW7cSFxeHvb09ffv2lcUnz5o2ja6enhSkpaBiZMKLgMMItbRx3X8EdRMz7q5cQd8BA9izcyebNm/h6aH9WLZqy4Uxw9E0t6QwLRWJRMyxpvVKYtkLCqg+YSq3Fs+nfN8BWLdtT8rVSI4sXcCM6dNJT09HKBTisXH9D2uEi8Xi77o3/kzy8/O5evkSzXcdkHnbHSdMJaxXV/Lz8z+6Nj+CkZERIaeDuH//PsXFxVSsWPGL/b+TfXz3xKnk/2bk5uT+tHnJkSPnr0NelvpfwH/5kdvXlKX+EiEhITJ1i65du2Jra/vB+xkZGcTFxWFqaoq+vv7PmPZ3YV+hAlWmzcbSrURjuDD9Dcec63Lr1i0sLCx+2jhisZj58+ezeetWRIWFNGjUiA1r12JsbPzVfeTk5NC0RQvytbSx/KUj6feieBkYwPp162jTpo2sCEBOTg4xMTGoqKhQpUqVDyqH3b9/H2dnZzpeuIqKbol3PS4shLuzvHn6+BEAiYmJ1HJywmH8ZMr37EN+WirnB/RCWyohNSMDo7r1yXr4ANUiEWHBwV/ciHyOuo0aodvJk3I9egMgKS7msJMDRw4f/qTcXE5ODm6tW5OSnYOugyNpN67hUL48Rw8dksV/X7t2jW3bt5OTm8u169ex7D+E8j37fDQGwORp00iIi8fIyJD6dety4NAh9GrWRs3QiLSb1xGLCrHz8ORl8ClaHTkp25xeGjeCFlYWLF269JPnJ5VKCQkJITY2FmNjYzp27FhqsmFISAjjJ04kKT4eSxsbVvr4lJoU+2dT2me/qKgIC0tLGq5aj5mzCwAJ5yO4OGYYca9e/dSY++/hg7LhM+dRlJ3NpVFDqG5p/l1lw3/0u18sFnPjxg3S09OpVKnSvypxUl6WWs4/AbknWc7/e1xdXXF1df3k+7q6uj+l8MiPoqOrS/aL57LXWc+flfxdR4e8vDxWrFjBzbt3MdLXZ9zYsZ+U00pISODevXtoa2vj5OT0UUnb5cuXs2XXLqrPmo+qvgExq1bQrWcvQs+c/mrPoaamJoHHjuE9fQZRe3dhbGSE3+HD1K9fX3bMzZs36d6rF+lpaUilUmo4ObFvzx7KlCkDlCQpKikrE382jLLunZFKpSSdC8fK+o8f8ujoaBSEQplRqWZgiHWnLhSFBDFm1Ciio6MxrlGN/v37y/r9XrQ0NclLTpK9LkhLRSIWfzZM4bfffiMlN49mB48j1NIiLzmJ0M6/cPjwYbp1K1FFqF27tix8xLV1a/LfGyM/NQWJWExwcDAHDh8hJzsLp9q1WbtqFYsXL0ZoZIxte3eMatdBWUubwFYuPPLfifL/aARLxeLPPs2RSqV4TZjA3n37MahUmawXz9m0dSsBR458kMR3584d+vTtS7m+A6nUsDHxoWfo3qMH4WFhlH+vyMrfhbKyMt179CBg9nQKx3qBQECM33K6de/+3QayRCJh//79xMTEYGxsTO/evb87AVQoFLJ75w669ezJ4TpVkUokVKlajZU+patTFBcX/2klpwsKCujZpw8Xzp1DqK6BuLAAP1/fzyoQyZEj50PkRrIcOf8QvMaOZbyXF4UZGajo6vJk9w66eHpiZGREc1c3Yl+9wqxVW549uI9bq1YEnz79kaF84sQJhg0fAUqKFOXnU6duPfb57/nA0Nt36BCVRo7Dus0vAGguX0WgWxMeP34sk777GkxMTNi6eVOp7xUUFNCrb190GzrjMm02oswMLo0czIRJk2VtdHR0WDB/PlOmTiXh9ElEWZlkP33C0bdeVShJ7hPl5pIbH4eGeYk3PevxIyz19enbty/Xrl0jOjqay5cv4+rq+kNlbEcOHcrwESMQKCigYW7Bk13bqFOvPg4ODmRlZXH+/HmKioqoW7euLN765cuX6FWtjlBLCwB1YxP07MsTFxf3yTGGDhsGAgEa5hY83b0d27J2/LZ5M47jJ6FpacXDrZto1749KampSBQUubV0AZKiIhqv2YiakREZDx8gyc/j9uJ5WLb5hZSrkSRcOEeHXz9dgS4iIoK9+/bRdMde9B2qUvDmNRE9u7BmzRomT54sO+7YsWMY1qhF1bFeABjWqk3GnVucOHECLy+v717bd7zTG/8RlixahJqaGkdWlSS/enbswJz3NKO/dT4DBw8h9Gw4hk51yDp5iu27dhEcFPTdm67q1atzLTKS6OhoVFRUcHBw+MiADw8PZ+z48STFx2Nkaobv8mUfhXn9KMuWL+d27APanAxF08KSx/v3MO7XX6lduzZly8p1l+XI+RrkRrIcOf8QevTogZqaGlt37CC/sJCRAwcwfvx4wsLCuHHzBq1PhqL+toDJxVFD8Fu5ko0bNsjaJyYmMnzECCoOG0XFgUPIT0nmwsDezJs//4PqfmKxGIX3frQVlUsMS4lEIvs3JSUFLS2t75YKe/bsGalJSTT0moySqipKqiaUHziUi8sXfXDcgAEDKF++vKxSnIeHxwdSYbVq1aKZqyvnB/TEqmNncl4859WZU/gdPsyixYvx8/NDz8aWnKQkHKpU5sjBg58tYvI53N3dkUqlrFy7luTsHBpVdWT8uHE8f/4c986dSc/MRFFFBWlBAbt27MDZ2Rk7OzuOb9pEwZvXqJbRJ+fVC17H3kerY3u6de/O/QcPMDQ0ZNzo0bRr146OHTsilUrxXb2al0Fp2FtZkZWTS7m+A2UFUwxqOBHQtB6mDRtTf8UqBAqK3Fw0l9/HjkCUVTKH0cOHs+/gQcL8d6FnYMCG9es/W6b74cOH6NnZo+9QFQDVMvoYNnQm9uHDD44Ti8UovBeCIRAIUBAKZffG9yAWi1m8ZAlbtm6jsKAA5ybOrF658rsVV1RUVFi0YAGLFiz47jm9IywsjDNnTtN8/1F07MpRnJfH2d5d8fPzY+7cud/dr5aWFvXq1Sv1vejoaHr27o19j95UbuZK4vkI+vbrx+mgoB8qqvS/RF67hmVHDzQtStSD7D178mDDGu7cuSM3kuXI+Up+vrikHDlyvht3d3dOHDtGaFAQkyZNQklJidTUVDT09VF/q9kqEAjQrlCJlLc6vu+4d+8eEoGAigOHIBAIUDc2waZL949KPbdv04bYdatIunyRjIcPuDZtIrb25TA2NmbHjh1UdnDE0dERW1tbZs2a9V0G0jvjOi8pUfa3vKRENNQ/NrobNWrEjBkzmDRp0kdauoqKipw4doz+XbqgevMq5cUijh09ilAoxM/Pj0ZrN9HiWBAtA4N5nJCIn5/fN8/1fTp16sShffswNNDnREAALi4uNHNzQ2pqTtvwS7QNu4ilhycDBg2isLCQQYMGUdbUlFCPdvw+tB9h3TpR3dGBufMXcOHaddILRUTdu8eAgQM59jZhtGrVqrxOTSO/WMyTlFQeP3ksS34EUBQKkRQVUa5XPxSVhSgoKlKhd39EGelUGjAE9TL6WFhYcOfmTeLi4nh4//4XC8SYmpqS9fKl7HqIi0RkRN3G/H/kzFq2bEnCxQs83LOD7OfPuL95I6l373w2XOlL+Pj4sGHLFipNnEo93zXcjounZ58+P2R4/yxevHiBjqW1TAtbSV0d/Tr1ePbixZ825smTJ9GvVJmq4yfLvPaG1Wtw4sSJnzpOGV1dct6GbAEUpKVRkJX1jwgtkyPn34LckyxHzj+catWqkZWUxKvgICzdWpOfkkx8UCAm5ctx9OhRXF1d0dTUREdHh+KCAvKTk1A3KTF+sl88w/h/4itnzJhBemYmB4b0A6CSgwPTZs+iQePGvHnzBus2v1B3yAiynj5hy9QJmJqaMmzYsG+as6WlJS1bt+bSmOGUGzAEUfobYjdvZMG8b/fOqampMWvWrA8SN3f+H1eKazgAACAASURBVHvnGRVVsrXhp7tpcpSMoKgoiCCgYkDMGXVUUBnzmHXMEcwBcwJFxZx1zAEUFUUxY84YUBQRRZCcU5/vB9p3+DCgM3NnnNvPWq5l01XVVec0h33q7P2+27aha1EO0/pFBWVqBoaYNGvJ3QcPvnn8/8/gX38lOjMLt6AQRBIxV7zGkpWUiJKqKgDWffrxZOtGXr9+TaVKlTh65Ai7d+8mNjaWSt1+ZtmKFRg1aES9hcsQKSlxZ/F8og7uZenyFXTo0IHho0YhqViJ1v5rkCirEDboFx5tXEsZ++polivPw5V+SKRSUh4/wrh20W5kypNHiMQSlDQ0yE6Il+9Sltat0s3NjRqbN3O2RxcM6zcgLeIhkrQURowYQWZmJjKZDC0tLerXr8+K5cuZMHEitxfMQV1Tk7Vr1pQwefkWdu7Zg+3wMVTo4A6AlmUFjrk1Iyoq6m83ybC0tCTlVTSpzyLRsapMflYmiVev0KJF87/sM2UyGWKptFjaiVgq/dNvGkYMG0aHjh25NmUi2laVeXX4IHb29p8tQlWgQEFJFOoWPwAKdYuvq1vk5OQQFxeHkZHRdz9u/6eipaXFwoULmTlrFtompmQmvkcmE9AyNiYvIx2jMmUIOnwYIyMjOnXuTMSrV1h2/pmMV9G8OLSfPbt307hxY2QyGTKZTF4olJmZSW5uLlpaWtSqU4d8QxOSn0TQ6eKNIkc54L6/L5oP7nDsyLdr0GZnZzPLx4fQs2fJzc4hNz+P/Lw8ajjVYLnvMsqWLfvVMT53/k+cOEH/wYNpFXiyKAVFJuN8/140s6mCn6/vN8/1I/n5+ZQ1N6fxhm0YOdcBIOnhfU797I57+G2kGpq8vXie80P7F6Uw/L/qe5lMhompKY3Wb5UHuOmvoglu2xx9IyM0NTWJjooCwKxxM+ot8iUj9jUhndsjfFifqoYGA/v1Y1VAABXcuyBRVuHZnp3I8vNRUVXFf8WKr+4cC4JASkoK2tra8mLM3Nxc1q1bR8SjR5iamNC7d29m+fhwNDAQAOe69di8YT3Gxsbk5+eTmJiIgYHBHy4sq+bggOXQkVTo6AEU7WgeaVKPCxcuYGNj89l+f4ayzdcQBIEBgwZz8vRpjGrUIu15JHqqKoQcP/6XKSvcvn2bNm5u2A4bhXnT5rw5H8Z9vyUEBQaWcED9o9f+8PBwlvj5kZiYSE1HR2ZMn47Wh/z5fzoKdQsF/wQUQfIPwP9ykCwWizl8+DArVgeQk5NDq+bN8Jo4sViB1v79+xkzdiw52dlIlZWZN3cuv/zyy9836T+Zj+f/wYMHXLlyhWnTp2M/ejzWffqTn5XJpaEDqGFmwrbNm8nMzGTOvHmEX7uGro4Oo4YPx8XFhSlTp7Jz1y4K8vOxd3Bg6aJF8t3BV69eUbNmTWr7LODmvFl0PHcVpQ96sHeWLED/RSRHfldM960EBgYyaPBgbIeOQLtiJZ7v3IpaSgphoadL3NBcuXKFCxcuoKKigru7O5aWlp8MlPLz8+nk0ZmIly8xbdaS1McPyYqMJPRUSAmJv/9PRkYGcXFxmJiYlFCuKCwspKy5OXWXrMC8WVGKQdzli5wb3BfLjh6o6unxYu9ufunZgzlz5sj73b59m+mzZhH75i3v3sVRsVtPHEZPACA6OIhw73GoqqujUaESSY8jkGpokp+RjpqxCWIlJaSamtiPGEd2wjvuLluItFBGQUEBgpIEqbYOBRkZGOvpEnj48FdvLs6dO8egoUNJSkhAVU2NuXPm0Lt37xLthg4bxqkr4dSYNQ8ldXXuzpuFuYoyJ44d+1N1z8dPnMihkyepNX8pqmX0ubtoLtI3r7l0/vwXCy3/G0EyFN3Y7N+/n4iICIyMjOjZsyfa/0895HsRBIGkpCQKCgowMjKSH9cjR44weuxYMtLSUNfUZNmSJXh4eJTo/7987VcEyQr+CSiC5B+A/+UL5ZYtW5g0dSpV+vRHWVuHyK0baNWoEWsDAoAimbE2bm5UH+eFRYvWvL14nhuzp7F/3z4aNWr0N8/+27h58yZjJ0wkOvol5hYWLJ4/n3r16hU7/+Hh4bRv354utx/Jd3ujDu7j7eb13L5+7ZPjTp06lR0HDuA4dRZSLW1uL5hD+osopkzyZuTIkSQnJ1OlShUarFrPrXmz0K5QCes+/UiLes69pQvwW7aMVq1aoa6u/l3qER07dybevDw1vKcBkJ+RTmDjeuzcto2mTZvK223ZsoWJXl6Y1qxFbkoKufHvOBYYSMOGDT8ZKB09epSAgACS09JwsLNj4sSJXw2Qt2/fjtekSeTn5qKkrMz8T9xQtWjZkojnUThOnIxIIuHuskXkJiUiCALaunr079Mbb29vxB/szJ88eULzFi0wadIcA+c6vD5xjPhbNyjbtAXKOjpEHdiLrq4uKcnJiCQSHMZ5UaVHH7LfJxDay5PMN7G4BZ5E64MT5MugI1yfMQlVfQNaHzmOVF2DvLQ0TnVyY8qY0QwYMOCz63v+/DmNmjTBsmt3LDu48/7WdW7P92HH9u0l8orLWVpSY+4izJsVqSqkRD7lpHtbHjx48E2a2V8jOzub4SNGEnikKCfbytqaHVu3lsg/B4iPj+fFixcYGxtTqVKl/0qQ/FeRmppKv4ED5Q6ODjVqsH3LFrmtdWFhIcnJyejp6X1WevF/+dqvCJIV/BNQFO4p+Efju2IFdiPGYj9iDNZ9+lF32UoO7t9PXFyR1mxoaCjGDk5Y9+pL1rs4nm7fDIJA7779OPIdKQJ/F1FRUbh37kxORSucfBZSaGtPl65defLkSbF2H80ykiP+k3ubHPEAQ8PPKwXsO3SIaqMnYN6sJca16+KydAWygnzmzJ3LpUuX0NPTw7NbN25N96Zcm3akRT0jbNAvPPb35dchQ1ji60flypUpV748PnPm8PG+OjIyklmzZjFx4kQCPzyy/xS5ubko6/ynWEhJXQOJVJm8vLz/rCE5mUmTJ1Nr5hwabNpJs/1B6Lu4Mmb8+E+OuWDBAgYMGsQbqQqJ+QWEnj2LTCbjwIEDdPH0pEpVW0zLlsWhRg15wdyVK1cYN3481SdO5qezl3GaMpOJXl5cuHCh2NjWVaqgrKPLPb8l3Fk8H/OmLdCqUJEKP3VCx8GRnb/tJjU1Vd5+69at6NpVp/aCpVTq7Inr6vWo6+ujFRON/qsXjB09ms0bNyLIZB80n4tULNQMDLHq2q2Y0kgRAohE6FWzlxf0KWtro1u5Cm/fvuVLhIaGomFWFodxXuhWroKVZw/MW7Qm6OhRoEgBZfny5cydOxdZYSFCwX+CT6GwAEAe/P9ZqKmpsXHDeiIjI7l//z6Xzp//ZIC8c+dOHBwdadeuHc7OzkyYOJEfeQ9nxOjRPHj1mhZ7DtP6UDBvZdCnXz/5miQSCQYGBv84V0MFChT8B0XhnoJ/NOnp6VT4nducxgc5Iw9PTwz09TE3NSU/K4uM2NecH9of8xatqTl1Fgm3bjBo8GAMDAz+lkKV0NBQzp49i7KyMl26dPms8cdHDh8+jLp5OWr5LEAkEmHWpBnpkU/Yv38/tWrVkrerVKkSP3fvzuGh/Sn3kzvZ797y5mwo+/bu/ezYgkyG6Hd/iMVKRf83qFqN8PBw6tevj+/SpZgsWsTxkFNYGhrQa+QIPDw8cGnQAHWHGrRa6Et69AvWTJ+EkaEhtWvX5qeOHdGpYoOKkRHbhgzl4cOHTJo0qcTnt2zaFN/VARjVqo12RSserV+NVCLGyclJ3iYmJoaC/HwsWrQGQCQWY9a0JY8X+pQYLyoqiqVLl9IwYCOmrg2RFRRwecRgevbpQ9TzKMTKUozruWLf5WeS7t1h0ODB6OrqcunSJcxq18Wqa3cAKrp34e2pE5w5c4YGDRogk8nw8fFh7969GNV1ofG6LfLjd8K9LTpWVbDq1oPg5g0JCwuT5wWnZ2SgamIqf5QuUVZBw9CYzp06MGLECKAoZ97M3Jw3sbHFNJ9Tnz8DQeDKxNHUmDSdvLRU7i5bhFAoI+H6VTJex6BpbkFa1HMS7t7BuvvPX/weiUQi8tLTebRhDeomZli0bgOFhYjFYp49e0abtm0R6ZVBqleG3Lw8rk7zRqysjJKaGveXzMelQYPvlmb7Gl9SVbh37x5jx43DafIMKnbqTOK9O2wfNpDazs506dLlL5nPX4lMJuNUSAgufqspY1sNAKepszjZuT1JSUl/q7OnAgUKSo8iSFbwlyGTydi5cye3bt1CT0+Pvn37YmFh8U1j1KlTh3ub1mNY0xmphib3/ZYgVlZGuWkrEhLfc2XPTiQSCSGenZAVFiJRUaGMXXWMnOuQ+ughB75gKfxXsXbtWqbPmEHZho3JS01l7br17Nu754s6trm5uShra8sDLZFIhFRLp9hu60f8li2jWtWqXLh0CU1tTQYEBsod3T5F+7Zt2e+7CFV9A5S1dbi9aC56VW3JfJ8gT5+QSqVMnTKFqVOmyPuFhoaSnJxMo3mLkCiroGttQ2rkU/YdOsyqNWsxbtKcOvOXIBKJeHM+jGXDBtKnTx+50cZHRo4cSXRMDDv79QRAU0eHRq6u+Pr60q5dO1xdXTEzM0MsFhN36SIWrdogCALxVy5i/onvS3R0NErKypi6NgRArKSEccMm3F26kArunXkTdgaXxX6IpVJM6zcg/eULdu/ZQ6WKFcnPSJcbWgiCQH56mtzoYeXKlWzYuhW7EWN4sGo591Ysw7hOPaKDg8iKe0vZps0RS5VRUlEhPz9fPp/6Li4cmDiR+E6dMazpTHRwEPEP71NnwTx5G1VVVQIPH6ZZy5ac7uWJlWd30l++IPpYIBJVVVIjIwnt5QliMRJVVco4OKKkosKJTm5ol7MkMyaaZs2a0blz58+eZ0EQOHfhAlnJSbwODSHj1SseBqwg43UMnfbtw3vqVDTtHajntxqxkhKxZ05zcdSvXBw1FJFIRLPmzVm9ciUikYjMzEyioqLQ1tamXLlyf2qO8kdkMhmPHz8mLS2N69evU6aSFVZduwFFJiYWbdpx5uzZHzJIFolEKCkpUZCdJf9ZQXY2wN9una1AgYLSowiSFfwlCILA8JEjCTwWjGmjJmTevsvW7TsIOXH8k49aP4e/nx9dfv6ZIw3rIBJLEERQZ+4iuVtcVvw7Ys+ehtQUAKIO7CXx3l2a79yHWFmFwv+yFmtaWhozZs7E2WcBlu2LjCNuzZnBxMmTuRgW9tl+jRs3xtfPj+f7dlO2WQveXjjHm8sXaDJyWIm2EomEIUOGlJBli4mJ4cqVK0ilUho3bizP55vj48O7+HhOfpB807Qoh4q+PrkpyYSGheHo6MiJE0WW1J06dZLv8H587C7I/vPIW1ZYyNPIp+TnF1DDxVUePBnXK7oBeP78eYkgWSKR4LdsGZO9vTlw4AAzZs7kbnom97JessnDA/8VK/D09GTKlCnM9R5LTHAQeclJpDyO4MihQyXWX65cOQry8oi7cgmTevWRFRby7uI5ZIUFqJuYIlZWRvQ7RQYlDQ3y8rLp1KkTy/39uTlrGmZNm/H2fBgpTx7jsWolAAcDA6ncdyC2A4eiY1WFW/Nn82jDGsRSKXa/jkIslXLPdxH56WnF7Lc9PDxY5ufH2X494cPxcK5Vq8SNS/ny5bl/5w7zFyzg2vUrxL14gZKGBmVs7bAfMYanu7YTd+kCBRnpZEe/ID87G31dXXq2c6N69eq0adPmi6kQwcHBnA0Lo8XuQ+hWsSY7IZ6TnX+iY4cONGrUiDETJmLSu588l92scVNEYhE2A4fyYvtmpkyahJqaGpcvX6ZP376kJCUB0LZ9e9YGBJRabq40ZGVl0btvX86dOQOAipoaShoaFObmIvnwOTnv4tCyrvynfeZ/E5FIhGfXrhxYMAdBJkOirMKDZQtp2bo1mpqaPHr0iPT0dKytrb/bAluBAgV/PYrCvR+AH7F449atW7Ru04YWew6hZ2OLrLCQS78OoJahARs/Y2X8KSQSCRoaGpw5c4bbt28zefJkOt96KHeJO9SwDsgKqe+3Gq3yljxYtZwXRw5SuVsvnu3axratW2nVqtVftUxSU1NRUlKSm2c8efIEV1dXOpwLR7VM0SPV16GnuDtjEi+ePfviWNu3b8fL25v8vDwkSkr4zJ7NwIEDS3X+z549S+9ffkGqpU1hbi6aamoEHjoovyFJTk7GzsEBFWMTRBIJWuUrULHLz1wY2h+RWEzZBo2Q5ebx7sZVtm3dSsuWLcnIyMClQQMklSpjPWAIaS+iuD13Jkqqamhb26CkrkF935WIlZR4efQIVydPwMbWlpDjx1H7oI7xewRBwLpqVcy798Z20K9Fx2vbZp4GrODF8+eIxWJCQkIICwtDVVUVT09PbG1tP1m85TNnDqtWB2BW35Wst2/IfxeHTCbDqEUroo8FUaXnL1h5difx/l2ueY9nue8yunbtyrVr1xgzYQIx0dGYlyvH0oUL5QFvkxYtwLUx1QYX3ZgUZGVxoK4j7u7uHDp4EEEQ0NHTY8O6dTRu3Fg+F39/fxb6+pGXk41Opcqom5ry9vw5evXoztKlRdbJubm5TJs+nQOHDiHIBH76qT3RL19y8cIFWu47gp6NLQCvjh/j6pQJaGppoaujy5KFC2jSpMkXz/1H/Pz82Bh8nEbb9sh/dm2qFzqvXtC/Xz9+27uXGBU16i31RyQWy6XsNMwtyHwdA4CpuTmpKamUbd8RuxFjyIh5RfjIIfTu0pmZ32n9/Cm8Jk3iwImT1F+zCXUzM+4sms+Lg3sxcqqJedufSLp7m+igw4RfvkzFihV/yMK93Nxcps+YwZ59+5AVFtK6dWvm+vgwdPhw+c2Blo4uWzdvokGDBp8c40e89v9ZKAr3FPwTUATJPwA/4oUyMDCQEeMn0P78VfnPItYHILlygVPBwaUaIzY2lqioKCpXroyZmRlJSUk41qhBOc8e2I8cS25yEkdbN8F20K/YDijaVZUVFLDfuToiWSFz5sxh4MCBf9qa4uLiWL58OTGxsZibmXHrzh1u37wJFO22rfL3RxAEqlhbU91rClZduyPIZFyf5o1GdBRnT5/+6mekp6fz9u1bTExM5DJUXzv/ubm52NrZY9apM9XHTECWl0f4uBEY52Rx4kPBVtdu3Th/8SLOM+dSvu1PAGS/TyComStOXlOp3L0XAPdXLCMpOJD7d+4A8OzZMwYMHszDe/dQ09Cgup0dsSpq2I/z4lT3Lijr6KBuYkrinVvYjRjDyz27mPDrUIYOHVpinjk5OVhYWNB85z70qxfJz6U8eczJzu2JjIz8ZM7ql2TAjh07xtWrV9HS0qJbt248e/aMXn36IFHXIDslBVlBPiKxmAnjxzN+/PivpgwEBAQwd+EinKbNQsPcgsdrVyGOieZCWBiFhYUkJiZStmzZEgof3Xr25NKdu5i6NqTWjDny9JMLwwZy//59TExMGD12LEdOhlBtzASy4+OJ3LaRCiYmRDx8SKO1mzFxcSUvLY3jHVqjWa48lbr8TPLDBzz7bTuHDx0qtnP9Ofbs2cOEqVNpcSgYNQNDCnJyOOneFll2NiJBhp6GBsnJyUhNzFAzMSHuyiVUDQyRqmvQYNU6pFpa3Jg+mTcXztHpyi2UPuzoPt66kbyTwZw/E/rVOZSWeg0botXBQ17EKCss5EAtOxydnIh79w4TExN8ZszAzc3th1W3+BQTvb05eDKE+gEbUTcz477fUmIDD3Lz2jXKlClTov2PeO3/s1AEyQr+CSjSLRT8JVhZWZGdkkzc5YuYuLhSkJ3Nu7BQmlSzLVX/bdu2MdHLC0QiCvPz6frzz6zw82Pj+vX07d+f57u2UZCbi5KKKvlpafJ+BVlZCLJC1q1dS8eOHf+09cTHx9O8ZSsKy5RBz6kml06EkJuaQtNtexAKC7g4fRITvLxYvXIlixYuZOy4cbw5cYz8tDSyYl9z+ODBUn2OlpbWN4v9x8bGkpaSTKMevRGJREhUVKjQtRvXJ4wGiiS4zp4+jXH9BkSsD6CMvQOqZcpwc/Y0BJkMExdX+VjG9erzaMOaIlcwsRgrKyvCQkPJy8tDKpUWBWKTJwMiLNt3JC78EiZ1XbAfMQajWrVJjXjAq1evPjlPVVVVTMqWJeZEMGXsHQCIORmMnr7+dz1ybtu2LW3btpW/Njc358K5c1y4cAFBELC1tcXGxqaEFvLnGDx4MMkpKayaMYW83BzsHBzYsHu3/CnB57RzdbW1yU9Px8i5jjwQN/pgJPL27VsMDQ3Zs3s3zvOW8OLQPuIuXwSRiIjkZMzMzQn3HovDWC8Sbt+kMCeHRms3o6SqimW7DuTEv2PL1q3yILmwsJALFy6QkJCAra0t1apVk8+jU6dObN62jbPdPTCoW5+EG9coyMmh9aFjiJWUON+vJ81r1MC8bFmCjh5FJJOR8z6BGkumofmhINZp0jRenzlFauQT9O2qA5Cb+B6NTzwZ+IggCNy8eZPXr19jZWWFnZ3dV4+1lqZmMcvynPcJyAoKmD9nDjVq1AD4V6o+nL90iYo9f0HLskiqsPrYiUT+tp2IiAhcXV2/0luBAgX/bRRBsoK/BFtbW0aPGcPyYQMxru5IxptYdFSUmfa7wrDfEx4eTkhICEpKStja2jJh4kRqzvChQsfOJD+KIGhQHxzs7Rk0aBDXr17l7t27aGho8OTJE7wnT0ZFTw/NcpY82rAGs7Jlad269XfNOyUlhcTERMzMzIqlDKxfv54CLS2abN9TJF82ZATB7VuSFvWMSh5dsRvnxbGpXrByJT179qRy5cqcO3cOZWVlOnbsiKWl5XfNpzTo6+sjEolIfvQQdWMTAJIfRVDmg0rBx8CtcreePN26ieC2RZa7IiUl1DQ0iDl1AtuBQxEEgdjTJzG3tCyR+/px97Rr166cOHWKEM+OSDU1ycvOoUKnzqgaGBJ3+RIJN65hUufzRYSrVqyge48eJF2/ikgiJvlZJFs3b/7sLu+jR4+IiYnh5MmTJKWkYFG2LMOGDfusAoOlpeV3H2uxWMzkSZPw9vIiLy8P1Q821F9jyODBHDpyhOjgICxatkEslRJ9LBAlqZRy5coVOR0WFvLq+FEyYl7RNvg0aiam3PNdQuzh/bRp3pxzK5aSn5eHira23P4aQMXQkMykBKBoJ/7nHj24Gn4V9TJlSI9/x9QpUxg5ciRQdI4O7d/P2rVrOXPmDK8TEmh76hwqukW7cabNWxETfokN69czc+ZMCgsLqVbdgZzEBPnnZSfEA3Br+iSq9B9MRswrIrdvYfWqVZ9cu0wmY/jIkezftw91PT2ykpIYNXo0UyZP/uIxGzZ4MIMGD0YklqBpbsHzHVtxrluX6tWrl+qY/6hoaWqS/S5O/vrjzcHHGzEFChT8s1AEyQr+MiZPmkS9unXl6hYeHh6f3DHcu3cvI0aOxKR2XWS5uST4+6NhZEzFTkVV7WVsq1G2TXsuh4czaNAgjI2NadmyyADho3LFYl9fMtMzcHRyZO2uHdy+fZvHjx/L237NWlcQBOYvWICfry+CIKCprc2a1avl+czx8fFo2djKc6GVdXTQLG9JzvuiAEOWX/Ro/yN16tShTp06f/AIlg4dHR2GDR/O2oljsHTvQkFGBi+DDrPmg+GKqqoqbdq148ri+dh7TaWMnT3P9/xGOVNTunfvxrz584k/dxZZXh5pL6PY89tvn/0ssVjMpvXrWbduHbNmz0aipc3xTm6IJRLyPmgHr92wgSZNmnwy4GnYsCFnz5zh+PHj3Lt3D2Xbqjx48AAnJ6cSge9sHx/8V6xASU2dguwsdCpbI37wkINHjnDm1Kk/LKOVl5fHosWLCQk9g4qKMv1696Zbt26IxeJSB8gADg4OrPb3Z/io0Rxr0xTVMvqkPH3MksWL5XNs0Lgxl6+FYz9iDJoW5Yv6jZ3Is13b+KVPH9avW0dkZCQNGzfm8eb1WP3ck6SH94k5coj+U4tuLFesWMG9p5G0PhqChqkZr0NDmDN2BI0aNcLBoWhnXk1NjdGjR+Pi4kL7n34iJ/E9Krp6CDIZSXdu4WRqIp+3RCJh8ID+LFm2iMKcXKRamjxZs4pmLVqgpqbOVb8laGlr4efri7u7+yfXvnPnTgKPBctrD+KuXMJ/2EDq1a1bzCjm/9OhQwdkMhkrVq8mPiyUVnXrMNfH5w9bYP/T+XXQIIYMHYpIIkGjrDnPt2/5n7g5UKDgR+XffUVS8LfTpEmTLxYe5efnM27CBKqP88K6V1+gyAr52e4d5GdlIlXXQBAEsmNj0Lb4tB1vv3796Nevn/z19BkzWLduHbqWFUh/+4Yajo7s2737i4HP7t278V+1ivp+qylT3YHne3bRr/8Azp8Lo1KlSlStWpUjfn5y3dqkh/dJfnAfExdXXoeGcH/xfLp8wlb2v8X0adOoYGnJiZAQlJWVmbdzJ82bN5e/v9rfn5Gjx3B0+CAEQcC4Vm2yRCLmzZ/P9GnTyM7ORiwW065dOypX/rKigFgsJuz8ecyaNKf2/CWE9uqKrKCQ1gePIdXS5ubMKfTo3Ztb169/Uu7KysqKp8+ecfz0aYzr1OP0jd1s3LyFUydPyN3ITp48ScCaNTRevxXjui68v3OLsIF9qDVtNo/WrWb69Oms+sTu5vPnz3n69CmmpqY4ODh8MQ955OjRnDh7Fqs+/clNS2Ps+PHk5uZ+l6W5u7s7Li4uBAUFkZWVhaurKzVr1pS/v2bVKpxdXEqmGBQWyncRK1euTMCqVQwfMYK7yxYB0KhxE0xNTYmPj+fmnTuYtXJDw7RIPcS8WUt0Lcpx7949eZD8EWdnZ9zatiP0lx6YNmtJ5ovnZEQ+YdKJE8XajRo1CqlUyubtO8jPz6NTq5bMnjmzhF3457h9+zamjZrICw9N6tXHqLojt2/f/mKQDEXpIR+1pv9X+Lhev5UreZeeQat6dZnr4/OvTC1RoODfqe5fhAAAIABJREFUgKJw7wfg31y88fbtW6pXr47bsdNolSvaYYu/fpWz/Xpi6OCIRdsOJD+4x+uTwZwIDv7qjsvFixfx6NKFRuu2YORch6y4t4T19mRYnz6MGzfus/36DRhAhLIataYXmVcIgkBIuxZMGzWS3r17k5+fT/devbh8+TLaZS1Ijn6Biakpb2NjUVKS4unZlfnz5v2pMln3799nmZ8f75OScKhWDW9v71Ln134KmUxGpcqVqdhvEFX7DwbgwarlvD2whycREd80VuPmzVFq0QabPv05VL8WzrPmYt68aNc9OyGewKb1CQ8PLyb39/btW9avX8/Dhw85GxZGs5370LerTmFeblG+rF01lvv5ATB37lz2XbuO69ot8v6XxgxDzdiEvNRUoo8FcmD/fho2bCh/39/fHx8fH1Q0NclJT8ejSxdW+ft/MgB59+4ddnZ2NNu+BwPHohzYx1s2kLDvN+5+KMb8szl06BBDhg7F+pcBRbuIO7ZQxdiYI4cOFptjdHQ0P3fvzrNnz+CDhKFYIqGGkxOxUhUarC1KT8lJTOR422asX70aNze3Ep9XWFjIhg0buHnrFmX09Bg4cOA3yS+WhtmzZ7P7zFka79yPWCKhIDubUx1aMXnUKPr37/+Hxv5S0eb/Cv/ma//XUBTuKfgnoNhJVvC3YmBggKq6Om/OhmLdp8iy9c3ZUEzNzXGuUIGHB/ZQrqwZawIDS/VIMiIiAv1KVhg5F6U6qJuYYtywKfcfPvxiP2WplPzf/TGSFeSTnZbG6jVrsLGxoXbt2uzeuZNTp04RGxtL5cqV5S5tIpHoT7fyffjwIW3c3DCs54qOvRN7goO4dvMmR48cKaaukJ2dTWJiIsbGxl81KUhNTSUjLQ3TBo3lPzNt2JiHa1aSk5PzTSkGdra2hAYHUdG9KxI1NbJ+l2f5cbf093mWr1+/plnLlogNDNGsYoOShiYRa1fhujwAibIKBnXr8yLinry9rq4uWbGxFObnIZEqIysoIP3VK9RNzXgXfhn96o4sWLxEHiRfu3YNnzlzcPFdiXmzlqQ8ecyxfj1w3rLlk8Hax8Djo4MjFOlHv0grHpAkJiYyb/58Hj19irmpKd5eXlSsWLHUx+n3fNxFXL5qFQlhGbRxqcec2bNLBPGLlizhbWoaYqmUBivWYORch5dHj3Bj5hSUpVIu/joAXVs73pwMpqq1dbEnBr9HIpEwePDg75praenXrx/bduzg0tD+6NeqzbuwM2grK3/R9ESBAgUKfhQUQbKCvxWpVIrv0qUMGz6c+PNnKczNIenxI37buZNGjRp9826SkZER6W9iyXn/HlUDA2SFhaQ9foipc60v9uvRvTsHO3dGs1x59Ks78HzfHmQyGfkVK9OhUydOBAfj4OBQoiDwex+TXr9+ndOnTyOVSunQoUOJFIcV/v4Y1K6Ly/LViEQiKnXtxnG3ZoSFhcnzsVetWoXPnDkUFhSgpaPLmtWr5O99Ch0dHbR19Yg9cwrdKtYAvD4dgrqWFmlpad8UJM+aMYMbP/3ECbem5GVnc3fpQgoyM5Fq6xCxdiWaOjoYGxvL2y9dtgylshY02rQDsVRKSuRTQrp2JGLdaiw7epBw6QI1nP6TMtC1a1dWrVnDxYG/oF6hIu/v3CY9+iWZr1+hb++IWbNmvN+3W97+5s2bGNpUxbxZ0fp1rW0wa9GaGzdufDJItrCwwMDYmIf+vtSYOov8zAwiN63DufZ/ig4zMjJo06496UpKmDRtQfitm7Ro1ZqzoacpV65cqY/V7ylNisHV69dRNTVDv6azXHmkYqfOPNu5lZTIp7y9fJG4a+FUq1qVQ/v3l5Ck+29ibm5OyIkTzJu/gJjwSzS1r8bUyZMVBhkKFCj4V/Dnbn8pUPAddO7cmaNBQXR1qUuvFs05HRJCo0aNvmssNzc3qlpbE9bbk9sL53Lul+7kv45h2LCSznW/p0GDBmzauJH4wINcHD2MnOREmm/fTb0lyzGuV5/1GzZ813w+xd69e2nXvj2/XbjI5mPBNGnalDVr1hQ9Xv/A+6RktCtby3Nq1QwMUS9ThqQPLmiBgYH4zJ1LrdkLaHv8DBae3enbr3+xMf4/YrGYFX6+PFq7ilPdPAjp2pEnWzeipKtLs5YtvyktSV9fn9CQEJbNn09hXh6VunYjJuQ4kbu2YeziSkZqKomJifL2MbFvKONUE7FUSlbcW66MHwmCjIj1AQS7NUcWH4e3l5e8vaGhIXt/+43sl1G8OHyArDexIMio1KUbdRcu4/WRwzj+7smCjo4OmfHvyM/KBIrSZTKjX3w2WFNRUWH7li0knjvDwToOHGlYhzKFBSxftkze5vDhw8SnJNNwyy6qDR2B65qNqFiUY+PGjaU+Tt+Drq4u+WlpZL+L42M2nCw/n5ykJHSqWONx7R4NV2/g8dOnHDly5C+dS2moWLEiG9av42TwMfyXLy92c6RAgQIFPzKKIFnBPwJnZ2emTJmCl5cXtral01L+FB9lsPp36Yzl+zjcHKsTeuoU5ubmyGQytm/fzujRo5k1a1YJPd927drhPX48ehblaLFzP9oVrQBQL2tO2nfkBe7bt4/2nTrRqm07li9fTmFhITk5OYwdNw6H8d403LSTxrsOYN6+EzN8fKhXrx5e3t4IgkAtJ0deBweR+fYNAK+OHyU9Lg57e3sATpw8iUWbdli274CmuQV2w0ejaW5O2Besr6FIW3j0qFGkP4/EqG49Wu45TMvDx8lTU2fdunXftD4NDQ08PDzQ0NREz9aOVvuDcAs8SXm3IrMSNTU13r17x8DBg7l75zaxoafIS0vj+swpKOvo0vHCdTyu3aNCh04IMqFE/uGqgACUDIzocOYS7uG3qTZkOE93bCG4TRP0ZAXMmzNH3rZ9+/YYaGtzcUAfHm/ZwJXRw0h7FMGAAQM+O/9atWpxPTycfXv2EBQURGhISLEALzk5GU0zc6QaRXngYokEzYqVigX/fwXjRo0iLeoZ7+/c4tr0SbwIPMTFUUPJz8pEVd8AiYoKxnXqYeH2E+cuXPhL53L+/Hl8fX3ZvHkzqR/US/5Onj9/zvLly1m6dCl37979u6ejQIGCfzmKIFnBvw4NDQ0mTZrEzu3bWbx4MRYWFgiCwPCRI5k0fQaXUjPYe+4CjZs24/nz58X61qpVi5RX0Tw/sBdBEEh+9JDXxwJxqVv3m+awZcsWRowaRVLFKuTWqsNSf3+8J03i3bt35ObkUPZDWoBIJMK8eUsQBJpu/Y0dv/3G7t27GTNmDNWtKnG8bQuONa1PuPc4fGbPlptHKCkpIcvOln+eIJNRmJtbKgktZWVlDKpWw3GsF7rWNkiUVdCuWo1379590xo/zn/IoEHcnTebx5vX83TnVm5MnkDPXr0QBIG2HTpw+XkU5foMIDctlaOtmxB/LRybvgNR1tJCLJFQ7deRJL1PICYmptjY12/exLJrN1T0yiASiag6YAgIAhPHjuX0yZPFJOO0tLQIDgqiYVVrCk6fwEYq5kRwMFZWVl+cv66uLg0aNKBOnTol0hYcHR1JiHhQZP4BpEU9I+7cGRwdHb/5OH0Lbdq0Yfjw4UiUVUh/EcWDVcsRZDIMatSSB+wAue/j0SilCsX3sHjxYrp4erLp+Al8lvnSuFkz4uLivt7xMwiCQEBAAA41a2Jta8vAwYO/GninpqYSFRVFTk4Oly9fplGTJqzZf5DNx0/SqnXrf8ROugIFCv69KHKSFfxPcPv2bfbv3UuLvYfRs7GlIDeHKyOGMGfePDb/7vF5tWrVWLJ4MRMmTuT23JkU5ufj0aXLN9tbL1q6DPtR47HuUyRNZ+DgxJbBfRk7ZgxSFRXeXggrsq0WBN5eOIdGWXMMa9TCrHkrroSH061bNw7s28elS5fIzMykYsWKWFtby8f37NqVPR4ePAzwR9+xBq8CDyFkZHwxJ/kjVatW5b2vL0kPH1Cmmh2Zb2JJuHKRqqNGfbJ9QUEBWVlZaGlplZBUy8nJkWvoHgkOQlZYyMDevfCaOJEjR46QkJRM610HkKprUKlrN8706EJ23BvSo1/Ix0h/WfT//58aUaZMGdKjnv2uXRSCTEbLli2LGb18xMjIiIDPmF58C4IgEPFB7WNA//6sH9IPDQNDspKTcHNrS9++ff/wZ3yNMWPGcPDIEVBXp8qYCSRHPODxlo3o21bjZdBhEu/e5t3li/Q5dkzeJzc3l+zsbHR0dL5qwf01njx5wuLFi2mwaj2mDRpRkJ3NhYG9meXj893HeN26dcyZPx/bEWNQMzDk/LrV9OjVm8DDh0oUvgqCwNx581i2dGmRbrmODupqapT7yR2nKTMQiUQ82rCWkaNH4+bm9tWiVQUKFCj4HhRBsoK/jfj4eKZMm8a9Bw8wMjRkirc3db9xx7a0xMbGoqaji3bFSlybPomXRw4iyGSkaGsTHR1N+fLl5W179epFs2bNiIyMxMjICBsbm28OOtJSU7Cp8B8VBO2KRdJbeXl5LJw/n3Hjx/Mm9BS56emkPHlEw1XrEQSBnDev0arhBBQVBTZs2PCTMlD169dn/bp1TJk+nUfrVmNlbc3B/fswMzP76txat25NZw8P9vX+Gb2KFUmLeUVtZ+cSBW6CILBkyRJ8/fzIz8ujfMWKbFq/Xq4yEhoaysDBQ0hPTQFg2LBhzJgxQ36s0tLSUNc3QKquQeSu7dxbsZSCzExU1NR4sHwpOYnvUdbS5vmOrXTv2bOEmciEMWPo2asXBdnZqJua8XLfblq7uVG1atVvORXfRH5+PgMHD+ZYUBBiiQQlJSlTpkzBwsICExMT6tWrV6rvQmpqKqdPn2bdxk2kpqfhWrcuM2fMKLWEn7a2NkGHDzPey4u7i+ZiYGjIsqVLOXL0GI9W+mJsbMy+vXtxcnKioKCAKVOnsmXzZmQyGVWqVmXb5s1/SO7t2bNnqGprY9qgqDZASU0Nk6YteHoutERbmUzGpk2buBwejraWFv379ZOnBf2eDVu2UHXoCLkeul41e4LbNuf58+clClf37NnDCn9/XHxXUsauOs/37OLRxnVYOjjJj79Fq9bcW76EhISEUn3vFShQoOBbUegk/wD8G7UyMzIyaNayJRmq6pj/1ImUh/d5FRxE8NGjODk5ydv9WVqpjx49olGjRpg2akJyxEOcZ85FqqXNrXmzyHgZxdHDh6lRo8YfWtP58+cZ7+VNbMwrJCoq6NjY4rIiAImKKrfmzCT1Yhj3bt9GKpVy8eJFgoKC2L13L+oVKlK+owfvb1zj3bmzhJ46RZUqVeTjfu38C4JAfn4+ycnJGBgYlEpxQxAEzp49y7Nnzyj7wcb7//fbunUrk6dNo8aMOWhbVebppvWkXQ/nysWLZGRk4OLqSsXuvancsw/JEQ+5OmEUc2fNkptx3L17l5atWlGhy8+82L8Xp0lT0bOxJXLXNhLCzmBja0tiUhKJ79+Tn5dHdQdHVi73Kyaxdv78edZt3EhiUhINXFwYP27cX6rmsHjxYlZt2kSD9dvQrliJJ9s383DFMi5fvEiFChW+2j8hIYF+AwcSfukSAJrlylPRvSvP9+7CytiIk8ePf5MiSml+9xcsWMDqjZuoNWcBaiamRKxYhujVSy6dP//JHffScOfOHVq2bFnkpFe1GoJMxqXhg6iuo8W2zZvl7QRBYOTo0RwOCqKsW3uyY18Tfy0cezt7MnNyqFbVBp9ZszA2NsbeyQmLQcOo2KlIHi4vLY1D9WsSGhpaQt6xb//+PFJRL6ZbHtS8ATpVrGkUUPTk59mendxfvIAXUc//VoWPv5J/47W/tCh0khX8E/ihguQTJ05w8OBB0tLSkEql1KxZk0GDBn3VHUoRJP/zOHz4MCPHj6fNibNINbUAuDTqV+qU0ZHbKcOfayiwYMECfFeswHnWfCzbdwAgPfolwe1aoGdgwK3r17/brOP+/fu0aNUKjXKWpD2PBEAsVUYkAolUipqyMr/t3Imzs3OxfjExMUyaOpWnkZGUNTNj5rRpJdzTvnb+16xZw2wfH/Lz8tDT12dtQMAXXQ4jIiLYvn07GZmZuNavT9euXT+5O/qTuzvJVjY4jJ0IFCksBDasw/rVq0hPT8d7tg9tTp2X9721cA6WCXHs2rFDPsbmzZvxmjyZiu5dqDVtdtE4BQUEN3fF3c2Nnbt2UW34aHSrWBP12w5kL6O4eO4c2trawH/fUKKDuzspVe2xHzEGKArOjjapR3ljEzR1tGnaqBGjR436bO73T506EZmcgtO02cjyC7g23Rsdqyo4jvfmaKvG7N+//5uUW0rzu1+3QQO02rtj3btohzY/I52D9Wpw4sSJYq5/34IgCIwYNYrDQUcxbdKMrOgXZEW/JOT48WK7vk+ePMHV1ZUWuw9Sppo9giBwddJ44q9fxabfQGKDg1DLzCDs9GmmTp/O0bBz1PVdBRIxV8aOJO/dW0YOH87w4cOLBfSDhwzhZlYudRf5AlCYn0dwy0bkJCdj4lwXiaoKr8+HsXTJEnr16vVda/wR+Dde+0uLIkhW8E/ghyrcc3R0ZOnSpezevZu1a9dSUFDA1q1b/+5pKfgO0tPTUdXVlQfI8P0qEqXF29u7ZHDz4R4x+f17njx58t1jHzhwAFUDQ/JSkmmyaQdux05jVNcFFWVl1q5cydUrV+QB8sOHDxk0eDCdunRh27ZtLF20iCYNG5Kdk4vv8uXyfNjSEBQUxIxZs3CaNhu3oBCMf+pErz59iIqK+mT7Gzdu0LJVK47df0h4Zg5jxo9n+owZn2wrk8nIfBtL3JVL5KWlIQgyEAREIhFSqZTC3FxkeXny9vlpaSUcB/v27UsDV1dEot9dakQiCmUytu/ciWXHztgOGIJZwybU9V1FcmoqF0qp2BAREYGvry9+fn5/6Nz9Hm0trSK5uQ/kpaWSk5ZOir4BWY618F+3nhGfyd1OT0/nysWLOE2bTZlq9hg4OuHkNZU3Z0NRNTBEJJFw9erVYn0SExPp2bs3FuXLY2Vtzfz585F9cNkrLWKxGKGwQP5a9uFm4o8Y3IhEIlb4+TF/9izqa2vQpYErZ0+fLpEW8e7dO8RKSujZ2sn7GTjVQKqpSZUefXBdt4WE5BSOHz/OXB8falpX4WTn9oR06QAiMGvTnoDt23Hv0oW8332XunfrxquTwTxYvYI358O4NmE0amIxe3bvpmMNB9pUsWL/vn3/2AD5/fv3nDlzhitXrhRblwIFCn4sfqicZBMTk2KvRSIRb9++/Ztmo+CPUKtWLdJiY3m29zcqdfmZlKePiQk6TPfRnw5A/gxiY2PJy8nlzuJ5KOtoo6ytw+3F89C1sSXlccQXzTRSU1MZNXYsoadPI5Uq07tnD6ZOnSoPunNzc8lNTaH66Alytz+Xxb4crOuEmZkZ+vr6QFGA3LpNG/Sd66BdxYaNe/exdsNGVAyNMHdrx92IB7Rq04ZTJ09iY2NTYh5nz57l1KlTKCsr4+7uzrHgYMq5tadCRw8Aqo+ZyLszpzl37lwJZ7i8vDyGDh+OaYvW1J67CJFIxLsO7qzp34sB/fsXy8t+/fo1Uc+fkxAfT+zpU0i1tNCrYo2OlpY8b1xLXY3wMcOw7NqN5EcRRB89woJdu0rMuZunJyNGjqKMnT26VW2J3LmNvIwM9KpWQ1n7PzdJEmVlJMrKpQoqQkJC6NO3L2WsbRAKC1m8ZCk7d2yncePGX+37JYYMGoS7hwdKGhroVLHm2e6dKOvq4rJsJUqqqpi6NmR/jy5M9vbGwsKiWN+PO+qy/Hz5z2T5eSAW8SDAHwBTU9P/vCeT0aN3b6LTMnBe5EtOUhKrF89DKpUyfvz4Us/Z092dxX7LUTMyRt3ElEerV1CpSpU/JKUIRUF2r169vhiIWllZIQJeHjlIhY4eFGRl8TLoMDqVi4pMpRqaqOvrk5qaioaGBrt37WLChAkEXQmn6W8HkCirkJ0QT0jHNhw9ehR3d3devXrFvEWLEGQyHm9ah0gQqGZvz66DB7G2tv7D5/iv5uLFi/Ts04fc3FwK8/OxtbPnwN498muAAgUKfhx+qCAZipzKli5dSlZWFioqKnh7e5do8/79+2IpFmKxGENDw//mNP9URCLRdzu7/VOxs7PDz9eXMWPHcmeBT5GKROfODBs2rNhaP/7/a+vPzMzk3LlzZGVlUatWLSwtLUu0SU5OBkGGZrnyXBg+GAQBncpVKMjOxrluXapVq/bJzxEEgV/69yci9g21Fi4jPz2DzYvmIpFImDlzJlAU/MgKCynIzpL3K8zOAYok1z6O6+u3HIO6LrgsD0AkEmHl2Z2jbZriNGI0Fi1aIwgCFwb3JWDNGlb6FwVWz5494/z581y5coUdO3di3qgJBZmZrF2/nvouLshU/2P/LMhkyAoKUFJSKraWvLw8PLp2JSb2DTX6DJAHdIY1ipwI4+PjiwXVv44YgcSiPO6HghGrqHBtihevQ0PYv3u3/I/90SNHGDZyJLcmjUffwID169Z9Ul3D09OT+Ph45s6dSV5ODlI1Nax+7oFGWQvu+y/DyLkuutY2PNmyAVluLmFhYRwNDsbJwYHhw4eXOP+CIDBsxEiq/DIA+xFjEASBu0sXMnzUKB49ePC5r0ipaNiwIfv37WPeokUk3rpB7ptYqo3zQunDDdTHAsy0tLQS3xUdHR1atm7N9emTsJ84BVl+PjdmT0UoLOTptk2IRGLOX7xInz59EIlEvHjxgpvXrtE2+DSaFkU3KIU5OWzfsRmvD8YqpfndHz16NJmZmQTMmkpuTg41a9dm4759X01D+zOwsLBg8aJFjJ8wgahtm8h4n0B+ZhbVfh2FIAhEHwsk8fkzateuLV9HZmYmuvaOSJSLnjqoGRqhU96SuLg48vPz6ezpSY6BEU237CLzTSx35s2ic8eOfzjo/2+Qnp5On379MO/ggcN4b3JTkrk0pD8Tvb3ZsmnTN4/3b7z2l5b/1XUr+Ich/KDEx8cL27ZtE16/fl3ivTVr1gg1a9aU//P39/8bZqigNLx+/Vo4ffq0cO/ePUEmk33XGG/evBEq29gIKpqagpaRsaCsqiocPHiwRLvU1FRBXVNTqDZ0hODoPVXQsCgnKKmpCybm5kJSUtJnx4+JiREAodWBo4Ln/UjB836k4Dx7vlDG0FDeZvLkyYJUQ0MQK6sIjl5ThYYBGwW9avaCjr6+kJeXJ2/n2rixYDt4mHwcz/uRgrKenlB3wVL56yo9fxHa/fSTIAiCsG/fPkGqrCxom5oJEjU1QdXQSGh/+oLgeT9SsO7VVzApW1YQi8VC9VHjhSabdggVO7gL2rp6QkxMTLE1BAQECBr6+oJRnXqCSf0GQuebDwTP+5FC7TkLBYmSkvDmzZti7ZVVVISGazYJnvcjha73ngouy/wFQKhsbS3IZDIhMzNTuHPnjhAVFVXq81ZQUCAkJycL1WvWFKoNGS50vfdUqNK7nwAIgKCprSOoa2oKRk41hEqe3QVNQyOhZevWQkFBQbFxEhMTS5yP5rv2C4CQnZ1dqrmUlnYdOgjGjk5Cp0s3ha53nwg2fQcKWjo6Qnp6+ifbp6amCh5dughSZWVBLJEIyrp6Qv3lAUKHc+FCy72HBZFYLFy+fFkQBEF48OCBAAgdzl6Rr6P2nIWCcdmy3zVXmUwm5Obmfvda/wg3b94UVq5cKWzevFno3LWrAAhSVVVBLJEIK1euLNZ2zpw5grapmfDT2cuC5/1IocXuQ4JURVU4evSocOnSJUEkEgmdLt+SHxP7kWMFOyenv2Vd38qNGzcEQPC4elc+/zrzFgsm5uZ/99QUKFDwHfxjdpIXLFjA5cuXP/t+YGBgsdeGhobUqFGDxYsX4+fnV+w9Dw+PYsUxYrG4aBfxB0VDQ4PMzMy/exp/Cerq6nJViZSUlBLvSyQStLW1SUtL+2zhVv9Bg0hTVaftqfMoaWjyaH0A3Xv2JOLBA3R1dYu1Xb92Lf3690dZR5fCrEzMTIw5+sGQ4HPfkY9PJZQ+7MylRT3j6bbNpKekYmNnh1vLlqzw90fFwBBRdhb3fBcjIKCspk6X9u3IyMiQj+VgZ8fOwCCsfu6BmoEhr04cIy8lhez3CQBkxETz5mQwXQYNJCoqil69e1P115HY9BtEQVYm54cO4Na82bguX42xiysv9/3GmjVrmDR1KvdXLKVSFWsOHdiPhoZGsfU8fPiQMnbVqe41hTO/9OBY2xYoa2mR+iwSAyMjwsPDiz3G1tDSIiPmFYJMxrVp3rw8egSplhaRT57QoWNHLl2+TNKH41LL2ZmfPT2xt7cvUZj4yfPVuzfjJkxASV0dg+qOvLe2wVAixs7WlssxsTRYtwWRWEzGLwM42aENp0+fpl69evLzLwgCGlpaxF25iG6Vosf6cZcvoqevT1ZWFtm/M1n5o0ydNImGTZpyuFEdJCoqyHLzMDE1+T/27jIgyqwL4Ph/ZmDoVlIEsTAWW+wGW9duTOzVXbtQrLVdu0Bdu1GMNbBr1bW7RSSlS3Jm3g+4vLoWFgNyf1+U4YnzzHXGM8/cew7R0dGkvTGt4k1eK1eycvlyGjZtSkoFZwrUawCAtqkZemZm3LlzB0dHR/Lnz4994cJcmTQOp9HjSYmK4v6yRbRu6Jo5dl/y2lfHe0WhQoUyq3+0aNGCXwYNIjQ0lGLFimFnZ/fWv8WePXuyZ+8+jrRshJGdPVEPH9CuXTuqVq2aMWdbIkH6xl1EqaYmKa+rt+QW8QH+mDhm3PlOCHiOgYHBF8X/I7/3f8q/7/2CoE45Jkl+37SJT1EoFO/tAJUvX763aq5GRERky8r470WlUuXq+L8FhULxwefg2vXr2PX/JXMRYPHuvbm1+A8ePnz4zup+V1dXzp45wz///IOOjg516tRBX1//o8+vlZUVxUqU4OrkCZQcOJQzQ/pj5lSGUgMGE3HtCn8sWEDRzt0oP8aD9ORkzgwdZy4nAAAgAElEQVTsQ8zD+xjp6jB69Oi3jj1i+HD+vniRA43qomlgmFEr2MSUG/Nmcc97BWnx8dStW5eBAwdy8+ZNkpOSKNatR8ZiOT19HNq05/ayRahUKoL8DmHn4ECrVq1o1aoVCoUi8yvK/16Pra0tUVu3oqGjR/WFyznevSNaJiaUGT6apNAQ2nfsyOGDBzNLcf02ZAiTpkwh5MxJwi9fwnXbbkwcSxJ24Tz7+/XCsnoNWk6dxdlfB3L1+nXuBwXzKiyUwYMH4zFhwkfHslOnTqSkpLBo2TICEhKoUqUK8+fMwX3AAIx/KoPk9YIz/QK26OXPT0hIyDvjP2fWLAYNHkzkxb9RKpWEXjiPt5fXZy96+5R9+/ahY2ZG5VHjUSmVGBQqzLm+3dm4ceMnG8wUK1KEo2dOUbynOxra2oRf+YfEiAjs7e1RKBRIpVK2btpEFzc3/mqakUg3a9GCKZMnv/WBIDe+9kuWLJk5PeK/8cvlcnx3+7Bv3z5CQkIoVqwYLi4uKJVKSpYsiaW1NZfGjqDk4F9JDHrBw9UrGdKvX654HgoWLEjT5s05Nagvhbt2Jyk8nMeb17N0yZIvij+3jr8g/ChyTJKcFX5+flSoUAFTU1NCQ0PZuHHjO+WyhLzHzMyM2If/r24Q8/A+kNGx7X3s7e3fO2f5Q2QyGZs3bKBL9+4cc+uAdr581FiwDKmmJraujYl79pT0Vxl3LzW0tSnUuh23Z0zlxNGjmJubv3UsXV1d8ufLh0QiQdvcHIlMRvqrjDtFqTExTJs2DXd3d6RSaeYHveh7d8lXJqN2dPTdO6QnJnC8XQteBQWyc/v2t+L8kC5durBt506OtW+JhpERupZWuG7dnZmQxj96yM6dOzOT5P79+3Pw0CEunD9LAZeGmXfFLKpUw6RESUxLO/Fs904SgwJpsu8IejYFCLtwniUDelOvbl2qV6/+wVgkEgk9e/Z8p3NdaUdHth0+QvHuvZBIpIRd+pu4kODMVtxvateuHdbW1vz1119IJBJajBtD5cqVP3jOLxUWFoZRiZLY1K2f+Zhh4SJZauE9fuxYTjdpwtGfG6NvW5Cwq1fo26/fW22tCxcuzPkzZwgJCUFHR+eD/2Z/NHK5nDZt2rzzuJ6eHju3bcOtZ08Ot26KVCqlV+/e/Pbbb2qI8vNJJBJWLl/OrNmzOX7sMMa6eqxauZKWLVuqOzRBEL5ArkqSHz16xMaNGzNb5FasWBE3Nzd1hyV8Azdv3mTQ0KE8fvCAfObm/D51Ks2bN8/SvuNGjaKbmxspMdHo5DfHf9d22nXokKXmD1llZ2fH6ePHmTdvHmv2+CJ9ow2ulqkZSWH/r7ISfecW9vZ27yTIkNGl7tjx47ju3IeBfSEUKSkc7dYemVyONCwUd3d3goOD0dDQwM7Ojo6dO+M7yJ2CrdqSHBbGiyMHadumDcWLF6d58+ZZvkYtLS18fXxYv349u3fv5nlyamaCDKCpr/9WVQmJRMKO7dtp2LAhgY8eoVQokMpkpCclkRgSjFRTTvSDe9jUa4CeTQEgI4E2K1qMW7dufTRJ/pBRo0Zx4vRp9rvUIj05Y9Gjrb39B6+xevXqX3Sez1GiRAk27dxJ/HN/DOzsiXn0kIgb1ynh1vWT+1pYWHDy2DG2bdtGVFQU5QYNoGHDhu9sJ5VKsbGx+R7h50rFihXj77NniYuLw8bGhqSkpFx1N1VLS4uJHh5M9PBQdyiCIHylXJUkDxw4kIEDB6o7DOEbCwkJoVWbtphWr0n1ISOIuH6VPu7u+OzaRa1atT65v6urKzu2b8d7zRoSnjyg7S+DGTRo0DePUyqV0rhxY+bNn8+D9Wsp1LI14dcu8+LQAaRSKVd+n0JKxEuCTxxjy3tKoUFG8xADGxsM7DMSP5mWFuYVKhN58zoJCQnUqluXB6/rJNepXx+vFSsoV6YMh/380NPTY+GuXV+cGGpra9O3b18qVapEo8aNebjxT2wbNiH073MEnjxO/Q0b3tpeS0uLjRs3UqdePc7270W+Ss6EnjwOyUkE/rUPLXNzEoMCMxPolOgoEoKD3vvhICsMDAywtLTkZVo6FafOBCRc8xxPxy5d2LF16xcd82t16dKFw35+HG3XAqOCdsT4P6NJk6a0atUqS/sbGxvj7u6OUqn8YAMS4V0SiQRTU1O0tbW/6RxzQRCEz5GrOu59KdFxL2dbt24dU/9YgOuBo5kLdv4e9gvV85uydMmSr+64FhwczJjx47l3/z5WlpZMmjDhizuRAfj4+DBk6FBSXt/t/O2337C0tOTk6dPo6erSo3t3nJ2d37vvqVOn6NCpM/U3bcekRCnSEuI52qU96a8Skbx6hWHJ0pSfOJm0hAT+GT2M2uXKsnXz5m8+/jt27OC3YcNISU5GpqHBZE9P+vXrR2xsLFpaWm/VjH769Cm/z5hJQFAQxYoU5pdBg5g1Zy7nzp8jNjYWs9JOmJYpS+jxoxQwNuLg/v0frTn9ISkpKdja2lJn9YbMWtPh165w3K0jQUFBams9rFQqOXLkCAEBARQqVIgGDRq8t0PhfyUnJzNqzBh27NiBUqGgXv36LHv97zmrcuNr38/PjwWLlxATG0vVypXwnDTpizpZZne3xZwoN47/tyI67gk5gbi1IahdWloaMi2tt77+l+nofLB6wKfEx8cTHByMtbU1SqWSxs2aobSwxKaTG6HXr9Ki5c8cOXzovXNds6J169a4uLgQEBCAubl5Zg3uXr16fXLfWrVq0bZtG3y6d8KoRCni/Z+RnpBAPjNTwuJiqe0xObNmbsmhw/GbOPaLYvyUdu3a0bRpU0JCQrCwsCA8PJxadetx7/YtJBIJXbt1Y9bMmWhqauLg4IC31ypevHhBcHAwxsbGrPH2AuD58+f8sWAB9+/cRBUXy+3n/pQpX57pU6bQtm3bz4pJKpUikUozGnC8pkxJQSKRfFX3uK8llUpp1KjRZ+83dtw49h87TpV5i9DQ1uHanN/p5e6Oz44dn0yyVSoVcXFxb7Vqzg2OHj1K127dKNyuE/p2dvhu28y9+53x3e0j7qQLgpDr5Kq21MKPqXbt2sQHBXJn6UISgwJ5fmAvAQf30+g98zc/JDU1lWvXrjFp0iSKFS9OjRo1KFa8OOPGjSMuOZnqy9dQpH0nKk2fTb4KFVm7du17jxMVFcXly5d5/vz5R89nYGBA8eLFWblqFaWcnCheqhTDR4z45FfDEomExQsXsnzxYlpVKEebRg1ZvmQx+16XoUt7o1xcWkLCd00sdHV1KVy4MHK5nA6duxBraITrDl9qLvXC58ABfp8xA8hI2CZ5elK+fHmaNWuGU5ky/Pnnn0DGXO2RI0bw4MEDzGrVpd6fmynQuTsDBw3i5MmTnxWPpqYmLX/+mWtTJhJ0/ChBJ49xbYoHbdu3f6fd9fcQFxfH/v378fHxITAw8KuOpVKp8Nm9m59GjsWmTn0sqlSj/NRZnD11iqioqI/ue+PGDSo6O1OkSBFMTE2ZO3cuueULv8XLluHQtgPlx0+iWNce1PRezz+XLnL16lV1hyYIgvDZxEd7Qe2KFi3Kn2vW0G/gQO6sXIpMQ4NxY8dmeUV4aGgo7Tt1yui2JpFQafJ0rGvXI/jkcbZ7jsesaLHMjmkSiQRtKxvi3vMVpo+PD78MGUpqSsY0Crfu3Zkze/YH72JOmTqVPzdvodTQ4ci0tNm9eD6xsXF4e6167/aRkZGM9/Dg2o0b5DPLx5iRI6hZsyaQkVTVqV+fy2OGUXLIMNISErg9bxa9un14gVhCQgL79u0jOjqacuXKUbVq1Sw9X//14MEDnj1+xM9rNqJlYgqO4DjgF/ZsXMekiRPZuXMnXqtXU3XeIvx37yL0wjlGjRnL0aNHGTduHBcuXEBmYEiFyb8jlcnIX6ESMffvsmvXrs9uIbxg/nxGjBrF3tEZ1Qyat2jB2tWrs9Sq+ms8f/6cFq1aERUbi4aWFopXr1i3di1169b94mMqlUoksv+/xUpff+D5WJm6yMhI2nXsiFGV6jScs4jYxw+Z7zkeCwuLj7aHzili4+LQq/z/dt065hZoamsTFxenxqgEQRC+jEiShRzB1dWVB3fvEhYWhpmZ2We11B38669EyjQo0qkr8c/9cWjVDgCH1u3w37WViNu3eebrg32LVkTdukHQoQMMnOz51jEePHjAoMGDKf3bSIp06EzU7VtsG9SXkiVK0Lt373fOqVKpWLd+PU7jPbGsWgMNHR10razw7dmFP+bPw8DA4K3tk5KSaNm6NZFIKNiuM1EP79OufXv27N5NlSpVkEgkrPHyYtiIERz1HI+Ghga9unVl/Lhx773myMhImjRvTlhUFHqWVkRMmcLIkSMZMXx4lp+3f/37IUD5xrxPZboCiSQjSb106R9sGjbi4YY/UaakUHPJKlJjojk2dSKHa9fG3MoKlVT21nQZqVyO4gtqFuvq6rJsyRKWvm7JraGhgZ6e3ndPkn/59VcoUJCmu5Yj09bm5h9z6O3elzu3bn7RlAeJRELTpk05Om8mckNDZDo63Jg+mYrOzm/VcP8vHx8fEhITqdi1B8bFHTEu7kj0/bvs8vXNFUlyVWdndmzfgq1LI3StrLm7cikSlYrSpUurOzRBEITPJpJkIceQy+XY2tp+esP/uHD+PJXnLiTy5g3S4uNQqVRIJJKMP1XQoH59jk0ax+VJ41AqFHRzc3sn4bh06RIG1jYU75ZRuzd/+YrYNv+ZU2fOfDBJTklJ4dbiP7g4dgQABVwy5q2mpKS8kySfPn2aZ/7+ND1yGrmREQBpCfGsWLWKKlWqABlTOLxWrmT//v3s2buXwKAg/Pz8aN++PUlJSSxYsIAr12+Q38yUwMBAoiVSGu73Q1PfgODTJ5g9uB9NGjfObOKQVUWLFsXC2oZzQwfg9NsoksNfcm/ZIuRSCSFhYegVtCMxIICo2zdpcuAoBgUz5kynv3rFnRVLkNkVIvHqFW7Mn4VD6/ZEXL9KwMH9eHp7f1Ycb8rKwrhv6ebNm5SbOguN1wlx8e69ub/Wi8DAQIoWLZrl49y+fZvt27eTnJxMI1dXUlJS2N8r49sA52rVWOPl9cFrmzlzJvPmzUOmpY1fx1YU6dSN8mM9UCmUSD+wj0qlIj4+Hj09vY/Wyc4uE8aN4979++xvVBeZphwNDRleK1diaWmp7tAEQRA+m0iShVxPT1+fVyHB2DVpzoP1a7g8eQLWtesRcuoYcU8eM2XVSubOncuTJ0+wtLR8b9Kjq6tLSlwc6UlJmYlSSngY+qbG72wLGYmwXEsLo6LFqL3cm1ehIfw96jfM8ptjZmb2zvbx8fFoGRhmJsgAuja2xD158NZ23t7ejPfwoGDTFkTdvonv3r306tMHE1NTkiVSbBo15cH9u4RdukSRDp0zuwxa16qLrqkpDx8+/Owkefv27USEh6Mjl3OiVzckUin6+nrExcTgunMvEokUv44ZJc9kb1SYkL2ewuI0ajyHWzcl1NeHB3+uRlMuZ4qnJ02bNv2sONTJ1MyMmNd1nwFiHtzLeDwLzT0ePXrEzp07efr0KfsPHCBf2fLIjY1ZN2AAE8aNY8miRSiVync+OL3p2LFj/LFwIbVWrMGqek0irl/jpLsbipRkXuzfy+C5c97Z59KlS/Tp14+QwEC0tLXxmDCBfv36feEz8G3o6emxa/t2bt68SWxsLCVKlMDCwuKLj5eUlMTdu3cxMjISibYgCNlOJMlCrjd4wABmzplF8T79cWjTnme7tvNivy9FihZj144dFClSBABra+sPHsPFxQWT33/n/CB3bFu2Jvr2LYJPHqfn3r3v3f7u3bskJSTQeOY8NPUNMHQoQqkBvxCxffN77xSWK1eOpKhIHmxYS7Eu3Yl7+oRnO7cRKpNSvFQpyjo5MXvmTCZPmUL5cZOIefiA1NhYqvw+h7inT7nnvYKmB4+ha2mFSqXi9IDeBB7zo9zoCUikUuKePiYpJgYrK6vPfv7WbdpE8R69+WnIMJRpaaQlJuJb2xmZljYmxUsAUNtrPacH9OLC2BFUmOBJSnQ0txbNx6ZuA1KiMxaiXbtyhVevXmFiYqK2cm1fasKYMfQfMIBXoSFoGhriv2Mb7n37vvcDz5suXbpE67ZtMSpajJjn/ti1akeFCZ5IJBICDh1g2uhhdOvWDWPj93/Y+tfly5exLF8Rq+oZc9TzlS2HVY1avNi7h/Hjx9GxY8e3tg8JCaFD585YujTCtUNnou7cZtJkTywsLPj555+/7sn4SjKZjHLlyn31cc6cOUP3nr2IiYoEoGPnzvwxb56okiEIQrYR7zZCrjd48GC0tbVZv3kLyvQ0+vfpw9gxYz4rUTM0NGS/ry8jx4zh9orFmJubs23rVipVqvTe7f/9alv5Rpk6ZWrqB6swFC5cmCWLF/PL0KHcnD8bZXo6EpmMZIUCqYYmlx89pmXr1iQnJWHykxPX586k8tQZ2Lo25tne3WiZmaFrmZEASyQSTEuWJvzKZY736IxBIQeCjx6mfv36mJiYkJyc/Fl1ilNTU9F8fZdTqqmJpp4eSCQoUpLx3++LfbOWmJYoia61DbF3bnHo5yYAmJZ2wri4I1fGj6J127YYGBhgYGBAdHQ0gYGB2NjYZEtVim+hdevW6Ovrs37jRpJjonAbN5Y+ffp8cr+RY8ZSoElzKkyaxu7qFbGsViPzQ5KFc1WUSiWhoaGfTJKNjIxIDAlGkZqCTK6FUqEgOTiIYcN+Y/Dgwe9sf+rUKSTaOpT3mIJEKsXEsSRRt27iu2+f2pPkbyEsLIwu3bph3aI1dfoNJO7ZU3yHDMDezo7hw4apOzxBEPIIkSQLuZ5EIsHd3R13d/evOk6BAgXYsnFjlrYtWbIkxUqU4O9fB1Fi4BBehYZwf+UyRg9/9z/w+Ph4YmNjadmyJdWrV+fgwYOMHjMGp6HDsXVtTOj5s1yeNokkLS2Mzcx4uj0j2dfQyVi8aFK8BEnhL3nhdwhbl0YkRYQTcOgAdk2bI5HK8N/rg621NX5HjuB35AgmZmasXb06y535GjVowMp1qzEt7YReAVtO9++N6vUivovjRnJzwVwUyclI0tPwO3QIU1NTlixdyp59+wjwWka7pk2Y7OmJUqlkgocHXqsyqnuYmJmxxtubGjVqZCkOdXN1dcXV1fWz9nkREIBT7/5IJBIM7O15ceQgNnXrI5FKCTh8EE0tLWxsbIiOjmbFihXcuXMHS0tLRo4c+dY0hLZt27Jk2XLO9u+FZe36hF88T2pw8Hvnw2dSqTLm3Wf++PkLJXOqa9eukaZUUXbkWCRSKfnLVcChczeOnjghkmRBELKNSJIF4QvI5XJ2bN1Kv4EDOdO/F9o6Ogzu3++tdthKpRKPiRNZtXIlAPktLVm3Zg1RUVGYlCiJY8+MpL5wu44EnzpBxD8X6Onmxipvb2Sacq7OnEpVUzNk2lroW1lzfvgQjGwKEP8yDA0dHeQGhoSfP4OxgQFhUdFU+2MJKoWCoKOH6eLmxqW//85Si+gRI0YQFBLCttcLzGRaWtRdu4l8ZcrxdPdOrk73pLubG+PHj0culzN85Eh2+/igUiqpW78+Y0aPRltbmxUrVrB+8xZqrViDcdFi3F/rRZdu3Zjk4cHZs2c5e/48SUlJFHN0ZPEff7wzdzokJISxEyZw9949LC0s8Bg3LnNRY05lZ29HyImj2NRrQEWPKRzv0ZkDTRuga2JK+O2bGBgZUblKFeLi41FKpaQnJoJEwqatW2nRtCmhoaEYGhtTv25dDh7Yj+eUqTw6fIDStgXwPPgXdnZ27+24VqdOHSQeE7niOR6HDp2JvnOLgL27mejlpYZnIWsUCgXz5s1j/ebNpKen09DFhd+nTUNPTy/zg6SlpSUaGhpoaWmhSEslLTER+etvOVJjojH9gk6OgiAIX0q0pc4FRGvSnN2aVqlUIpFI3pmLvGzZMmbMnUulmfMxKlyEe14riDh+hF49evDn/gO47Nqfuc/xnl2IvHaFC3//jaamJgcPHuTPDRt4eC9jAZlTuXKMHzOG0NBQlEol5//+m+CwMByLFuXqjRtEmOYj+NQJVOkKlOkZHQxXLVtGixYtsnwdkZGRDBk6lMf6xlTynJb5+LE2zRjWozvu7u78MnQoB06cpJzHFKRaWtyaNY2S1lb47NjBz23bElXEEadfM6p9KBUKdlfNmJtqUtqJ+GdPkcrlmDqWIOH6Vc6cOpW5GCsuLo469euTamJGgWYtiLpxncDDf+F3+DC1a9f+buOflpbGtOnT2bHLB6VKSctmzZjs6fnJ6Sr+/v48fvyY6Ohoho0YgYF9IeRGxgRdOI9j8eI8evwYu5/bYOhQmFuL5iPV1ETH3JLaK1ajZWbGtZnTeOqzA3PnKujb2PLiwF66dOjA7Fmz3jrPx177V69exX3AAAKePkVXX59JHh5Z6vqoLjNmzGCZtzelhg5HQ1eP+8sW4VyqJLYFCrD6dSUUCytrVnut4ubNm8yaMwelvgGlBg0l4UUAd1cswdvLi+bNm6v5SrKPeO8XbakF9RJ3kgXhK32o2ciBw4dx6NQN61p1ACjvMZm9h//C2tqapKBArkydiK1rY0LOnSH86mU8J06kUKFCALi7u9OnTx8iIyPR1tZGT0/vrSS8a9f/Nxlp3KwZgcf8KD1oKCV69SUh8AXHu3di9549n5Ukm5mZYW5uzm3/gMzH0pOTSY6ORk9PD5VKxe7du6k4Yx5WNWsDoDH5d452akNMTAxampqkJvz/P/TgU8dRpKXhunU3xsUdSUtM4GiXdujZFiT+/j2OHDmCm5sbAIcOHSIqPp5G23zR0NVF1a4TKdFReK9eTe3atbN8DZ9rgocH2/bsoeTQ4UhkGmxfNJ/4hASWLVnywX2WLVuGp6cnGtrapCUl0bR5c0qVKEFqaip1Ro+kZ58+lB3rQZH2nQEIPXeGyFs3KN69V+a88rLDx/Bk+xacfhmGaamfsGvSnLU9OjN40CAKFiyYpdjLly/PlYsXefXqFTo6OtleNu9zrVm3jp9GjMmsY25gZ8+Rzm3RNjCg1vLVGNgX4u7yxbRq2w5NXR1MncoSfvM6VzzHY2lpxeJFi/JUgiwIgvqJJFkQvhNNTU3Sk5JQqVQkR0agUihQKtKxsbFhx7ZtDB02jDO7d2Jmbs4ab+93EgCJREK+fPk+eTfJuWJFrt28SYne/TLmxha0o2gXNwLOnPjsmHt0787WJk247Dke0zLlCPxrH/pyTRo3bpyxgUqFRPb/DwUS6esFjEolbl270qt3b3QtrTAqUpTbf8xFz9oG4+KOGc+Hnj4WVaqREPgCDV09UlJSMo8THx+PtokZGq+byEgkEnSsbYiP/3+b7m9NqVSyYeNGKs+cR4EGGS3QdfLlZ0e/nsyfO/e9d5MvXbqE5+TJVJ2zENuGjYm6c5ujfdyoU6sWPXr0ACAxPgE96wIApMbFkRwViTI1jQfr12BSshQmxUuQGBIEgIauHgCmTmWAjAVrWU2S//U5jXfUKTUlBS2j/98Z1DLO+HvBn9tgVaMWAKZlyvHimB/1t/uia2FJclQkx9q1pG/vXrRv314tcQuCkHe9/xaYIAhfrVunTjzesoF9LrXYW7ca+xrURFNDg7Jly1KlShUunj9PSHAwd27c+Ko7ZA0aNECVlkZKZGTmY4kvAjAx+nhFhfcpU6YMPjt3YvTCnyDv5ZQ01OfA3r2YmJhkdJFr1oxbc34n7NIFIm5c49rk8VSpXh0TExOaNm3KooULidy9g6tjR2Cpo0XKyzDi/Z8BGXelX/5zieTISGID/KlVq1bmeStVqkT0syc83b0DlUpF1J1bBP21j+rVvqzVdlYoFAoUaWnI33ie5K8Tt7Q3qpa86cqVK+R3LIFtw4wPDaalSmPt0pCLly5lbuNctQr3Vy7lVVgoJ3p3RfHqFSXd+6NvU4Cjndpwc+E8TvXtiZapGTqv7yw/3bENTS0tHBwcvtflql3tOnW4t3QBcU+fkPQyjOszpqBjYJD5QQsg/rk/JiVLoWuRMQ1H29QMs7Ll8Pf3V1PUgiDkZeJOsiC8IS0tDZlM9sEpFJ+jZcuWeHhORmJnR51Va0mJieGfscOZMXMmHTt0YM3atSS+ekWtGjXo3bv3F5/T2dkZpzJlOOPuhn27TsQ/e4q/rw+ztm79ouNVrVqVwwcOvPd38+bM4Zehv7K/d0bHQusCBahQtw7Pnz/H3t6eDh060KFDByDjTm2PXr040bUdZhUrE3X3DskR4WhqaOC9ahXFixfPPK6TkxNzZs9m1OjRXJkyEWV6Op26dPmuc2w1NTWpWqMGt+fPpvLs+UhkGtyaM50y5ct/sPGHgYEBr8LDM5vOqFQqkl4EYFzWKXObZYsX07ZDB/Y1qIlMW5vmfqfRMjZBpVJxql9PHq1fi1KlQqqtxX7XWmjq6ZMUGsLiRYs+WZc5N0pPT2f2nDncuXePVy9fcrBlRmdK+8JFGD50KDNnz0bXyhrDQoUIO3OKVxEvSXoZho65BSnRUUTduI5djWpqvgpBEPIisXAvFxCLN77/wr3g4GDc+w/g8sULaMrl9O7Vi4kTJ35Vq9/Hjx9TtWpVmh89k3lnzH/fHu7Ons6rhASs69ZHO785L/btoV2rVsyfN++9x8nK+MfFxeExaRKXrlzBxMiY4b8OpX79+l8c+6fMmzeP2XPnYl21BimR4bx6EcDePXtwcnJ6azuFQsG6detYtHgxQUFBaOnpk56cxJzZs99pDQ4ZFS4eP36MhYUFxYoV++7jHxYWRhc3N25cvQpAidKl2bxhAwUKFHjv9rGxsdSpX580EzOsGzYm8uoVXp47zfGjR9/q5Jiamsrs2bNZt3sPDQ8czXz82pwZ2IYG0qBuXfyOHSM2JobKlSrRsWPHt6p9XLp0iaHDh/P82TOsbQowZ+YM6tat+82vPzuMGDmSHXv3UazRhRYAACAASURBVLzvABSpqdxfuZSObdowc+ZMNDQ08Pb2Zt6CBcTFxlKmbDnS0lJ5/Pw5pk5libl7GwcbG/bt2YPO606YeYl47xcL9wT1EklyLiDeKL9vkpyWlkY9FxeitXQo+ctvJEeEc33aJAb37cuoUaMytztw4ADLV60iITGR2jVqMHbMmI9WQXj27BmVK1emyX4/DOzsAXi8fQu35s3CrkUryo+fBED4tSscd+vI5cuXsbOze+c4OW38Q0NDcXJyouq8Rdi6NEKlVHJxzDDMo6P4a9+7HQpnzJjBqk2bqb12E/q2BXnqs4OrUydy+tQpihUr9tFzZcf4K5VKnj9/jlKpxN7e/pMfjEJDQ5kwcRL3HjzAxtoKj3Hj+Omnn97Z7saNGzRwccG8UhV0zM0xLl6cx+vW8kuf3gwfPvyDx3/69Cl16tXDulFTbFwaEXb+LE+2buTwwYPvfAjJ6ZKSkrCzs6PmUq/MxZ7++325MXUiAf7+711smJqaysaNG/H398fR0ZG2bdvmug6O30pOe+1nJ5EkCzmBmG4h5HmPHj3i/p07tDhxHp18+QFIjoxk2/bNmUmyr68vffv1o3CnruiaW7Bh8wYeP3nCxvXrP1hVwM7OjorOzlwaMYSSQ0eQEh3N3cXz0dKSY1KqdOZ2pq///vLly/cmyTlNYGAgKpUK69oZdzYlUimWNevybMn8925/8coVbFu0Qt82Y0GaQ+t2PFi+mBs3bnwySc4OUqk0s6pIVlhaWuK9auUnt4uOjkYqlSLTkiPV0ODmwvkULFCAX3755aP77d+/H70CBakwaRoSiQSr6jWJu38XHx+fXJkkq1QqdF5/kwKga2lFanIyCoXivS2m5XI5vXr1yhXlHwVB+LGJJFnI85TKjE5l0jfuIEo1ZJmPA8xbuIjiPfpk1gC2qlmHQ62a8OjRow8melKplI3r1jF46FBO/zoITS05vd3cuP/oEbf3+mDr2hgNXV0eb92MXEubwoULf8er/HZsbW2RSqUEnziObcPGqJRKQk8dx/713fL/MjUyJsD/aebPyZGRJMXGcPPmTcLCwihVqlSunUrwMR6TJ1OkU1fKjZ4AQAGXRpwZ5E5MTMxHm7ykpaWhoft2STcNPb0PLibMyUxMTCjq6MidhRn1wlXpadxbupAKlZ3fmyALgiDkJOJdSsjzihUrRqEiRbk0ehilh40iOTyc+8sX07Nz58xt4uJisX7jLq/+6zJdsbGxHz22mZkZWzZuzGgf/DrpCQoKolnLlhxsWAe5oSEJIcEsXbIEU1PT73B1356FhQUeHh5MHf0bAbt3kBwRQXJIEH/6+r53+18GD6JJs2ZcHD0Mw+KOvNi7G00NDdZt2YphwYJEzphBz549+X3atPfun1uFhYZSomyFzJ/zlcv4e1hY2EeT5Hr16jF7zhwerFuDbcOMtuWBp07QYEC/7x7ztyaRSNjw55+069iR3dXKA1DU0RGvz1xUqlAovmp9gCAIwpcQc5JzATEv7ft/5erv70/3Xr25e+smEomELl27MnvWLDQ1NQHoN2AAp27dpsaKtWiZmnJzwRwCd23n+tWrGBkZffb54uLiOHbsGAkJCTg7O3902kFOHf8TJ05w5swZ9PT0aNu27Uenily+fJm58+cTHhmJKj2dgOgY6m7eiZaxCeHXrnCyV1d279pFtWpvVzH4luOvUqkICwsjPT0da2vrb1LB5GOatWxJkFybKvMXI9OU82DDWu4tms/dO3cwNDT86L67du3i199+IzkpCU25nOnTptGzZ8/vGu/3lJSUxL1795BKpZQsWTJLc4xlMhkvXrygY5cu3L9zByNTUyaOH5+54DMtLY1169bx4MEDLC0t6d27N8bGn1/2MCfLqa/97CDmJAs5gUiScwHxRpl98xJjY2PR0tJ6Z0FedHQ0bTt04NaNG2jI5cg1NVm7enW2TBP40ca/U9euBFjYUG7k2MzH/Fo2YuyA/pkNOf71rcY/JiaGnn36cPbUKQBKlP6JzRvWf7CKxbfw+PFjmrVsSZpMhtzAkOinT1i2dCmtW7fO0v7JyckkJCSgq6ubaxqGfEvR0dFUq1EDvXIVcejQmeh7d7k5fxZrVq+mUaNGdOjcmX+u3yB/5SrE3ruDoVSC36FDueYbmaz40V77n0MkyUJOIKZbCMIbPnRX2MTEhEMHDnDlyhUSExNxcnIif/782Rzdj6GAlRU3r11FmZ6OVEODxOAg4kOCsbKy+m7nHPLbb9wNCsZ15140tHW46jmert27c+Lo0e/WzrlIkSKcOXmSQ4cOkZSURPXq1SlVqlSW99fW1iZ//vx5Nkk6deoUSQoFdWfMRaqpiXklZ+KePmHbjh0oFAouXLyEy6596NkUID0piROd27BkyRImTpyo7tAFQfhBiCRZELJIU1OTKlWqqDuMXO/XX39lr4sLJ7q2w9CxJGGnT1DF2ZkGDRp8l/OpVCqO+R3Fef4iTIqXAKDsBE8O/dyE8PDwj84P/lr58+fPnB6QkJDA8+fPsbKyyrMlzT6HQqFAKtNA8uaCWrkcRaKCwMBAjOzt0bPJ+CZAQ0cHk/IVCQgMVFe4giD8gERbakEQspWNjQ0njx2jfe1alEPBiIED2bpp03ddmKUh1yQtISHz53///u+c8+/tjz/+oHCRIlSsWJHiJUty5MiRbDlvbla9enVUKclcmzGVuGdPCTi4H/9d22netCkODg5EP3lM7ONHAKTGxhJ54TxFc0mFGEEQcgdxJ1kQhGxnZWXF5MmTs+VcEomErp07s3HWdJTp6Wjo6HB3wVwaNm6cLXMed+/ezew5c3GeOY98ZcvzdOc2evbqzamTJyhSpMh3P39uZWNjw1/79tG6XTsObt2ITEODkSNGZLY9b9K4CYe6tiNfaSdinz7G1sKCQYMGqTlqQRB+JCJJFoQcKDY2ln379pGQkEDt2rUpUaKEukPKkRITE3n06BF6enoUKVLkg/OLPSdNQiqVsmXeTBQKBY0aNmTOrFnZEuPBQ4ewbdaCgo2aAlBq0FBCjhzkzJkzWUqS3ywfmNfUrFmT+3fuEBoairGxMVpaWpm/W7ViOb6+vhnVLdq2pn379nlygaMgCN+PSJIFIYcJCQmhcbNmxCYlo5svPxMnTWL6tGm4u7urO7Qc5dKlS3Tt3p3o19Vraterx7o1a9DT03tnW01NTaZOmcLUKVOyO0w0NTVRxPx/8Z1KoSA9JfmTzTROnz7NsJEjefH8OTYFC7Jg7lxq1ar1vcPNcaRSKRYWFu99vFWrVmqISBCEvELMSRaEHGbcBA/S85nT8MBR6m7fg/OMuUyYMIGAgAB1h5ZjxMfH08XNDdM69Wlz8QaN9x7m+uPHTPL0VHdo7+jUsSOBRw9ze9kiQs6d4dLYEUiTk3FxcfngPvfu3aNj585oV6tFqUG/kqirT/v2HTh9+nQ2Ri4IgpC3iSRZEHKYuw/uY9OoKRo6OgAUbNwMqYYGT548UXNkOce9e/eIiYyk3BgPNHR1MSzkQJHufThx+sxXHzspKYm7d+/y4sULPlZGXqVSffT3/6pRowbeXl5E79/D30MHoB/8gt27dmFpacmLFy9w79ePBo0a4d6vHy9evADA19cX0xIl0TAw4PayhciNjNGxsaGLm5v4dyAIgpBNRJIsCDmMjZUVkdcuZyZgUXdukZ6aiqWlpZojyzn+nXuaHPn/RkHJEeFfPSf1n3/+oVzFitSuXZvy5cvTo1cvkpOT39omJSWF4SNGYFeoELYFC9Knb79P1jJu3rw5N65eJTgwkJPHjlG6dGnCwsJwbdyYCwGBqGrU5UJAIK6NG/Py5UvS09NRIeHO8sXUWLiM2ivX0Nj3ECZlyzPOw+OrrlEQBEHIGpEkC0IOM2nCBMJOHueMe3f+mTSOs+496NKt2zdZvKdUKrl37x5Xr14l4Y2SaLlNiRIlcK5ajXMD+vBszy7urFjCfe8V9O/T+4uPGRsbS+du3TCuWZefz/6Dy7Y9nLl8hem///7WdmPHjcPn4CHKTZlBpTkLOHXtGv0HDvzs823ZsgWFnj41Vq2lRJ9+1Fi1FoWePps3b8bFxYXwm9eRyGRY1awDgFRDA+u69Xnm7//F1ygIgiBknUiSBSGHKVOmDH5HjtCopCPlpSrmzPid+XPnfvVx4+LiaNmqFbVq1aJhw4ZUdHbm6tWr3yDi7CeTydi8cQMulSvyYtVSko8dZu7s2XTp0uWLj3n79m3iYmIoN34iWkbGmJYsRZEevTl68mTmNiqViu3bt1NmrAe2ro2xqVOfClNncuTQoc/ujBcTE4O+bUFkmhmNRWSacvQLFCQ2NhZnZ2cmenigUigI+/ssAEqFgpfnzmBvZ/fF1ygIgiBknahuIQg5kKOjI7NnzwbAwMDgm7QmHjNuHA9CX9L0r2Nom+Xj2owpdHFz48qlS7mydJahoSFLFy/+ZsfT1tZGqVCQFhuHLF8+AFKiotDR1s7cRqVSoVAqkWn9/zHZ67Jk6enpn3W+8uXLs8rbm/BrV8hfrgLh164QevE85bp3BWDw4MEkJCayYHA/rKvXJCkkhNSwUKYd2P+1lyoIgiBkgUiSBSGPOH32LEUHDEHftiAAZUaNZ3e18jx+/BgnJyc1R6d+Tk5OOJUrx7mBvSna053EoCAe/un91l18qVSKi6srF+bORG5igkxTzvVpk6jo7PzZjUmaN2/O3xcv4u3WEV1jE17FRNOnb1+aN2+euc30adNw+uknLl68iH7linTq1IkCBQp8s2sWBEEQPkwkyYLwgwgNDSUmJgY7Ozt0XlfGeJOuri5J4S8zf056GQrw3rrCeZGmpibbt2xh+KhR/D13Bvr6BsyaMYNOnTq9td3iBQvo068fRzu1AaB8pUqs9fYG4K+//mLewoXExsZSpVJlpk+bipGR0XvPJ5FImDF9Op06dCAgIICCBQu+98NKkyZNaNKkyTe+WkEQBOFTJKqs1DDK5eLi4t7q1JTbaGhofPZXuT8KiUSCXC4nNTU1S+W2fkSfGv/09HT69e/Ppo0bATAxM2Pbli3vNJ7w8vLitxEjcHQfgE5+cx6tWUWFYkXZv3dvju3ollPHX6VSERUVhVKpJF++fEgkEg4cOEC79u0p2qU7+nb2+G/dhL2JESePHUNTU/OLziNe+zlv7LOTGH+5usMQ8rg8cSc5NTWV1NRUdYfxxb7VnNTcSCaTIZfLSUxMRKFQqDsctfjU+M+ZM4fdfx2k3vqtGNoX4s6KJbRu145Lf/9N/vz5M7fr0KEDKSkprFy9mpikJJrWqsm0KVNydJWLnDz+iYmJBAUFkZSUhImJCXP/+IPC7TpRduRYAGzqNWBf/RqcPHmSKlWqfNE5xGs/Z459dhHjL5JkQb3yRJIsCD+yIydO4NC5G/nLVQCg3OgJPPf14dq1a7i6umZuJ5FI6N69O927d1dXqD+MlStXMnHSJJQKBTINDaZPm0Z8QgI6VlaZ22ib5UNDSytHfwgRBEEQPkyUgBOEXE5HS4vUmJjMn9MSElCkpqH9RlUG4fMplUqWLl1Ktdq1ca5Rg2nTp5OWlsaJEyeYOGkSlabNotW5K1TwnM7YceNwsLPj2dZNxPs/Q5mezu3Ff6AhlfLTTz+p+1IEQRCELyDuJAtCLtere3f6DxiA3NgYw0IOPNnwJ4UcClGpUiV1h5arzZ07l0XLllO87wBkWlp4ey0nIjISY0NDrKvVwL5ZSwAKtWxN0IG92BYoQKXERP5q7opEKkVHV5fVXl5YWFio+Uqyz+PHjzl48CBKpRIXFxdKliyp7pAEQRC+mEiSBSGX+/nnn0lOTmbOHwsIjI2hfPnyLJy/7r0VLoSsUalULFu5kjJjJlDo54wqFoaFCrOpX08GDx5MakwMKpUKiUSCSqkkNSYGAwMDtmzaxL1794iNjcXR0RFTU9PPOu/z588ZPHQoN65fx9jEBE8PD1q3bv09LvGbO3fuHB06dcLAzh6pTMbM2bP5c80abG1tOXr0KFKplMaNG1O4cGF1hyoIgpAlIkkWhB9Ax44d6dixo7rD+GGoVCqSX71C1/L/c4z//XujRo3wXrOGyxPHYlmrDiEnj5P44jmtWrVCKpVSqlSpLzpnQkICP7dpg9K6ABVn/0Hso4cMGDgQTU3Nt2on51SDhgzBrlVbyo7xQCKRcHvpQvr2H0BKSjKmRYuhUiiYOXs227ZsoXr16uoOVxAE4ZPEnGRBEHIkdVY0kEqlVHJ25t7yxaRER5GWmMDthfMoVKQolStXZveuXej5P+HOtEkYvPBnj48PDg4OX3XO8+fP8zI8nKoLlmFdqy4levfDoV0n1m3a9I2u6vMdPnyYcePGMWXKFB4+fPjB7dLS0ggKCMC2cbPMcoK2jZrwKiGeIp26UW/bHurt2Itd63YMGjIku8IXBEH4KiJJFgQhR3n69CmujRtjbW2NnYMDc+fOVUud3JXLlmGUlMieWs74VCmH4tF9Nq77E4lEQsWKFTnu58fjBw84duQI5cqV++rzpaamItPURPbGgktNAwNSUlK++thfYuHChbj16MGhJ/5sP3OOeg0acPny5fduq6mpiZm5OWF/n8t8LOzC30ikUuxbtgIyqqvYNmpKUEAAaWlp2XINgiAIX0NMtxAEIcdISEigTfv2qGztqO29nnj/Z4yb4IGGhgZdu3bN1lisra05cfQod+/eRaFQUKJECXR1db/b+SpWrIhUpeL6rGkU79WXuCePeLZ1E+NHjfxu5/yQ8PBwpk+fTtV5i7B1aYRKpeKyxxjGTJjA0UOH3rvPnJkz6ePuTvStG0g0NAg6dQKZhgYv/7mEcTFHAMIunMfM3PyLm6sIgiBkJ5EkC4KQY1y+fJnQkBBabt+Lhq4u5pWcSQwOYtO2bdmeJAPI5XLKli2bLeeytLRk0/r19OzTh4ebNwAwYOBA+vbtmy3nf1NwcDAqlQrL6jWBjLvA5tVq8Gj+uQ/u07x5c/b6+uLr64tSqaTJ4B34+PiwadY0Qs+fQZWezssL5/F+3cJbEAQhpxNJsiAIOYZCoUAilSLR/P9bk1QuR6lUqjGq7FO9enVu37hBYGAgJiYmFCxYUC0d12xtbZFpaBDod5hCLVujVCgIOX6UQoUKfXQ/Z2dnnJ2dATh9+jSbt2yhcLuOpMbFkvDcH5mGBo6OjtlxCYIgCF9NJMmCIHwXSqWSWbNm4b12LSlJSdSsVYvFCxeSL1++D+5ToUIFDA0NuTxhDCX6Dybe/xlPNvzJ2BHDszFy9bl//z4PHjzAwsLikwnp92Rqasrv06czZuxYAn13kRwVTVpEOOt892T5GPv376dA3fpU9JgCZFQMOd6uBX5+fhQtWvR7hS4IgvDNiCRZEITvYv78+Szz8sJp1Hi0TM24vnQBXdzcOLh/P1Lp+9cMGxsbs33LFtx69uRgi4ZIpVKGDB3KoEGD1LJ4LzstXLiQ6dOno2tqSlJMDA0bNWLHtm1qi6dXr144Ojpy9uxZdHR0aNWqFQUKFPi8g/xnyFR55BsBQRB+DBLVj/4/DxAREaHuEL6KgYGBWr5yzQlkMhkmJiZER0ertSSYOuXW8S9bsSIWnbtTtHM3ABICX3CgcT3Onz//yTuJKpWK8PBwjI2Nsba2/uHH/59//qFZ8+ZUm78Em3oNiHv2lFM9OjNx1Eh69+6t7vC+yNmzZ2nTti0/DR2OeeUqBOzfi/+ubZw8fpwiRYp8cn/x2s+9r/1v4d/xFwR1EiXgBEH4LtLS0pC90fVPQyejMkR6evon95VIJJibm+eZroHXrl3DrEhRbOo1AMCwkANWLg25+M8/ao7sy9WoUYNlS5fybI0Xfh1bE3PsCFs2bcpSgiwIgpATiOkWgiB8F00aNcJn+WIM7AuhbWrGzdnTsXNwEG2J38PU1JTEsDBS4+KQGxqiUqlIfPqE/OXKqDu0r9KmTRtat25NUlLSdy2fJwiC8D2IJFkQhO9iiqcnUZFR7HXLaJdduFgxNm3ejFwuV3NkOU+TJk2Yv3Ahp3t1xdq1EdE3rxN37w6DV3upO7SvJpFIRIIsCEKuJKZbCILwXejo6LDa24uHDx9y8+ZNzp85I+4if4Curi4H9u6liXMlNC+co4yhPocPHqRYsWLqDk0QBCHPEneSBUH4rnLa4pu7d++ybds2kpOTqVu3Lo0aNVJ3SEDG8zR/3jx1hyEIgiC8Ju4kC4KQZ5w/fx4X14b4/HOZowGBdO/Zk0WLFqk7LEEQBCEHEneSBUHIM8ZO8KBgi58p7zEFiURCwKG/mD76N7p27Yqpqam6wxMEQRByEHEnWRCEPCMw8AXmVasjkUgAsKxaHaVSSWhoqJojEwRBEHIakSQLgpBnOBQuTJDfIZSvm1MEHP4LDbn88zvJCYIgCD88Md1CEIQ8Y/7s2bRo1YpjbZqhZWRE2I3rzJs7F0NDQ3WHJgiCIOQwIkkWBCHP+Omnnzh94gR79+4lOTmZWtOmUqlSJXWHJQiCIORAIkkWBCFPsbW1ZdCgQeoOQxAEQcjhxJxkQRAEQRAEQfgPkSQLgiD8oJKTk1G8XqQoCIIgfB6RJAuCIPxgAgMDadikCba2thQoWJAJHh4iWRYEQfhMYk6yIAjCDyQ1NZX2nToRb2BE/Q3bSQoPY/0UDwz09Rk9erS6wxMEQcg1RJIsCILwA3nw4AGP7t+n5ckLaJuZAZD0MowdO7aIJFkQBOEziOkWgiAIPxCVSgWARCrJfEwikfL6YUEQBCGLRJIsCILwA3F0dMShaFEujRpG1J1bBJ04xv0VS2jdsoW6QxMEQchVRJIsCILwA5HL5WzfsgWz5ET8Orbm/G+D6Ni6FaNHjVJ3aIIgCLmKmJMsCILwg7Gzs+O4nx8JCQloaWmhqamp7pAEQRByHZEkC4Ig/KD09fXVHYIgCEKuleuS5GfPnuHt7c2jR4+Qy+W4urri5uam7rAEQRAEQRCEH0iuSpLj4+OZOHEiPXr0YNKkSahUKoKDg9UdliAIgiAIgvCDyVVJsq+vL2XLlqV+/fqZjxUqVEiNEQmCIAiCIAg/olyVJN+/fx87OztGjx5NYGAgDg4O9O3bF1tbW3WHJgiCIAiCIPxAclWSHBERwaNHj5g8eTKFCxdmx44dTJ8+naVLlyKTyd7aLiIiIvNnqVRK/vz51RHyNyGRSN66vrzk3+vOq9cPYvzf/DOvEWOfd8cexPgLgrrlmCR55syZnD9//oO/37t3L1paWjg7O+Po6AhAhw4d2LVrF0FBQRQsWDBz2127duHl5ZX5c48ePRg8ePD3Cz4byOVydYegVoaGhuoOQa3E+Ofd8Rdjn3fHHsT4C4I65ZgkecyYMZ/cxt7ePkvHatOmDbVr1878WSqVEh0d/aWhqZ2enh6JiYnqDkMtZDIZhoaGxMXFoVAo1B2OWojxz7vjL8Y+7449iPHP6x+QBPXLMUlyVri4uDBt2jQePXqEg4MDO3bswNzcHBsbm7e2y5cvH/ny5cv8OSIiIle/yapUqlwd/7egUCjy7HMgxj/vjr8Y+7w79iDGXxDULVclyaVLl6ZXr17MmDGDV69eUaRIEcaPHy/mLgmCIAiCIAjfVK5KkgFcXV1xdXVVdxiCIAiCIAjCD0yq7gAEQRAEQRAEIacRSbIgCIIgCIIg/IdEpVKp1B2EIHxIREQEu3btok2bNm8txhTyBjH+eZcY+7xNjL+QE4g7yUKOFhERgZeX11vNYYS8Q4x/3iXGPm8T4y/kBCJJFgRBEARBEIT/EEmyIAiCIAiCIPyHzNPT01PdQQjCx+jo6FCxYkV0dXXVHYqgBmL88y4x9nmbGH9B3cTCPUEQBEEQBEH4DzHdQhAEQRAEQRD+QyTJgiAIgiAIgvAfua4ttSCMHz+eW7dusXPnTuRyubrDEb6DhIQEli5dytWrV9HR0aFVq1a0bNlS3WEJ2SwuLo4BAwZgZWXF3Llz1R2OkE3CwsJYuXIl9+/fRyaTUb58efr16yfmJgvZTtxJFnKVY8eOoVAo1B2G8J2tXLmStLQ01q5di6enJzt37uTKlSvqDkvIZmvXrsXW1lbdYQjZbOnSpejr67N27VqWL19OREQEmzZtUndYQh4kkmQh14iLi2P79u307NlT3aEI31FycjLnzp2jW7du6OrqYm9vj6urK35+fuoOTchGt2/fJjg4mAYNGqg7FCGbhYWFUatWLbS0tNDX16datWo8f/5c3WEJeZBIkoVcY+3atbRo0QJjY2N1hyJ8R0FBQahUKuzs7DIfK1SoEAEBAWqMSshOaWlprFy5kv79+yORSNQdjpDNWrRowalTp0hKSiIuLo5z585RoUIFdYcl5EEiSRZyhdu3b/P8+XMaN26s7lCE7yw5OfmduYd6enokJSWpKSIhu+3atYsyZcpQqFAhdYciqMFPP/1EUFAQnTp1omvXrmhqatKsWTN1hyXkQWLhnqB2M2fO5Pz58x/8vY+PDytWrGDIkCFIpeJz3Y9OW1v7nYT41atX6OjoqCkiITsFBwdz7NgxFi5cqO5QBDVQKBR4enrSoEEDZs6cSXp6Ol7/a+9eQ6La/jCOPzP+dRoH5VQOpkYogVZmdMUiw14kwShRaAgRdiHKMhAxqBC7YBaBybzoykmMMoguCJFCStmFIki6QBAllGYhoqBSUzFo67w4nKEZ64+d42k8zfcDG2attWetn/vF8LD3Guf331VdXa2dO3cGuzyEGEIygm7Xrl3/d7y7u1tv377VgQMHJElfvnyRJG3atEnFxcU8hvvFJCQkSJLevHmjKVOmSJJev37te41f2/Pnz9XX16fCwkJJktfrldfrVUFBgU6ePMl/OPjFeTwe9fb2KicnRxEREYqIiJDL5VJZWVmwS0MIIiRjzIuJiVFtba2v3dvbq9LSUlVVVWn8+PFBrAz/hnHjxmnx4sU6d+6cSkpK1NPTo6amJhUXFwe7NPwEQOZXGAAABh9JREFUGRkZmjt3rq999+5dtbS0aM+ePTxNCAHR0dGaNGmSGhsblZubq6GhIV2/fl2JiYnBLg0hiJCMMS8sLMwvDHu9XknSb7/9pvDw8GCVhX/Rli1bdPToUa1fv152u125ubk8MQgRNptNNpvN13Y4HMM+A/Br2717t2pqanT16lVZLBalpKSopKQk2GUhBFmMMSbYRQAAAABjCd+CAgAAAAIQkgEAAIAAhGQAAAAgACEZAAAACEBIBgAAAAIQkgEAAIAAhGQAAAAgACEZAAAACEBIBgAAAAIQkgH42bdvnywWy7Bj5syZo7qO2+1WY2PjqM45Wo4fP66cnBw5nU5ZLBZdvnw52CUBAH6y/wW7AABjj91u182bN/36IiMjR3UNt9utnJwcuVyuUZ13NJw9e1aS5HK5fK8BAKGFkAxgGKvVqoULFwa7jB/y6dMn2e32UZnr/v37slqtam9vJyQDQIhiuwWAH9LQ0KD09HTZ7XY5nU5t3bpVHo/HN+7xeLR9+3alpKQoMjJSiYmJKiws1MDAgO+cxMREdXR06NixY77tHGfOnJEkWSwWVVVV+a3pdrtlsVh87Vu3bslisaihoUF5eXmKjo7W6tWrJUn9/f3atm2b4uLiZLPZNG/ePDU1Nf3Q32i18tEIAKGOO8kAvmlwcNCvHRYWpitXrig/P18bNmzQ/v371dXVpV27dqmvr08XLlyQJH38+FFDQ0OqrKyU0+lUZ2enKisrtXLlSrW0tEiS6uvr5XK5lJGRodLSUknS1KlTf7jGzZs3a+3ataqvr1dYWJi8Xq+ysrLU3d2tyspKJSQkqK6uTtnZ2Xr06JHS0tL+4VUBAIQKQjKAYTwej8LDw/36zp49q/LycuXn5+v06dO+/ri4OLlcLpWXlys1NVVOp1MnTpzwjQ8ODiopKUkZGRl6+fKlkpOTNWfOHNlsNsXGxv6jbR0rVqzQ4cOHfe3a2lo9efJET58+1YwZMyRJy5cvV1tbmyoqKnTx4sW/vRYAILQQkgEMY7fbdefOHb++oaEhdXR0yO12+91lzszMlNVqVWtrq1JTUyVJ586dU3V1tdra2vy2YvwVkkdLdna2X7upqUlpaWlKTk72qzErK0t1dXWjti4A4NdHSAYwjNVq1fz58/367t27J0latWrVN9/T2dkp6c+tFAUFBdq8ebMqKys1ceJEdXV1adWqVfr8+fOo1hkbG+vX7u3t1ePHj4fdBZf+3C4CAMBIEZIBjMiECRMkSUePHlV6evqw8fj4eEnSpUuXNHv2bJ06dco3dvv27RGvY7PZ5PV6/fr6+vq+ee7XX+b7q8ZZs2appqZmxOsBAPAthGQAIzJt2jRNnjxZr169UlFR0XfP+/TpkyIiIvz6zp8/P+y8iIiIb95Znjx5sp4/f+7X19zcPKIaly1bpsbGRsXHx/tCOwAAfwchGcCIWCwWVVdXa82aNfJ4PMrOzpbD4VBHR4caGhp08OBBJScnKysrS0VFRaqoqNCiRYvU2NioGzduDJtv+vTpunnzppqbmzV+/HglJSVp4sSJysvLk9vt1oIFC5SSkqK6ujq9e/duRDUWFBTo1KlTWrp0qXbs2KHk5GT19/fr8ePH8nq9OnTo0IjmaW1tVXt7u3p6eiRJDx48kCQ5nU5lZmaO8IoBAP7TDAB8Ze/evcbhcHx3vKmpyWRmZhqHw2EcDodJTU01paWlpr+/3xhjzODgoCktLTVOp9NERUWZvLw88+DBAyPJXLp0yTfPs2fPzJIlS0xUVJSRZGpra40xxnz48MFs2LDBTJgwwcTExJiysjJz5MgR8/XHVUtLi5FkHj58OKy+gYEBU1JSYqZMmWLCw8NNXFyccblc5tq1ayO+BuvWrTOShh2ZmZkjngMA8N9mMcaYoCV0AAAAYAziZ6UAAACAAOxJBhAyjDEaGhr67rjVauUnqQEAkriTDCCE3L59W+Hh4d89Nm7cGOwSAQBjBHuSAYSM9+/f68WLF98dj4mJUWJi4s8rCAAwZhGSAQAAgABstwAAAAACEJIBAACAAIRkAAAAIAAhGQAAAAhASAYAAAACEJIBAACAAIRkAAAAIMAf18+Pg3g11A4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ggplot: (8754637745798)>\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(scaled_X)\n",
    "\n",
    "scaled_X_pca = pca.transform(scaled_X)\n",
    "\n",
    "pca_df = pd.DataFrame({\"Labels\": km.labels_, \n",
    "                       \"Feature_1\": scaled_X_pca[:, 0], \n",
    "                       \"Feature_2\": scaled_X_pca[:, 1]})\n",
    "\n",
    "print(ggplot(pca_df, aes(x='Feature_1', y='Feature_2', fill=\"factor(Labels)\"))\n",
    " + geom_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPTW63iK10Df"
   },
   "outputs": [],
   "source": [
    "## Join Clustering Labels\n",
    "scaled_X_Kmeans = np.column_stack((scaled_X, km.labels_.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FXXs88zGK7e"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfmpTyRRdVEA"
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ney73oAuJrM"
   },
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "def build_model():\n",
    "  clf = Sequential()\n",
    "\n",
    "  clf.add(Dense(32, kernel_initializer='random_normal', input_shape=(scaled_X_Kmeans.shape[1], )))\n",
    "  clf.add(BatchNormalization())\n",
    "  clf.add(LeakyReLU(0.2))\n",
    "\n",
    "  clf.add(Dense(64, kernel_initializer='random_normal'))\n",
    "  clf.add(BatchNormalization())\n",
    "  clf.add(LeakyReLU(0.2))\n",
    "  \n",
    "\n",
    "  clf.add(Dense(1, kernel_initializer='random_normal'))\n",
    "\n",
    "  optim = optimizers.RMSprop(learning_rate=0.0001)\n",
    "  clf.compile(loss='mse', optimizer=optim, metrics=['mae'])\n",
    "\n",
    "  return(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f68nBl6ejfvE"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  clf = Sequential()\n",
    "\n",
    "  clf.add(Dense(16, kernel_initializer='random_normal', input_shape=(scaled_X_Kmeans.shape[1], )))\n",
    "  clf.add(BatchNormalization())\n",
    "  clf.add(ReLU())\n",
    "\n",
    "  clf.add(Dense(32, kernel_initializer='random_normal'))\n",
    "  clf.add(ReLU())\n",
    "  clf.add(Dropout(0.45))\n",
    "  \n",
    "  clf.add(Dense(64, kernel_initializer='random_normal'))\n",
    "  clf.add(BatchNormalization())\n",
    "  clf.add(ReLU())\n",
    "\n",
    "  clf.add(Dense(128, kernel_initializer='random_normal'))\n",
    "  clf.add(BatchNormalization())\n",
    "  clf.add(Dropout(0.3))\n",
    "\n",
    "  clf.add(Dense(256, kernel_initializer='random_normal'))\n",
    "  clf.add(BatchNormalization())\n",
    "  clf.add(ReLU())\n",
    "\n",
    "  clf.add(Dense(512, kernel_initializer='random_normal'))\n",
    "  clf.add(BatchNormalization()) ## 512 ----\n",
    "  clf.add(ReLU())\n",
    "\n",
    "  clf.add(Dense(1, kernel_initializer='random_normal'))\n",
    "\n",
    "  optim = optimizers.RMSprop(learning_rate=0.00001)\n",
    "  clf.compile(loss='mse', optimizer=optim, metrics=['mae'])\n",
    "\n",
    "  return(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w0Qt59pdYfn"
   },
   "source": [
    "## Loss & Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTSgOHy-uTIy"
   },
   "outputs": [],
   "source": [
    "## Loss & Optimizer setup\n",
    "keras_model = build_model()\n",
    "callback = [EarlyStopping(monitor='val_loss', patience=400, \n",
    "                                              verbose=1, mode='min'), \n",
    "            ModelCheckpoint('model.sve', monitor='val_loss', verbose=True, \n",
    "                            save_best_only=True, mode='min')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaS6yvPedb3c"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qYCYfqIiuU-x",
    "outputId": "4bd7429a-83d5-4aa6-df60-551d951f9215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 633 samples, validate on 159 samples\n",
      "Epoch 1/1000\n",
      "633/633 [==============================] - 1s 1ms/step - loss: 26.7709 - mae: 4.9362 - val_loss: 19.2776 - val_mae: 4.2095\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 19.27764, saving model to model.sve\n",
      "Epoch 2/1000\n",
      "633/633 [==============================] - 0s 207us/step - loss: 26.3589 - mae: 4.8902 - val_loss: 19.6302 - val_mae: 4.2512\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 19.27764\n",
      "Epoch 3/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 25.8028 - mae: 4.8540 - val_loss: 19.9609 - val_mae: 4.2899\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 19.27764\n",
      "Epoch 4/1000\n",
      "633/633 [==============================] - 0s 193us/step - loss: 25.2497 - mae: 4.8004 - val_loss: 20.2869 - val_mae: 4.3278\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 19.27764\n",
      "Epoch 5/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 24.8543 - mae: 4.7514 - val_loss: 20.5262 - val_mae: 4.3553\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 19.27764\n",
      "Epoch 6/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 24.3987 - mae: 4.7089 - val_loss: 20.7139 - val_mae: 4.3768\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 19.27764\n",
      "Epoch 7/1000\n",
      "633/633 [==============================] - 0s 227us/step - loss: 23.9426 - mae: 4.6699 - val_loss: 20.9029 - val_mae: 4.3984\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 19.27764\n",
      "Epoch 8/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 23.5497 - mae: 4.6267 - val_loss: 21.0720 - val_mae: 4.4176\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 19.27764\n",
      "Epoch 9/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 23.0174 - mae: 4.5739 - val_loss: 21.1847 - val_mae: 4.4304\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 19.27764\n",
      "Epoch 10/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 22.8543 - mae: 4.5442 - val_loss: 21.2297 - val_mae: 4.4355\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 19.27764\n",
      "Epoch 11/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 22.3398 - mae: 4.4990 - val_loss: 21.1828 - val_mae: 4.4301\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 19.27764\n",
      "Epoch 12/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 21.7633 - mae: 4.4394 - val_loss: 21.0758 - val_mae: 4.4180\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 19.27764\n",
      "Epoch 13/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 21.6277 - mae: 4.4186 - val_loss: 20.9414 - val_mae: 4.4028\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 19.27764\n",
      "Epoch 14/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 21.0701 - mae: 4.3571 - val_loss: 20.7735 - val_mae: 4.3837\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 19.27764\n",
      "Epoch 15/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 20.6184 - mae: 4.3156 - val_loss: 20.6037 - val_mae: 4.3643\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 19.27764\n",
      "Epoch 16/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 20.3949 - mae: 4.2793 - val_loss: 20.4182 - val_mae: 4.3431\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 19.27764\n",
      "Epoch 17/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 20.0053 - mae: 4.2270 - val_loss: 20.1829 - val_mae: 4.3160\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 19.27764\n",
      "Epoch 18/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 19.5254 - mae: 4.1820 - val_loss: 19.8356 - val_mae: 4.2757\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 19.27764\n",
      "Epoch 19/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 19.2537 - mae: 4.1464 - val_loss: 19.5733 - val_mae: 4.2450\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 19.27764\n",
      "Epoch 20/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 18.7911 - mae: 4.0886 - val_loss: 19.2575 - val_mae: 4.2077\n",
      "\n",
      "Epoch 00020: val_loss improved from 19.27764 to 19.25748, saving model to model.sve\n",
      "Epoch 21/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 18.5781 - mae: 4.0511 - val_loss: 18.9326 - val_mae: 4.1690\n",
      "\n",
      "Epoch 00021: val_loss improved from 19.25748 to 18.93258, saving model to model.sve\n",
      "Epoch 22/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 17.9667 - mae: 4.0098 - val_loss: 18.5627 - val_mae: 4.1245\n",
      "\n",
      "Epoch 00022: val_loss improved from 18.93258 to 18.56269, saving model to model.sve\n",
      "Epoch 23/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 17.6895 - mae: 3.9629 - val_loss: 18.1907 - val_mae: 4.0790\n",
      "\n",
      "Epoch 00023: val_loss improved from 18.56269 to 18.19071, saving model to model.sve\n",
      "Epoch 24/1000\n",
      "633/633 [==============================] - 0s 212us/step - loss: 17.4350 - mae: 3.9249 - val_loss: 17.8452 - val_mae: 4.0364\n",
      "\n",
      "Epoch 00024: val_loss improved from 18.19071 to 17.84520, saving model to model.sve\n",
      "Epoch 25/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 17.0772 - mae: 3.8739 - val_loss: 17.4904 - val_mae: 3.9920\n",
      "\n",
      "Epoch 00025: val_loss improved from 17.84520 to 17.49040, saving model to model.sve\n",
      "Epoch 26/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 16.7377 - mae: 3.8430 - val_loss: 17.2073 - val_mae: 3.9563\n",
      "\n",
      "Epoch 00026: val_loss improved from 17.49040 to 17.20734, saving model to model.sve\n",
      "Epoch 27/1000\n",
      "633/633 [==============================] - 0s 216us/step - loss: 16.2910 - mae: 3.7912 - val_loss: 16.7747 - val_mae: 3.9009\n",
      "\n",
      "Epoch 00027: val_loss improved from 17.20734 to 16.77474, saving model to model.sve\n",
      "Epoch 28/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 16.0957 - mae: 3.7525 - val_loss: 16.4180 - val_mae: 3.8552\n",
      "\n",
      "Epoch 00028: val_loss improved from 16.77474 to 16.41796, saving model to model.sve\n",
      "Epoch 29/1000\n",
      "633/633 [==============================] - 0s 196us/step - loss: 15.6584 - mae: 3.7138 - val_loss: 16.1243 - val_mae: 3.8178\n",
      "\n",
      "Epoch 00029: val_loss improved from 16.41796 to 16.12429, saving model to model.sve\n",
      "Epoch 30/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 15.4164 - mae: 3.6704 - val_loss: 15.7566 - val_mae: 3.7699\n",
      "\n",
      "Epoch 00030: val_loss improved from 16.12429 to 15.75660, saving model to model.sve\n",
      "Epoch 31/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 15.0086 - mae: 3.6115 - val_loss: 15.4385 - val_mae: 3.7278\n",
      "\n",
      "Epoch 00031: val_loss improved from 15.75660 to 15.43848, saving model to model.sve\n",
      "Epoch 32/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 14.8398 - mae: 3.5820 - val_loss: 15.1858 - val_mae: 3.6941\n",
      "\n",
      "Epoch 00032: val_loss improved from 15.43848 to 15.18577, saving model to model.sve\n",
      "Epoch 33/1000\n",
      "633/633 [==============================] - 0s 199us/step - loss: 14.4661 - mae: 3.5412 - val_loss: 14.8892 - val_mae: 3.6542\n",
      "\n",
      "Epoch 00033: val_loss improved from 15.18577 to 14.88916, saving model to model.sve\n",
      "Epoch 34/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 14.0966 - mae: 3.4860 - val_loss: 14.5284 - val_mae: 3.6053\n",
      "\n",
      "Epoch 00034: val_loss improved from 14.88916 to 14.52841, saving model to model.sve\n",
      "Epoch 35/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 13.8873 - mae: 3.4545 - val_loss: 14.2249 - val_mae: 3.5633\n",
      "\n",
      "Epoch 00035: val_loss improved from 14.52841 to 14.22486, saving model to model.sve\n",
      "Epoch 36/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 13.5683 - mae: 3.4081 - val_loss: 13.8432 - val_mae: 3.5100\n",
      "\n",
      "Epoch 00036: val_loss improved from 14.22486 to 13.84320, saving model to model.sve\n",
      "Epoch 37/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 13.2349 - mae: 3.3631 - val_loss: 13.5403 - val_mae: 3.4671\n",
      "\n",
      "Epoch 00037: val_loss improved from 13.84320 to 13.54029, saving model to model.sve\n",
      "Epoch 38/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 13.0778 - mae: 3.3340 - val_loss: 13.3066 - val_mae: 3.4338\n",
      "\n",
      "Epoch 00038: val_loss improved from 13.54029 to 13.30660, saving model to model.sve\n",
      "Epoch 39/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 12.6940 - mae: 3.2800 - val_loss: 13.0313 - val_mae: 3.3946\n",
      "\n",
      "Epoch 00039: val_loss improved from 13.30660 to 13.03132, saving model to model.sve\n",
      "Epoch 40/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 12.3572 - mae: 3.2443 - val_loss: 12.7209 - val_mae: 3.3498\n",
      "\n",
      "Epoch 00040: val_loss improved from 13.03132 to 12.72092, saving model to model.sve\n",
      "Epoch 41/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 12.1272 - mae: 3.2025 - val_loss: 12.4441 - val_mae: 3.3093\n",
      "\n",
      "Epoch 00041: val_loss improved from 12.72092 to 12.44409, saving model to model.sve\n",
      "Epoch 42/1000\n",
      "633/633 [==============================] - 0s 205us/step - loss: 11.8173 - mae: 3.1563 - val_loss: 12.1896 - val_mae: 3.2717\n",
      "\n",
      "Epoch 00042: val_loss improved from 12.44409 to 12.18958, saving model to model.sve\n",
      "Epoch 43/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 11.5312 - mae: 3.1199 - val_loss: 11.9170 - val_mae: 3.2303\n",
      "\n",
      "Epoch 00043: val_loss improved from 12.18958 to 11.91697, saving model to model.sve\n",
      "Epoch 44/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 11.2082 - mae: 3.0673 - val_loss: 11.6606 - val_mae: 3.1914\n",
      "\n",
      "Epoch 00044: val_loss improved from 11.91697 to 11.66064, saving model to model.sve\n",
      "Epoch 45/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 10.9620 - mae: 3.0294 - val_loss: 11.3752 - val_mae: 3.1476\n",
      "\n",
      "Epoch 00045: val_loss improved from 11.66064 to 11.37517, saving model to model.sve\n",
      "Epoch 46/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 10.7603 - mae: 2.9846 - val_loss: 11.1007 - val_mae: 3.1055\n",
      "\n",
      "Epoch 00046: val_loss improved from 11.37517 to 11.10066, saving model to model.sve\n",
      "Epoch 47/1000\n",
      "633/633 [==============================] - 0s 195us/step - loss: 10.5291 - mae: 2.9545 - val_loss: 10.8928 - val_mae: 3.0727\n",
      "\n",
      "Epoch 00047: val_loss improved from 11.10066 to 10.89280, saving model to model.sve\n",
      "Epoch 48/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 10.1851 - mae: 2.9013 - val_loss: 10.6673 - val_mae: 3.0380\n",
      "\n",
      "Epoch 00048: val_loss improved from 10.89280 to 10.66729, saving model to model.sve\n",
      "Epoch 49/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 10.0408 - mae: 2.8734 - val_loss: 10.4341 - val_mae: 3.0011\n",
      "\n",
      "Epoch 00049: val_loss improved from 10.66729 to 10.43413, saving model to model.sve\n",
      "Epoch 50/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 9.6993 - mae: 2.8310 - val_loss: 10.1807 - val_mae: 2.9606\n",
      "\n",
      "Epoch 00050: val_loss improved from 10.43413 to 10.18073, saving model to model.sve\n",
      "Epoch 51/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 9.5721 - mae: 2.7961 - val_loss: 10.0010 - val_mae: 2.9312\n",
      "\n",
      "Epoch 00051: val_loss improved from 10.18073 to 10.00102, saving model to model.sve\n",
      "Epoch 52/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 9.1798 - mae: 2.7477 - val_loss: 9.7627 - val_mae: 2.8920\n",
      "\n",
      "Epoch 00052: val_loss improved from 10.00102 to 9.76265, saving model to model.sve\n",
      "Epoch 53/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 9.0714 - mae: 2.7204 - val_loss: 9.5045 - val_mae: 2.8485\n",
      "\n",
      "Epoch 00053: val_loss improved from 9.76265 to 9.50454, saving model to model.sve\n",
      "Epoch 54/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 8.6907 - mae: 2.6557 - val_loss: 9.2655 - val_mae: 2.8076\n",
      "\n",
      "Epoch 00054: val_loss improved from 9.50454 to 9.26550, saving model to model.sve\n",
      "Epoch 55/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 8.5208 - mae: 2.6202 - val_loss: 9.0386 - val_mae: 2.7684\n",
      "\n",
      "Epoch 00055: val_loss improved from 9.26550 to 9.03864, saving model to model.sve\n",
      "Epoch 56/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 8.3809 - mae: 2.5936 - val_loss: 8.8217 - val_mae: 2.7301\n",
      "\n",
      "Epoch 00056: val_loss improved from 9.03864 to 8.82170, saving model to model.sve\n",
      "Epoch 57/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 8.1539 - mae: 2.5569 - val_loss: 8.6377 - val_mae: 2.6974\n",
      "\n",
      "Epoch 00057: val_loss improved from 8.82170 to 8.63770, saving model to model.sve\n",
      "Epoch 58/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 7.9932 - mae: 2.5265 - val_loss: 8.4262 - val_mae: 2.6596\n",
      "\n",
      "Epoch 00058: val_loss improved from 8.63770 to 8.42617, saving model to model.sve\n",
      "Epoch 59/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 7.8134 - mae: 2.4889 - val_loss: 8.2304 - val_mae: 2.6252\n",
      "\n",
      "Epoch 00059: val_loss improved from 8.42617 to 8.23040, saving model to model.sve\n",
      "Epoch 60/1000\n",
      "633/633 [==============================] - 0s 197us/step - loss: 7.5244 - mae: 2.4341 - val_loss: 8.0451 - val_mae: 2.5913\n",
      "\n",
      "Epoch 00060: val_loss improved from 8.23040 to 8.04510, saving model to model.sve\n",
      "Epoch 61/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 7.3755 - mae: 2.4187 - val_loss: 7.8222 - val_mae: 2.5495\n",
      "\n",
      "Epoch 00061: val_loss improved from 8.04510 to 7.82220, saving model to model.sve\n",
      "Epoch 62/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 7.1957 - mae: 2.3935 - val_loss: 7.6054 - val_mae: 2.5085\n",
      "\n",
      "Epoch 00062: val_loss improved from 7.82220 to 7.60541, saving model to model.sve\n",
      "Epoch 63/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 6.9829 - mae: 2.3311 - val_loss: 7.4398 - val_mae: 2.4760\n",
      "\n",
      "Epoch 00063: val_loss improved from 7.60541 to 7.43977, saving model to model.sve\n",
      "Epoch 64/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 6.6784 - mae: 2.2922 - val_loss: 7.2224 - val_mae: 2.4338\n",
      "\n",
      "Epoch 00064: val_loss improved from 7.43977 to 7.22245, saving model to model.sve\n",
      "Epoch 65/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 6.5521 - mae: 2.2487 - val_loss: 7.0560 - val_mae: 2.4015\n",
      "\n",
      "Epoch 00065: val_loss improved from 7.22245 to 7.05600, saving model to model.sve\n",
      "Epoch 66/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 6.4601 - mae: 2.2315 - val_loss: 6.8656 - val_mae: 2.3625\n",
      "\n",
      "Epoch 00066: val_loss improved from 7.05600 to 6.86563, saving model to model.sve\n",
      "Epoch 67/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 6.1579 - mae: 2.1706 - val_loss: 6.7037 - val_mae: 2.3293\n",
      "\n",
      "Epoch 00067: val_loss improved from 6.86563 to 6.70374, saving model to model.sve\n",
      "Epoch 68/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 5.9781 - mae: 2.1584 - val_loss: 6.4612 - val_mae: 2.2790\n",
      "\n",
      "Epoch 00068: val_loss improved from 6.70374 to 6.46117, saving model to model.sve\n",
      "Epoch 69/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 5.7676 - mae: 2.1090 - val_loss: 6.3020 - val_mae: 2.2459\n",
      "\n",
      "Epoch 00069: val_loss improved from 6.46117 to 6.30205, saving model to model.sve\n",
      "Epoch 70/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 5.7533 - mae: 2.1029 - val_loss: 6.1474 - val_mae: 2.2129\n",
      "\n",
      "Epoch 00070: val_loss improved from 6.30205 to 6.14739, saving model to model.sve\n",
      "Epoch 71/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 5.5091 - mae: 2.0312 - val_loss: 5.9509 - val_mae: 2.1705\n",
      "\n",
      "Epoch 00071: val_loss improved from 6.14739 to 5.95092, saving model to model.sve\n",
      "Epoch 72/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 5.3025 - mae: 2.0308 - val_loss: 5.7875 - val_mae: 2.1348\n",
      "\n",
      "Epoch 00072: val_loss improved from 5.95092 to 5.78750, saving model to model.sve\n",
      "Epoch 73/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 5.2873 - mae: 1.9963 - val_loss: 5.6397 - val_mae: 2.1032\n",
      "\n",
      "Epoch 00073: val_loss improved from 5.78750 to 5.63972, saving model to model.sve\n",
      "Epoch 74/1000\n",
      "633/633 [==============================] - 0s 198us/step - loss: 5.1574 - mae: 1.9715 - val_loss: 5.4727 - val_mae: 2.0674\n",
      "\n",
      "Epoch 00074: val_loss improved from 5.63972 to 5.47274, saving model to model.sve\n",
      "Epoch 75/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 4.8149 - mae: 1.8992 - val_loss: 5.3604 - val_mae: 2.0429\n",
      "\n",
      "Epoch 00075: val_loss improved from 5.47274 to 5.36044, saving model to model.sve\n",
      "Epoch 76/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 4.6844 - mae: 1.8753 - val_loss: 5.1945 - val_mae: 2.0055\n",
      "\n",
      "Epoch 00076: val_loss improved from 5.36044 to 5.19453, saving model to model.sve\n",
      "Epoch 77/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 4.7733 - mae: 1.8765 - val_loss: 4.9974 - val_mae: 1.9603\n",
      "\n",
      "Epoch 00077: val_loss improved from 5.19453 to 4.99736, saving model to model.sve\n",
      "Epoch 78/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 4.6015 - mae: 1.8329 - val_loss: 4.8183 - val_mae: 1.9188\n",
      "\n",
      "Epoch 00078: val_loss improved from 4.99736 to 4.81833, saving model to model.sve\n",
      "Epoch 79/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 4.4950 - mae: 1.8129 - val_loss: 4.7216 - val_mae: 1.8956\n",
      "\n",
      "Epoch 00079: val_loss improved from 4.81833 to 4.72156, saving model to model.sve\n",
      "Epoch 80/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 4.2515 - mae: 1.7522 - val_loss: 4.6112 - val_mae: 1.8694\n",
      "\n",
      "Epoch 00080: val_loss improved from 4.72156 to 4.61118, saving model to model.sve\n",
      "Epoch 81/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 4.1469 - mae: 1.7495 - val_loss: 4.4420 - val_mae: 1.8285\n",
      "\n",
      "Epoch 00081: val_loss improved from 4.61118 to 4.44195, saving model to model.sve\n",
      "Epoch 82/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 3.9441 - mae: 1.6907 - val_loss: 4.2896 - val_mae: 1.7903\n",
      "\n",
      "Epoch 00082: val_loss improved from 4.44195 to 4.28958, saving model to model.sve\n",
      "Epoch 83/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 3.7730 - mae: 1.6647 - val_loss: 4.1375 - val_mae: 1.7509\n",
      "\n",
      "Epoch 00083: val_loss improved from 4.28958 to 4.13752, saving model to model.sve\n",
      "Epoch 84/1000\n",
      "633/633 [==============================] - 0s 196us/step - loss: 3.6713 - mae: 1.6206 - val_loss: 3.9990 - val_mae: 1.7149\n",
      "\n",
      "Epoch 00084: val_loss improved from 4.13752 to 3.99898, saving model to model.sve\n",
      "Epoch 85/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 3.7454 - mae: 1.6359 - val_loss: 3.8530 - val_mae: 1.6760\n",
      "\n",
      "Epoch 00085: val_loss improved from 3.99898 to 3.85300, saving model to model.sve\n",
      "Epoch 86/1000\n",
      "633/633 [==============================] - 0s 206us/step - loss: 3.5513 - mae: 1.5958 - val_loss: 3.7366 - val_mae: 1.6448\n",
      "\n",
      "Epoch 00086: val_loss improved from 3.85300 to 3.73663, saving model to model.sve\n",
      "Epoch 87/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 3.4508 - mae: 1.5662 - val_loss: 3.6372 - val_mae: 1.6171\n",
      "\n",
      "Epoch 00087: val_loss improved from 3.73663 to 3.63722, saving model to model.sve\n",
      "Epoch 88/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 3.3660 - mae: 1.5430 - val_loss: 3.5462 - val_mae: 1.5914\n",
      "\n",
      "Epoch 00088: val_loss improved from 3.63722 to 3.54624, saving model to model.sve\n",
      "Epoch 89/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 3.2519 - mae: 1.5261 - val_loss: 3.3764 - val_mae: 1.5422\n",
      "\n",
      "Epoch 00089: val_loss improved from 3.54624 to 3.37644, saving model to model.sve\n",
      "Epoch 90/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 3.1279 - mae: 1.4844 - val_loss: 3.2740 - val_mae: 1.5130\n",
      "\n",
      "Epoch 00090: val_loss improved from 3.37644 to 3.27398, saving model to model.sve\n",
      "Epoch 91/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 3.1344 - mae: 1.4709 - val_loss: 3.1720 - val_mae: 1.4835\n",
      "\n",
      "Epoch 00091: val_loss improved from 3.27398 to 3.17197, saving model to model.sve\n",
      "Epoch 92/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 2.9989 - mae: 1.4510 - val_loss: 3.0928 - val_mae: 1.4616\n",
      "\n",
      "Epoch 00092: val_loss improved from 3.17197 to 3.09280, saving model to model.sve\n",
      "Epoch 93/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 2.8658 - mae: 1.4232 - val_loss: 2.9830 - val_mae: 1.4303\n",
      "\n",
      "Epoch 00093: val_loss improved from 3.09280 to 2.98298, saving model to model.sve\n",
      "Epoch 94/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 2.8578 - mae: 1.4119 - val_loss: 2.9055 - val_mae: 1.4084\n",
      "\n",
      "Epoch 00094: val_loss improved from 2.98298 to 2.90549, saving model to model.sve\n",
      "Epoch 95/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 2.8663 - mae: 1.4071 - val_loss: 2.8026 - val_mae: 1.3766\n",
      "\n",
      "Epoch 00095: val_loss improved from 2.90549 to 2.80264, saving model to model.sve\n",
      "Epoch 96/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 2.6928 - mae: 1.3663 - val_loss: 2.7269 - val_mae: 1.3556\n",
      "\n",
      "Epoch 00096: val_loss improved from 2.80264 to 2.72687, saving model to model.sve\n",
      "Epoch 97/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 2.5378 - mae: 1.3209 - val_loss: 2.6227 - val_mae: 1.3254\n",
      "\n",
      "Epoch 00097: val_loss improved from 2.72687 to 2.62271, saving model to model.sve\n",
      "Epoch 98/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 2.6514 - mae: 1.3562 - val_loss: 2.5291 - val_mae: 1.2999\n",
      "\n",
      "Epoch 00098: val_loss improved from 2.62271 to 2.52906, saving model to model.sve\n",
      "Epoch 99/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 2.5101 - mae: 1.3040 - val_loss: 2.4604 - val_mae: 1.2794\n",
      "\n",
      "Epoch 00099: val_loss improved from 2.52906 to 2.46045, saving model to model.sve\n",
      "Epoch 100/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 2.4817 - mae: 1.3131 - val_loss: 2.3950 - val_mae: 1.2612\n",
      "\n",
      "Epoch 00100: val_loss improved from 2.46045 to 2.39497, saving model to model.sve\n",
      "Epoch 101/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 2.3894 - mae: 1.2546 - val_loss: 2.3233 - val_mae: 1.2397\n",
      "\n",
      "Epoch 00101: val_loss improved from 2.39497 to 2.32325, saving model to model.sve\n",
      "Epoch 102/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 2.4764 - mae: 1.2999 - val_loss: 2.2875 - val_mae: 1.2309\n",
      "\n",
      "Epoch 00102: val_loss improved from 2.32325 to 2.28749, saving model to model.sve\n",
      "Epoch 103/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 2.3090 - mae: 1.2435 - val_loss: 2.2105 - val_mae: 1.2060\n",
      "\n",
      "Epoch 00103: val_loss improved from 2.28749 to 2.21048, saving model to model.sve\n",
      "Epoch 104/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 2.2692 - mae: 1.2371 - val_loss: 2.1491 - val_mae: 1.1871\n",
      "\n",
      "Epoch 00104: val_loss improved from 2.21048 to 2.14907, saving model to model.sve\n",
      "Epoch 105/1000\n",
      "633/633 [==============================] - 0s 202us/step - loss: 2.1519 - mae: 1.2084 - val_loss: 2.0875 - val_mae: 1.1689\n",
      "\n",
      "Epoch 00105: val_loss improved from 2.14907 to 2.08751, saving model to model.sve\n",
      "Epoch 106/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 2.2857 - mae: 1.2383 - val_loss: 2.0691 - val_mae: 1.1624\n",
      "\n",
      "Epoch 00106: val_loss improved from 2.08751 to 2.06909, saving model to model.sve\n",
      "Epoch 107/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 2.2368 - mae: 1.2012 - val_loss: 2.0206 - val_mae: 1.1470\n",
      "\n",
      "Epoch 00107: val_loss improved from 2.06909 to 2.02061, saving model to model.sve\n",
      "Epoch 108/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 2.0864 - mae: 1.1830 - val_loss: 1.9823 - val_mae: 1.1343\n",
      "\n",
      "Epoch 00108: val_loss improved from 2.02061 to 1.98232, saving model to model.sve\n",
      "Epoch 109/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 2.0581 - mae: 1.1656 - val_loss: 1.9403 - val_mae: 1.1235\n",
      "\n",
      "Epoch 00109: val_loss improved from 1.98232 to 1.94028, saving model to model.sve\n",
      "Epoch 110/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 2.0566 - mae: 1.1569 - val_loss: 1.8813 - val_mae: 1.1056\n",
      "\n",
      "Epoch 00110: val_loss improved from 1.94028 to 1.88130, saving model to model.sve\n",
      "Epoch 111/1000\n",
      "633/633 [==============================] - 0s 206us/step - loss: 2.0697 - mae: 1.1690 - val_loss: 1.8421 - val_mae: 1.0954\n",
      "\n",
      "Epoch 00111: val_loss improved from 1.88130 to 1.84208, saving model to model.sve\n",
      "Epoch 112/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 2.0831 - mae: 1.1735 - val_loss: 1.8388 - val_mae: 1.0943\n",
      "\n",
      "Epoch 00112: val_loss improved from 1.84208 to 1.83885, saving model to model.sve\n",
      "Epoch 113/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 2.1250 - mae: 1.1863 - val_loss: 1.8075 - val_mae: 1.0865\n",
      "\n",
      "Epoch 00113: val_loss improved from 1.83885 to 1.80752, saving model to model.sve\n",
      "Epoch 114/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 2.0566 - mae: 1.1417 - val_loss: 1.7823 - val_mae: 1.0798\n",
      "\n",
      "Epoch 00114: val_loss improved from 1.80752 to 1.78232, saving model to model.sve\n",
      "Epoch 115/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.9821 - mae: 1.1306 - val_loss: 1.7626 - val_mae: 1.0756\n",
      "\n",
      "Epoch 00115: val_loss improved from 1.78232 to 1.76257, saving model to model.sve\n",
      "Epoch 116/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 2.0686 - mae: 1.1608 - val_loss: 1.7430 - val_mae: 1.0711\n",
      "\n",
      "Epoch 00116: val_loss improved from 1.76257 to 1.74302, saving model to model.sve\n",
      "Epoch 117/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.9955 - mae: 1.1630 - val_loss: 1.7355 - val_mae: 1.0692\n",
      "\n",
      "Epoch 00117: val_loss improved from 1.74302 to 1.73546, saving model to model.sve\n",
      "Epoch 118/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.8897 - mae: 1.1049 - val_loss: 1.7180 - val_mae: 1.0655\n",
      "\n",
      "Epoch 00118: val_loss improved from 1.73546 to 1.71799, saving model to model.sve\n",
      "Epoch 119/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.9965 - mae: 1.1399 - val_loss: 1.6932 - val_mae: 1.0592\n",
      "\n",
      "Epoch 00119: val_loss improved from 1.71799 to 1.69318, saving model to model.sve\n",
      "Epoch 120/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.9212 - mae: 1.1274 - val_loss: 1.6695 - val_mae: 1.0534\n",
      "\n",
      "Epoch 00120: val_loss improved from 1.69318 to 1.66951, saving model to model.sve\n",
      "Epoch 121/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.9858 - mae: 1.1175 - val_loss: 1.6705 - val_mae: 1.0540\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.66951\n",
      "Epoch 122/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.9015 - mae: 1.1084 - val_loss: 1.6571 - val_mae: 1.0503\n",
      "\n",
      "Epoch 00122: val_loss improved from 1.66951 to 1.65709, saving model to model.sve\n",
      "Epoch 123/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 2.1133 - mae: 1.1507 - val_loss: 1.6498 - val_mae: 1.0487\n",
      "\n",
      "Epoch 00123: val_loss improved from 1.65709 to 1.64982, saving model to model.sve\n",
      "Epoch 124/1000\n",
      "633/633 [==============================] - 0s 210us/step - loss: 2.0356 - mae: 1.1413 - val_loss: 1.6431 - val_mae: 1.0469\n",
      "\n",
      "Epoch 00124: val_loss improved from 1.64982 to 1.64315, saving model to model.sve\n",
      "Epoch 125/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.9770 - mae: 1.1249 - val_loss: 1.6248 - val_mae: 1.0412\n",
      "\n",
      "Epoch 00125: val_loss improved from 1.64315 to 1.62480, saving model to model.sve\n",
      "Epoch 126/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.9891 - mae: 1.1263 - val_loss: 1.6147 - val_mae: 1.0375\n",
      "\n",
      "Epoch 00126: val_loss improved from 1.62480 to 1.61474, saving model to model.sve\n",
      "Epoch 127/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.9107 - mae: 1.1086 - val_loss: 1.6006 - val_mae: 1.0329\n",
      "\n",
      "Epoch 00127: val_loss improved from 1.61474 to 1.60063, saving model to model.sve\n",
      "Epoch 128/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.9531 - mae: 1.1159 - val_loss: 1.6015 - val_mae: 1.0334\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.60063\n",
      "Epoch 129/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.8453 - mae: 1.0899 - val_loss: 1.5986 - val_mae: 1.0327\n",
      "\n",
      "Epoch 00129: val_loss improved from 1.60063 to 1.59857, saving model to model.sve\n",
      "Epoch 130/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.8202 - mae: 1.0786 - val_loss: 1.5925 - val_mae: 1.0309\n",
      "\n",
      "Epoch 00130: val_loss improved from 1.59857 to 1.59253, saving model to model.sve\n",
      "Epoch 131/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.8576 - mae: 1.0847 - val_loss: 1.5825 - val_mae: 1.0280\n",
      "\n",
      "Epoch 00131: val_loss improved from 1.59253 to 1.58253, saving model to model.sve\n",
      "Epoch 132/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.9480 - mae: 1.1019 - val_loss: 1.5816 - val_mae: 1.0290\n",
      "\n",
      "Epoch 00132: val_loss improved from 1.58253 to 1.58165, saving model to model.sve\n",
      "Epoch 133/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.8927 - mae: 1.0939 - val_loss: 1.5790 - val_mae: 1.0284\n",
      "\n",
      "Epoch 00133: val_loss improved from 1.58165 to 1.57905, saving model to model.sve\n",
      "Epoch 134/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.9797 - mae: 1.1207 - val_loss: 1.5708 - val_mae: 1.0262\n",
      "\n",
      "Epoch 00134: val_loss improved from 1.57905 to 1.57080, saving model to model.sve\n",
      "Epoch 135/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.8893 - mae: 1.1117 - val_loss: 1.5698 - val_mae: 1.0255\n",
      "\n",
      "Epoch 00135: val_loss improved from 1.57080 to 1.56983, saving model to model.sve\n",
      "Epoch 136/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.8541 - mae: 1.0788 - val_loss: 1.5671 - val_mae: 1.0248\n",
      "\n",
      "Epoch 00136: val_loss improved from 1.56983 to 1.56711, saving model to model.sve\n",
      "Epoch 137/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.9130 - mae: 1.0877 - val_loss: 1.5680 - val_mae: 1.0253\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.56711\n",
      "Epoch 138/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.8651 - mae: 1.0971 - val_loss: 1.5634 - val_mae: 1.0257\n",
      "\n",
      "Epoch 00138: val_loss improved from 1.56711 to 1.56338, saving model to model.sve\n",
      "Epoch 139/1000\n",
      "633/633 [==============================] - 0s 168us/step - loss: 1.9939 - mae: 1.1190 - val_loss: 1.5599 - val_mae: 1.0242\n",
      "\n",
      "Epoch 00139: val_loss improved from 1.56338 to 1.55989, saving model to model.sve\n",
      "Epoch 140/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.8942 - mae: 1.0911 - val_loss: 1.5635 - val_mae: 1.0250\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.55989\n",
      "Epoch 141/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.8947 - mae: 1.0972 - val_loss: 1.5629 - val_mae: 1.0247\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.55989\n",
      "Epoch 142/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.9092 - mae: 1.0904 - val_loss: 1.5682 - val_mae: 1.0260\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.55989\n",
      "Epoch 143/1000\n",
      "633/633 [==============================] - 0s 169us/step - loss: 1.9126 - mae: 1.1286 - val_loss: 1.5669 - val_mae: 1.0264\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.55989\n",
      "Epoch 144/1000\n",
      "633/633 [==============================] - 0s 168us/step - loss: 1.8681 - mae: 1.0901 - val_loss: 1.5685 - val_mae: 1.0269\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.55989\n",
      "Epoch 145/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.8893 - mae: 1.0944 - val_loss: 1.5720 - val_mae: 1.0288\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.55989\n",
      "Epoch 146/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.8482 - mae: 1.0731 - val_loss: 1.5778 - val_mae: 1.0307\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.55989\n",
      "Epoch 147/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.8795 - mae: 1.1079 - val_loss: 1.5714 - val_mae: 1.0284\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.55989\n",
      "Epoch 148/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.9447 - mae: 1.0971 - val_loss: 1.5690 - val_mae: 1.0273\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.55989\n",
      "Epoch 149/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.8729 - mae: 1.0888 - val_loss: 1.5718 - val_mae: 1.0278\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.55989\n",
      "Epoch 150/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.8786 - mae: 1.0854 - val_loss: 1.5679 - val_mae: 1.0274\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.55989\n",
      "Epoch 151/1000\n",
      "633/633 [==============================] - 0s 197us/step - loss: 1.9323 - mae: 1.0868 - val_loss: 1.5638 - val_mae: 1.0264\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.55989\n",
      "Epoch 152/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.8330 - mae: 1.0789 - val_loss: 1.5606 - val_mae: 1.0253\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.55989\n",
      "Epoch 153/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.8487 - mae: 1.0948 - val_loss: 1.5616 - val_mae: 1.0259\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.55989\n",
      "Epoch 154/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.8907 - mae: 1.0916 - val_loss: 1.5633 - val_mae: 1.0251\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.55989\n",
      "Epoch 155/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.8622 - mae: 1.0871 - val_loss: 1.5606 - val_mae: 1.0230\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.55989\n",
      "Epoch 156/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.8649 - mae: 1.0921 - val_loss: 1.5605 - val_mae: 1.0232\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.55989\n",
      "Epoch 157/1000\n",
      "633/633 [==============================] - 0s 169us/step - loss: 1.8377 - mae: 1.0730 - val_loss: 1.5616 - val_mae: 1.0232\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.55989\n",
      "Epoch 158/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.7783 - mae: 1.0587 - val_loss: 1.5582 - val_mae: 1.0219\n",
      "\n",
      "Epoch 00158: val_loss improved from 1.55989 to 1.55820, saving model to model.sve\n",
      "Epoch 159/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.8986 - mae: 1.0889 - val_loss: 1.5628 - val_mae: 1.0237\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.55820\n",
      "Epoch 160/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.8429 - mae: 1.0786 - val_loss: 1.5603 - val_mae: 1.0226\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.55820\n",
      "Epoch 161/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.8960 - mae: 1.0813 - val_loss: 1.5588 - val_mae: 1.0225\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.55820\n",
      "Epoch 162/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.8926 - mae: 1.0919 - val_loss: 1.5544 - val_mae: 1.0220\n",
      "\n",
      "Epoch 00162: val_loss improved from 1.55820 to 1.55440, saving model to model.sve\n",
      "Epoch 163/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.8901 - mae: 1.0969 - val_loss: 1.5507 - val_mae: 1.0208\n",
      "\n",
      "Epoch 00163: val_loss improved from 1.55440 to 1.55073, saving model to model.sve\n",
      "Epoch 164/1000\n",
      "633/633 [==============================] - 0s 227us/step - loss: 1.9710 - mae: 1.1150 - val_loss: 1.5512 - val_mae: 1.0210\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.55073\n",
      "Epoch 165/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.7843 - mae: 1.0613 - val_loss: 1.5537 - val_mae: 1.0224\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.55073\n",
      "Epoch 166/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.8535 - mae: 1.0818 - val_loss: 1.5585 - val_mae: 1.0230\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.55073\n",
      "Epoch 167/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.8143 - mae: 1.0628 - val_loss: 1.5591 - val_mae: 1.0238\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.55073\n",
      "Epoch 168/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.9314 - mae: 1.0979 - val_loss: 1.5584 - val_mae: 1.0246\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.55073\n",
      "Epoch 169/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.9157 - mae: 1.0973 - val_loss: 1.5579 - val_mae: 1.0254\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.55073\n",
      "Epoch 170/1000\n",
      "633/633 [==============================] - 0s 195us/step - loss: 1.8874 - mae: 1.1026 - val_loss: 1.5530 - val_mae: 1.0238\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.55073\n",
      "Epoch 171/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.8427 - mae: 1.0824 - val_loss: 1.5515 - val_mae: 1.0223\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1.55073\n",
      "Epoch 172/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.8620 - mae: 1.1003 - val_loss: 1.5538 - val_mae: 1.0234\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1.55073\n",
      "Epoch 173/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.7835 - mae: 1.0555 - val_loss: 1.5511 - val_mae: 1.0230\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.55073\n",
      "Epoch 174/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.7280 - mae: 1.0260 - val_loss: 1.5477 - val_mae: 1.0214\n",
      "\n",
      "Epoch 00174: val_loss improved from 1.55073 to 1.54775, saving model to model.sve\n",
      "Epoch 175/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.9306 - mae: 1.1141 - val_loss: 1.5474 - val_mae: 1.0224\n",
      "\n",
      "Epoch 00175: val_loss improved from 1.54775 to 1.54744, saving model to model.sve\n",
      "Epoch 176/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.7938 - mae: 1.0686 - val_loss: 1.5529 - val_mae: 1.0239\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.54744\n",
      "Epoch 177/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.7641 - mae: 1.0540 - val_loss: 1.5548 - val_mae: 1.0236\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.54744\n",
      "Epoch 178/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.8373 - mae: 1.0931 - val_loss: 1.5585 - val_mae: 1.0245\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.54744\n",
      "Epoch 179/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.7686 - mae: 1.0581 - val_loss: 1.5581 - val_mae: 1.0239\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.54744\n",
      "Epoch 180/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.8003 - mae: 1.0809 - val_loss: 1.5548 - val_mae: 1.0224\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.54744\n",
      "Epoch 181/1000\n",
      "633/633 [==============================] - 0s 205us/step - loss: 1.8325 - mae: 1.0732 - val_loss: 1.5517 - val_mae: 1.0220\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.54744\n",
      "Epoch 182/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.9703 - mae: 1.1029 - val_loss: 1.5501 - val_mae: 1.0223\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.54744\n",
      "Epoch 183/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.7815 - mae: 1.0662 - val_loss: 1.5519 - val_mae: 1.0229\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.54744\n",
      "Epoch 184/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.8564 - mae: 1.0890 - val_loss: 1.5506 - val_mae: 1.0230\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.54744\n",
      "Epoch 185/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.8576 - mae: 1.0912 - val_loss: 1.5475 - val_mae: 1.0212\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.54744\n",
      "Epoch 186/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.8229 - mae: 1.0640 - val_loss: 1.5516 - val_mae: 1.0224\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1.54744\n",
      "Epoch 187/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.7298 - mae: 1.0462 - val_loss: 1.5524 - val_mae: 1.0225\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1.54744\n",
      "Epoch 188/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.7298 - mae: 1.0448 - val_loss: 1.5594 - val_mae: 1.0249\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.54744\n",
      "Epoch 189/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.8502 - mae: 1.0894 - val_loss: 1.5603 - val_mae: 1.0251\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1.54744\n",
      "Epoch 190/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.8633 - mae: 1.0662 - val_loss: 1.5590 - val_mae: 1.0246\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1.54744\n",
      "Epoch 191/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.8346 - mae: 1.0845 - val_loss: 1.5572 - val_mae: 1.0232\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1.54744\n",
      "Epoch 192/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.7692 - mae: 1.0527 - val_loss: 1.5561 - val_mae: 1.0230\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1.54744\n",
      "Epoch 193/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.7771 - mae: 1.0409 - val_loss: 1.5583 - val_mae: 1.0230\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1.54744\n",
      "Epoch 194/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.8659 - mae: 1.0845 - val_loss: 1.5574 - val_mae: 1.0231\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1.54744\n",
      "Epoch 195/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.7321 - mae: 1.0589 - val_loss: 1.5602 - val_mae: 1.0236\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1.54744\n",
      "Epoch 196/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.8761 - mae: 1.0898 - val_loss: 1.5561 - val_mae: 1.0212\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1.54744\n",
      "Epoch 197/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.8919 - mae: 1.0937 - val_loss: 1.5590 - val_mae: 1.0221\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1.54744\n",
      "Epoch 198/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.7491 - mae: 1.0522 - val_loss: 1.5623 - val_mae: 1.0230\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1.54744\n",
      "Epoch 199/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.8641 - mae: 1.0834 - val_loss: 1.5668 - val_mae: 1.0239\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1.54744\n",
      "Epoch 200/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.7872 - mae: 1.0597 - val_loss: 1.5662 - val_mae: 1.0241\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1.54744\n",
      "Epoch 201/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.7549 - mae: 1.0520 - val_loss: 1.5692 - val_mae: 1.0233\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 1.54744\n",
      "Epoch 202/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.8714 - mae: 1.0836 - val_loss: 1.5702 - val_mae: 1.0222\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 1.54744\n",
      "Epoch 203/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.8407 - mae: 1.0555 - val_loss: 1.5681 - val_mae: 1.0220\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 1.54744\n",
      "Epoch 204/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6921 - mae: 1.0362 - val_loss: 1.5650 - val_mae: 1.0206\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 1.54744\n",
      "Epoch 205/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.8616 - mae: 1.0734 - val_loss: 1.5648 - val_mae: 1.0209\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 1.54744\n",
      "Epoch 206/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.8180 - mae: 1.0682 - val_loss: 1.5634 - val_mae: 1.0208\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 1.54744\n",
      "Epoch 207/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.8065 - mae: 1.0620 - val_loss: 1.5642 - val_mae: 1.0212\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 1.54744\n",
      "Epoch 208/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.7658 - mae: 1.0551 - val_loss: 1.5611 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 1.54744\n",
      "Epoch 209/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.8678 - mae: 1.0896 - val_loss: 1.5537 - val_mae: 1.0189\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 1.54744\n",
      "Epoch 210/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.8499 - mae: 1.0667 - val_loss: 1.5594 - val_mae: 1.0213\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 1.54744\n",
      "Epoch 211/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.7944 - mae: 1.0640 - val_loss: 1.5556 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 1.54744\n",
      "Epoch 212/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.8490 - mae: 1.0966 - val_loss: 1.5604 - val_mae: 1.0223\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 1.54744\n",
      "Epoch 213/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.8319 - mae: 1.0820 - val_loss: 1.5532 - val_mae: 1.0200\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 1.54744\n",
      "Epoch 214/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.8651 - mae: 1.0813 - val_loss: 1.5557 - val_mae: 1.0204\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 1.54744\n",
      "Epoch 215/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6511 - mae: 1.0138 - val_loss: 1.5516 - val_mae: 1.0192\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 1.54744\n",
      "Epoch 216/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.8534 - mae: 1.0816 - val_loss: 1.5465 - val_mae: 1.0177\n",
      "\n",
      "Epoch 00216: val_loss improved from 1.54744 to 1.54648, saving model to model.sve\n",
      "Epoch 217/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.7508 - mae: 1.0421 - val_loss: 1.5447 - val_mae: 1.0181\n",
      "\n",
      "Epoch 00217: val_loss improved from 1.54648 to 1.54466, saving model to model.sve\n",
      "Epoch 218/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.7717 - mae: 1.0623 - val_loss: 1.5437 - val_mae: 1.0184\n",
      "\n",
      "Epoch 00218: val_loss improved from 1.54466 to 1.54366, saving model to model.sve\n",
      "Epoch 219/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.7641 - mae: 1.0447 - val_loss: 1.5454 - val_mae: 1.0177\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 1.54366\n",
      "Epoch 220/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.8896 - mae: 1.0874 - val_loss: 1.5456 - val_mae: 1.0174\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 1.54366\n",
      "Epoch 221/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.8131 - mae: 1.0732 - val_loss: 1.5450 - val_mae: 1.0172\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 1.54366\n",
      "Epoch 222/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.7973 - mae: 1.0557 - val_loss: 1.5445 - val_mae: 1.0169\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 1.54366\n",
      "Epoch 223/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.7542 - mae: 1.0287 - val_loss: 1.5403 - val_mae: 1.0158\n",
      "\n",
      "Epoch 00223: val_loss improved from 1.54366 to 1.54030, saving model to model.sve\n",
      "Epoch 224/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.7908 - mae: 1.0642 - val_loss: 1.5380 - val_mae: 1.0156\n",
      "\n",
      "Epoch 00224: val_loss improved from 1.54030 to 1.53798, saving model to model.sve\n",
      "Epoch 225/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.7987 - mae: 1.0589 - val_loss: 1.5380 - val_mae: 1.0157\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 1.53798\n",
      "Epoch 226/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.8831 - mae: 1.1034 - val_loss: 1.5391 - val_mae: 1.0169\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 1.53798\n",
      "Epoch 227/1000\n",
      "633/633 [==============================] - 0s 199us/step - loss: 1.8402 - mae: 1.0623 - val_loss: 1.5323 - val_mae: 1.0159\n",
      "\n",
      "Epoch 00227: val_loss improved from 1.53798 to 1.53233, saving model to model.sve\n",
      "Epoch 228/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.7937 - mae: 1.0719 - val_loss: 1.5311 - val_mae: 1.0154\n",
      "\n",
      "Epoch 00228: val_loss improved from 1.53233 to 1.53113, saving model to model.sve\n",
      "Epoch 229/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.7600 - mae: 1.0486 - val_loss: 1.5287 - val_mae: 1.0150\n",
      "\n",
      "Epoch 00229: val_loss improved from 1.53113 to 1.52868, saving model to model.sve\n",
      "Epoch 230/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.7225 - mae: 1.0451 - val_loss: 1.5297 - val_mae: 1.0154\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 1.52868\n",
      "Epoch 231/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.7640 - mae: 1.0653 - val_loss: 1.5291 - val_mae: 1.0148\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 1.52868\n",
      "Epoch 232/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.7799 - mae: 1.0649 - val_loss: 1.5324 - val_mae: 1.0159\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 1.52868\n",
      "Epoch 233/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.8192 - mae: 1.0658 - val_loss: 1.5319 - val_mae: 1.0157\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 1.52868\n",
      "Epoch 234/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.7598 - mae: 1.0507 - val_loss: 1.5344 - val_mae: 1.0158\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 1.52868\n",
      "Epoch 235/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.7531 - mae: 1.0492 - val_loss: 1.5400 - val_mae: 1.0175\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 1.52868\n",
      "Epoch 236/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.7370 - mae: 1.0441 - val_loss: 1.5418 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 1.52868\n",
      "Epoch 237/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.7514 - mae: 1.0509 - val_loss: 1.5426 - val_mae: 1.0204\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 1.52868\n",
      "Epoch 238/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.7707 - mae: 1.0636 - val_loss: 1.5404 - val_mae: 1.0208\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 1.52868\n",
      "Epoch 239/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.7623 - mae: 1.0512 - val_loss: 1.5410 - val_mae: 1.0203\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 1.52868\n",
      "Epoch 240/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.7393 - mae: 1.0423 - val_loss: 1.5394 - val_mae: 1.0210\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 1.52868\n",
      "Epoch 241/1000\n",
      "633/633 [==============================] - 0s 201us/step - loss: 1.7611 - mae: 1.0575 - val_loss: 1.5482 - val_mae: 1.0228\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 1.52868\n",
      "Epoch 242/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.7092 - mae: 1.0467 - val_loss: 1.5410 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 1.52868\n",
      "Epoch 243/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.7614 - mae: 1.0481 - val_loss: 1.5390 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 1.52868\n",
      "Epoch 244/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.7830 - mae: 1.0598 - val_loss: 1.5385 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 1.52868\n",
      "Epoch 245/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.8125 - mae: 1.0715 - val_loss: 1.5427 - val_mae: 1.0206\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 1.52868\n",
      "Epoch 246/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.8261 - mae: 1.0579 - val_loss: 1.5464 - val_mae: 1.0215\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 1.52868\n",
      "Epoch 247/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.8045 - mae: 1.0642 - val_loss: 1.5438 - val_mae: 1.0210\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 1.52868\n",
      "Epoch 248/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.6276 - mae: 1.0048 - val_loss: 1.5446 - val_mae: 1.0222\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 1.52868\n",
      "Epoch 249/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.7519 - mae: 1.0311 - val_loss: 1.5445 - val_mae: 1.0230\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 1.52868\n",
      "Epoch 250/1000\n",
      "633/633 [==============================] - 0s 195us/step - loss: 1.6710 - mae: 1.0153 - val_loss: 1.5481 - val_mae: 1.0243\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 1.52868\n",
      "Epoch 251/1000\n",
      "633/633 [==============================] - 0s 199us/step - loss: 1.7040 - mae: 1.0276 - val_loss: 1.5517 - val_mae: 1.0244\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 1.52868\n",
      "Epoch 252/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.7841 - mae: 1.0585 - val_loss: 1.5488 - val_mae: 1.0225\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 1.52868\n",
      "Epoch 253/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.7445 - mae: 1.0396 - val_loss: 1.5475 - val_mae: 1.0225\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 1.52868\n",
      "Epoch 254/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.7556 - mae: 1.0575 - val_loss: 1.5481 - val_mae: 1.0223\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 1.52868\n",
      "Epoch 255/1000\n",
      "633/633 [==============================] - 0s 217us/step - loss: 1.5891 - mae: 1.0033 - val_loss: 1.5494 - val_mae: 1.0239\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 1.52868\n",
      "Epoch 256/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.7937 - mae: 1.0545 - val_loss: 1.5496 - val_mae: 1.0247\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 1.52868\n",
      "Epoch 257/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.8378 - mae: 1.0790 - val_loss: 1.5459 - val_mae: 1.0236\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 1.52868\n",
      "Epoch 258/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.7538 - mae: 1.0556 - val_loss: 1.5399 - val_mae: 1.0218\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 1.52868\n",
      "Epoch 259/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.7240 - mae: 1.0453 - val_loss: 1.5418 - val_mae: 1.0229\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 1.52868\n",
      "Epoch 260/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.7779 - mae: 1.0631 - val_loss: 1.5399 - val_mae: 1.0219\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 1.52868\n",
      "Epoch 261/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6731 - mae: 1.0095 - val_loss: 1.5445 - val_mae: 1.0232\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 1.52868\n",
      "Epoch 262/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.7553 - mae: 1.0655 - val_loss: 1.5396 - val_mae: 1.0208\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1.52868\n",
      "Epoch 263/1000\n",
      "633/633 [==============================] - 0s 193us/step - loss: 1.6779 - mae: 1.0328 - val_loss: 1.5401 - val_mae: 1.0204\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 1.52868\n",
      "Epoch 264/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.6988 - mae: 1.0268 - val_loss: 1.5364 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 1.52868\n",
      "Epoch 265/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.7787 - mae: 1.0547 - val_loss: 1.5354 - val_mae: 1.0185\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 1.52868\n",
      "Epoch 266/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.7114 - mae: 1.0471 - val_loss: 1.5349 - val_mae: 1.0186\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 1.52868\n",
      "Epoch 267/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6846 - mae: 1.0306 - val_loss: 1.5356 - val_mae: 1.0192\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 1.52868\n",
      "Epoch 268/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.7452 - mae: 1.0488 - val_loss: 1.5419 - val_mae: 1.0210\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 1.52868\n",
      "Epoch 269/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.7636 - mae: 1.0549 - val_loss: 1.5429 - val_mae: 1.0218\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 1.52868\n",
      "Epoch 270/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.7557 - mae: 1.0380 - val_loss: 1.5421 - val_mae: 1.0210\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 1.52868\n",
      "Epoch 271/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.7605 - mae: 1.0611 - val_loss: 1.5414 - val_mae: 1.0203\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 1.52868\n",
      "Epoch 272/1000\n",
      "633/633 [==============================] - 0s 196us/step - loss: 1.7963 - mae: 1.0647 - val_loss: 1.5400 - val_mae: 1.0198\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 1.52868\n",
      "Epoch 273/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.7516 - mae: 1.0441 - val_loss: 1.5382 - val_mae: 1.0196\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 1.52868\n",
      "Epoch 274/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.8317 - mae: 1.0813 - val_loss: 1.5401 - val_mae: 1.0208\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 1.52868\n",
      "Epoch 275/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.6917 - mae: 1.0262 - val_loss: 1.5400 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 1.52868\n",
      "Epoch 276/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.7625 - mae: 1.0530 - val_loss: 1.5360 - val_mae: 1.0189\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 1.52868\n",
      "Epoch 277/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.7178 - mae: 1.0260 - val_loss: 1.5342 - val_mae: 1.0180\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 1.52868\n",
      "Epoch 278/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.7199 - mae: 1.0403 - val_loss: 1.5270 - val_mae: 1.0160\n",
      "\n",
      "Epoch 00278: val_loss improved from 1.52868 to 1.52700, saving model to model.sve\n",
      "Epoch 279/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.6820 - mae: 1.0381 - val_loss: 1.5303 - val_mae: 1.0173\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 1.52700\n",
      "Epoch 280/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.6831 - mae: 1.0266 - val_loss: 1.5345 - val_mae: 1.0183\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 1.52700\n",
      "Epoch 281/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.6454 - mae: 1.0091 - val_loss: 1.5391 - val_mae: 1.0192\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 1.52700\n",
      "Epoch 282/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.7455 - mae: 1.0437 - val_loss: 1.5432 - val_mae: 1.0198\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 1.52700\n",
      "Epoch 283/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.7666 - mae: 1.0584 - val_loss: 1.5451 - val_mae: 1.0200\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 1.52700\n",
      "Epoch 284/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.7851 - mae: 1.0442 - val_loss: 1.5453 - val_mae: 1.0213\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 1.52700\n",
      "Epoch 285/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.7726 - mae: 1.0419 - val_loss: 1.5452 - val_mae: 1.0200\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 1.52700\n",
      "Epoch 286/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.6251 - mae: 1.0073 - val_loss: 1.5426 - val_mae: 1.0200\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 1.52700\n",
      "Epoch 287/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.7310 - mae: 1.0485 - val_loss: 1.5391 - val_mae: 1.0189\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 1.52700\n",
      "Epoch 288/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.7413 - mae: 1.0356 - val_loss: 1.5361 - val_mae: 1.0182\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 1.52700\n",
      "Epoch 289/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.6180 - mae: 0.9994 - val_loss: 1.5345 - val_mae: 1.0176\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 1.52700\n",
      "Epoch 290/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.7563 - mae: 1.0411 - val_loss: 1.5293 - val_mae: 1.0160\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 1.52700\n",
      "Epoch 291/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6903 - mae: 1.0268 - val_loss: 1.5283 - val_mae: 1.0167\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 1.52700\n",
      "Epoch 292/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.7594 - mae: 1.0573 - val_loss: 1.5239 - val_mae: 1.0151\n",
      "\n",
      "Epoch 00292: val_loss improved from 1.52700 to 1.52393, saving model to model.sve\n",
      "Epoch 293/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.7468 - mae: 1.0484 - val_loss: 1.5224 - val_mae: 1.0139\n",
      "\n",
      "Epoch 00293: val_loss improved from 1.52393 to 1.52238, saving model to model.sve\n",
      "Epoch 294/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.7187 - mae: 1.0488 - val_loss: 1.5250 - val_mae: 1.0153\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 1.52238\n",
      "Epoch 295/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.6730 - mae: 1.0399 - val_loss: 1.5271 - val_mae: 1.0163\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 1.52238\n",
      "Epoch 296/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.6757 - mae: 1.0261 - val_loss: 1.5261 - val_mae: 1.0163\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 1.52238\n",
      "Epoch 297/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.6741 - mae: 1.0266 - val_loss: 1.5317 - val_mae: 1.0176\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 1.52238\n",
      "Epoch 298/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.6707 - mae: 1.0241 - val_loss: 1.5332 - val_mae: 1.0172\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 1.52238\n",
      "Epoch 299/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6587 - mae: 1.0112 - val_loss: 1.5396 - val_mae: 1.0193\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 1.52238\n",
      "Epoch 300/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.6572 - mae: 1.0162 - val_loss: 1.5362 - val_mae: 1.0180\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 1.52238\n",
      "Epoch 301/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.6868 - mae: 1.0193 - val_loss: 1.5380 - val_mae: 1.0189\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 1.52238\n",
      "Epoch 302/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.7081 - mae: 1.0490 - val_loss: 1.5391 - val_mae: 1.0190\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 1.52238\n",
      "Epoch 303/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.7312 - mae: 1.0424 - val_loss: 1.5367 - val_mae: 1.0191\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 1.52238\n",
      "Epoch 304/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.6853 - mae: 1.0305 - val_loss: 1.5412 - val_mae: 1.0198\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 1.52238\n",
      "Epoch 305/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.6816 - mae: 1.0185 - val_loss: 1.5379 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 1.52238\n",
      "Epoch 306/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.7347 - mae: 1.0350 - val_loss: 1.5391 - val_mae: 1.0199\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 1.52238\n",
      "Epoch 307/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.7425 - mae: 1.0493 - val_loss: 1.5381 - val_mae: 1.0205\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 1.52238\n",
      "Epoch 308/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.6570 - mae: 1.0406 - val_loss: 1.5403 - val_mae: 1.0212\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 1.52238\n",
      "Epoch 309/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.7043 - mae: 1.0225 - val_loss: 1.5388 - val_mae: 1.0220\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 1.52238\n",
      "Epoch 310/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6150 - mae: 1.0043 - val_loss: 1.5419 - val_mae: 1.0217\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 1.52238\n",
      "Epoch 311/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.6477 - mae: 1.0059 - val_loss: 1.5396 - val_mae: 1.0217\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 1.52238\n",
      "Epoch 312/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.7646 - mae: 1.0631 - val_loss: 1.5354 - val_mae: 1.0202\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 1.52238\n",
      "Epoch 313/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.7301 - mae: 1.0210 - val_loss: 1.5357 - val_mae: 1.0207\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 1.52238\n",
      "Epoch 314/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.6745 - mae: 1.0244 - val_loss: 1.5420 - val_mae: 1.0225\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 1.52238\n",
      "Epoch 315/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.6671 - mae: 1.0298 - val_loss: 1.5429 - val_mae: 1.0217\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 1.52238\n",
      "Epoch 316/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.6707 - mae: 1.0315 - val_loss: 1.5432 - val_mae: 1.0220\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 1.52238\n",
      "Epoch 317/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.6817 - mae: 1.0271 - val_loss: 1.5476 - val_mae: 1.0230\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 1.52238\n",
      "Epoch 318/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.6376 - mae: 1.0164 - val_loss: 1.5445 - val_mae: 1.0210\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 1.52238\n",
      "Epoch 319/1000\n",
      "633/633 [==============================] - 0s 200us/step - loss: 1.7113 - mae: 1.0308 - val_loss: 1.5428 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 1.52238\n",
      "Epoch 320/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.6645 - mae: 1.0281 - val_loss: 1.5432 - val_mae: 1.0218\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 1.52238\n",
      "Epoch 321/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6823 - mae: 1.0339 - val_loss: 1.5442 - val_mae: 1.0217\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 1.52238\n",
      "Epoch 322/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.7102 - mae: 1.0332 - val_loss: 1.5424 - val_mae: 1.0216\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 1.52238\n",
      "Epoch 323/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.7157 - mae: 1.0410 - val_loss: 1.5365 - val_mae: 1.0190\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 1.52238\n",
      "Epoch 324/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.7050 - mae: 1.0490 - val_loss: 1.5326 - val_mae: 1.0186\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 1.52238\n",
      "Epoch 325/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.7466 - mae: 1.0463 - val_loss: 1.5280 - val_mae: 1.0179\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 1.52238\n",
      "Epoch 326/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6530 - mae: 1.0160 - val_loss: 1.5300 - val_mae: 1.0182\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 1.52238\n",
      "Epoch 327/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.7326 - mae: 1.0629 - val_loss: 1.5266 - val_mae: 1.0161\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 1.52238\n",
      "Epoch 328/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.6666 - mae: 1.0207 - val_loss: 1.5241 - val_mae: 1.0166\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 1.52238\n",
      "Epoch 329/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.6486 - mae: 1.0031 - val_loss: 1.5259 - val_mae: 1.0176\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 1.52238\n",
      "Epoch 330/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.7505 - mae: 1.0412 - val_loss: 1.5243 - val_mae: 1.0171\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 1.52238\n",
      "Epoch 331/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.6496 - mae: 1.0250 - val_loss: 1.5264 - val_mae: 1.0169\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 1.52238\n",
      "Epoch 332/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5665 - mae: 0.9794 - val_loss: 1.5234 - val_mae: 1.0161\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 1.52238\n",
      "Epoch 333/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.6964 - mae: 1.0244 - val_loss: 1.5275 - val_mae: 1.0175\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 1.52238\n",
      "Epoch 334/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6321 - mae: 1.0119 - val_loss: 1.5310 - val_mae: 1.0179\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 1.52238\n",
      "Epoch 335/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.6846 - mae: 1.0253 - val_loss: 1.5342 - val_mae: 1.0192\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 1.52238\n",
      "Epoch 336/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.6581 - mae: 1.0291 - val_loss: 1.5340 - val_mae: 1.0195\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 1.52238\n",
      "Epoch 337/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.6006 - mae: 0.9967 - val_loss: 1.5287 - val_mae: 1.0176\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 1.52238\n",
      "Epoch 338/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.6888 - mae: 1.0447 - val_loss: 1.5271 - val_mae: 1.0164\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 1.52238\n",
      "Epoch 339/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.6672 - mae: 1.0035 - val_loss: 1.5318 - val_mae: 1.0189\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 1.52238\n",
      "Epoch 340/1000\n",
      "633/633 [==============================] - 0s 219us/step - loss: 1.6473 - mae: 1.0225 - val_loss: 1.5293 - val_mae: 1.0191\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 1.52238\n",
      "Epoch 341/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.6375 - mae: 0.9942 - val_loss: 1.5304 - val_mae: 1.0192\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 1.52238\n",
      "Epoch 342/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.6070 - mae: 1.0054 - val_loss: 1.5283 - val_mae: 1.0183\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 1.52238\n",
      "Epoch 343/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.7517 - mae: 1.0493 - val_loss: 1.5302 - val_mae: 1.0179\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 1.52238\n",
      "Epoch 344/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.6526 - mae: 1.0183 - val_loss: 1.5279 - val_mae: 1.0170\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 1.52238\n",
      "Epoch 345/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.7154 - mae: 1.0392 - val_loss: 1.5263 - val_mae: 1.0163\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 1.52238\n",
      "Epoch 346/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.6591 - mae: 1.0117 - val_loss: 1.5336 - val_mae: 1.0201\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 1.52238\n",
      "Epoch 347/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.7449 - mae: 1.0291 - val_loss: 1.5332 - val_mae: 1.0200\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 1.52238\n",
      "Epoch 348/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.7110 - mae: 1.0379 - val_loss: 1.5306 - val_mae: 1.0189\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 1.52238\n",
      "Epoch 349/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.6673 - mae: 1.0199 - val_loss: 1.5279 - val_mae: 1.0179\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 1.52238\n",
      "Epoch 350/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.6005 - mae: 0.9951 - val_loss: 1.5223 - val_mae: 1.0175\n",
      "\n",
      "Epoch 00350: val_loss improved from 1.52238 to 1.52229, saving model to model.sve\n",
      "Epoch 351/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.6526 - mae: 0.9926 - val_loss: 1.5233 - val_mae: 1.0177\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 1.52229\n",
      "Epoch 352/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.6377 - mae: 1.0274 - val_loss: 1.5218 - val_mae: 1.0177\n",
      "\n",
      "Epoch 00352: val_loss improved from 1.52229 to 1.52178, saving model to model.sve\n",
      "Epoch 353/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.6605 - mae: 1.0192 - val_loss: 1.5299 - val_mae: 1.0192\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 1.52178\n",
      "Epoch 354/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.5553 - mae: 0.9960 - val_loss: 1.5259 - val_mae: 1.0166\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 1.52178\n",
      "Epoch 355/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.7131 - mae: 1.0357 - val_loss: 1.5237 - val_mae: 1.0157\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 1.52178\n",
      "Epoch 356/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.6561 - mae: 1.0020 - val_loss: 1.5186 - val_mae: 1.0139\n",
      "\n",
      "Epoch 00356: val_loss improved from 1.52178 to 1.51862, saving model to model.sve\n",
      "Epoch 357/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.6572 - mae: 1.0375 - val_loss: 1.5246 - val_mae: 1.0159\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 1.51862\n",
      "Epoch 358/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 1.6080 - mae: 0.9996 - val_loss: 1.5253 - val_mae: 1.0172\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 1.51862\n",
      "Epoch 359/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.6451 - mae: 0.9995 - val_loss: 1.5251 - val_mae: 1.0172\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 1.51862\n",
      "Epoch 360/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.6399 - mae: 1.0201 - val_loss: 1.5216 - val_mae: 1.0169\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 1.51862\n",
      "Epoch 361/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.7375 - mae: 1.0468 - val_loss: 1.5201 - val_mae: 1.0162\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 1.51862\n",
      "Epoch 362/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.6428 - mae: 1.0224 - val_loss: 1.5159 - val_mae: 1.0148\n",
      "\n",
      "Epoch 00362: val_loss improved from 1.51862 to 1.51593, saving model to model.sve\n",
      "Epoch 363/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.6444 - mae: 1.0041 - val_loss: 1.5138 - val_mae: 1.0131\n",
      "\n",
      "Epoch 00363: val_loss improved from 1.51593 to 1.51379, saving model to model.sve\n",
      "Epoch 364/1000\n",
      "633/633 [==============================] - 0s 193us/step - loss: 1.5868 - mae: 1.0001 - val_loss: 1.5111 - val_mae: 1.0135\n",
      "\n",
      "Epoch 00364: val_loss improved from 1.51379 to 1.51105, saving model to model.sve\n",
      "Epoch 365/1000\n",
      "633/633 [==============================] - 0s 197us/step - loss: 1.6401 - mae: 1.0114 - val_loss: 1.5056 - val_mae: 1.0108\n",
      "\n",
      "Epoch 00365: val_loss improved from 1.51105 to 1.50556, saving model to model.sve\n",
      "Epoch 366/1000\n",
      "633/633 [==============================] - 0s 197us/step - loss: 1.6891 - mae: 1.0315 - val_loss: 1.5066 - val_mae: 1.0106\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 1.50556\n",
      "Epoch 367/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.6740 - mae: 1.0313 - val_loss: 1.5078 - val_mae: 1.0107\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 1.50556\n",
      "Epoch 368/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.6219 - mae: 1.0160 - val_loss: 1.5064 - val_mae: 1.0105\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 1.50556\n",
      "Epoch 369/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5977 - mae: 1.0047 - val_loss: 1.5073 - val_mae: 1.0101\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 1.50556\n",
      "Epoch 370/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.6930 - mae: 1.0218 - val_loss: 1.5103 - val_mae: 1.0111\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 1.50556\n",
      "Epoch 371/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.6165 - mae: 1.0030 - val_loss: 1.5120 - val_mae: 1.0118\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 1.50556\n",
      "Epoch 372/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.6506 - mae: 1.0126 - val_loss: 1.5138 - val_mae: 1.0101\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 1.50556\n",
      "Epoch 373/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.7229 - mae: 1.0418 - val_loss: 1.5161 - val_mae: 1.0113\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 1.50556\n",
      "Epoch 374/1000\n",
      "633/633 [==============================] - 0s 193us/step - loss: 1.6502 - mae: 1.0224 - val_loss: 1.5121 - val_mae: 1.0106\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 1.50556\n",
      "Epoch 375/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.6296 - mae: 1.0083 - val_loss: 1.5130 - val_mae: 1.0112\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 1.50556\n",
      "Epoch 376/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.6733 - mae: 1.0225 - val_loss: 1.5114 - val_mae: 1.0110\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 1.50556\n",
      "Epoch 377/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.5967 - mae: 1.0102 - val_loss: 1.5090 - val_mae: 1.0105\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 1.50556\n",
      "Epoch 378/1000\n",
      "633/633 [==============================] - 0s 201us/step - loss: 1.6366 - mae: 1.0201 - val_loss: 1.5124 - val_mae: 1.0129\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 1.50556\n",
      "Epoch 379/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.6615 - mae: 1.0105 - val_loss: 1.5156 - val_mae: 1.0142\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 1.50556\n",
      "Epoch 380/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.6804 - mae: 1.0326 - val_loss: 1.5108 - val_mae: 1.0121\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 1.50556\n",
      "Epoch 381/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.6677 - mae: 1.0283 - val_loss: 1.5152 - val_mae: 1.0120\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 1.50556\n",
      "Epoch 382/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.5917 - mae: 1.0054 - val_loss: 1.5190 - val_mae: 1.0135\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 1.50556\n",
      "Epoch 383/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6056 - mae: 1.0009 - val_loss: 1.5206 - val_mae: 1.0143\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 1.50556\n",
      "Epoch 384/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.7264 - mae: 1.0357 - val_loss: 1.5216 - val_mae: 1.0146\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 1.50556\n",
      "Epoch 385/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6291 - mae: 0.9978 - val_loss: 1.5184 - val_mae: 1.0126\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 1.50556\n",
      "Epoch 386/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.6431 - mae: 1.0098 - val_loss: 1.5233 - val_mae: 1.0144\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 1.50556\n",
      "Epoch 387/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.6827 - mae: 1.0198 - val_loss: 1.5280 - val_mae: 1.0156\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 1.50556\n",
      "Epoch 388/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5631 - mae: 0.9891 - val_loss: 1.5245 - val_mae: 1.0150\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 1.50556\n",
      "Epoch 389/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.5798 - mae: 0.9985 - val_loss: 1.5257 - val_mae: 1.0155\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 1.50556\n",
      "Epoch 390/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5963 - mae: 0.9971 - val_loss: 1.5237 - val_mae: 1.0145\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 1.50556\n",
      "Epoch 391/1000\n",
      "633/633 [==============================] - 0s 209us/step - loss: 1.6121 - mae: 0.9988 - val_loss: 1.5226 - val_mae: 1.0146\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 1.50556\n",
      "Epoch 392/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.5758 - mae: 0.9805 - val_loss: 1.5198 - val_mae: 1.0143\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 1.50556\n",
      "Epoch 393/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.7042 - mae: 1.0337 - val_loss: 1.5167 - val_mae: 1.0150\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 1.50556\n",
      "Epoch 394/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.6678 - mae: 1.0160 - val_loss: 1.5139 - val_mae: 1.0146\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 1.50556\n",
      "Epoch 395/1000\n",
      "633/633 [==============================] - 0s 210us/step - loss: 1.5525 - mae: 0.9890 - val_loss: 1.5203 - val_mae: 1.0161\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 1.50556\n",
      "Epoch 396/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.6271 - mae: 1.0070 - val_loss: 1.5222 - val_mae: 1.0154\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 1.50556\n",
      "Epoch 397/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5946 - mae: 0.9904 - val_loss: 1.5305 - val_mae: 1.0173\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 1.50556\n",
      "Epoch 398/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.6432 - mae: 0.9976 - val_loss: 1.5322 - val_mae: 1.0190\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 1.50556\n",
      "Epoch 399/1000\n",
      "633/633 [==============================] - 0s 203us/step - loss: 1.5754 - mae: 0.9954 - val_loss: 1.5381 - val_mae: 1.0205\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 1.50556\n",
      "Epoch 400/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.5648 - mae: 0.9943 - val_loss: 1.5317 - val_mae: 1.0184\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 1.50556\n",
      "Epoch 401/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.6109 - mae: 1.0019 - val_loss: 1.5307 - val_mae: 1.0169\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 1.50556\n",
      "Epoch 402/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.6310 - mae: 1.0123 - val_loss: 1.5272 - val_mae: 1.0167\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 1.50556\n",
      "Epoch 403/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5640 - mae: 0.9854 - val_loss: 1.5294 - val_mae: 1.0175\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 1.50556\n",
      "Epoch 404/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.6159 - mae: 0.9873 - val_loss: 1.5274 - val_mae: 1.0160\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 1.50556\n",
      "Epoch 405/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.5597 - mae: 0.9851 - val_loss: 1.5266 - val_mae: 1.0161\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 1.50556\n",
      "Epoch 406/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.6488 - mae: 1.0223 - val_loss: 1.5261 - val_mae: 1.0166\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 1.50556\n",
      "Epoch 407/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.5279 - mae: 0.9688 - val_loss: 1.5243 - val_mae: 1.0159\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 1.50556\n",
      "Epoch 408/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.6726 - mae: 1.0312 - val_loss: 1.5213 - val_mae: 1.0160\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 1.50556\n",
      "Epoch 409/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.7452 - mae: 1.0343 - val_loss: 1.5228 - val_mae: 1.0156\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 1.50556\n",
      "Epoch 410/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6152 - mae: 1.0016 - val_loss: 1.5169 - val_mae: 1.0131\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 1.50556\n",
      "Epoch 411/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5190 - mae: 0.9848 - val_loss: 1.5165 - val_mae: 1.0132\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 1.50556\n",
      "Epoch 412/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.6037 - mae: 0.9893 - val_loss: 1.5164 - val_mae: 1.0129\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 1.50556\n",
      "Epoch 413/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5612 - mae: 0.9995 - val_loss: 1.5126 - val_mae: 1.0112\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 1.50556\n",
      "Epoch 414/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.6830 - mae: 1.0251 - val_loss: 1.5084 - val_mae: 1.0101\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 1.50556\n",
      "Epoch 415/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5131 - mae: 0.9809 - val_loss: 1.5096 - val_mae: 1.0103\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 1.50556\n",
      "Epoch 416/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.6281 - mae: 0.9995 - val_loss: 1.5139 - val_mae: 1.0120\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 1.50556\n",
      "Epoch 417/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 1.5433 - mae: 0.9687 - val_loss: 1.5120 - val_mae: 1.0117\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 1.50556\n",
      "Epoch 418/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.6690 - mae: 1.0167 - val_loss: 1.5131 - val_mae: 1.0102\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 1.50556\n",
      "Epoch 419/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 1.6035 - mae: 0.9926 - val_loss: 1.5173 - val_mae: 1.0116\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 1.50556\n",
      "Epoch 420/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6038 - mae: 0.9924 - val_loss: 1.5103 - val_mae: 1.0103\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 1.50556\n",
      "Epoch 421/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.6167 - mae: 1.0058 - val_loss: 1.5159 - val_mae: 1.0127\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 1.50556\n",
      "Epoch 422/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.6445 - mae: 1.0126 - val_loss: 1.5158 - val_mae: 1.0131\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 1.50556\n",
      "Epoch 423/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.5947 - mae: 0.9911 - val_loss: 1.5167 - val_mae: 1.0129\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 1.50556\n",
      "Epoch 424/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.6520 - mae: 1.0161 - val_loss: 1.5168 - val_mae: 1.0126\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 1.50556\n",
      "Epoch 425/1000\n",
      "633/633 [==============================] - 0s 216us/step - loss: 1.6068 - mae: 1.0134 - val_loss: 1.5139 - val_mae: 1.0119\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 1.50556\n",
      "Epoch 426/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5455 - mae: 0.9788 - val_loss: 1.5116 - val_mae: 1.0114\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 1.50556\n",
      "Epoch 427/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.6766 - mae: 1.0297 - val_loss: 1.5131 - val_mae: 1.0114\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 1.50556\n",
      "Epoch 428/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.6007 - mae: 1.0083 - val_loss: 1.5153 - val_mae: 1.0113\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 1.50556\n",
      "Epoch 429/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.5404 - mae: 0.9753 - val_loss: 1.5121 - val_mae: 1.0103\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 1.50556\n",
      "Epoch 430/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.5795 - mae: 0.9810 - val_loss: 1.5144 - val_mae: 1.0104\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 1.50556\n",
      "Epoch 431/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.5329 - mae: 0.9693 - val_loss: 1.5188 - val_mae: 1.0118\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 1.50556\n",
      "Epoch 432/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.6193 - mae: 1.0071 - val_loss: 1.5178 - val_mae: 1.0107\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 1.50556\n",
      "Epoch 433/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6540 - mae: 1.0129 - val_loss: 1.5131 - val_mae: 1.0095\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 1.50556\n",
      "Epoch 434/1000\n",
      "633/633 [==============================] - 0s 201us/step - loss: 1.6602 - mae: 1.0124 - val_loss: 1.5153 - val_mae: 1.0104\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 1.50556\n",
      "Epoch 435/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.6643 - mae: 1.0189 - val_loss: 1.5167 - val_mae: 1.0106\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 1.50556\n",
      "Epoch 436/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.5468 - mae: 0.9952 - val_loss: 1.5176 - val_mae: 1.0109\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 1.50556\n",
      "Epoch 437/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.6241 - mae: 1.0104 - val_loss: 1.5209 - val_mae: 1.0121\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 1.50556\n",
      "Epoch 438/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.5696 - mae: 0.9910 - val_loss: 1.5178 - val_mae: 1.0120\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 1.50556\n",
      "Epoch 439/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.6169 - mae: 1.0025 - val_loss: 1.5174 - val_mae: 1.0118\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 1.50556\n",
      "Epoch 440/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6132 - mae: 1.0030 - val_loss: 1.5146 - val_mae: 1.0106\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 1.50556\n",
      "Epoch 441/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.5659 - mae: 0.9834 - val_loss: 1.5114 - val_mae: 1.0107\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 1.50556\n",
      "Epoch 442/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.5862 - mae: 0.9908 - val_loss: 1.5133 - val_mae: 1.0110\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 1.50556\n",
      "Epoch 443/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5523 - mae: 0.9785 - val_loss: 1.5140 - val_mae: 1.0117\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 1.50556\n",
      "Epoch 444/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.6059 - mae: 0.9977 - val_loss: 1.5182 - val_mae: 1.0130\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 1.50556\n",
      "Epoch 445/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.6215 - mae: 1.0067 - val_loss: 1.5128 - val_mae: 1.0119\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 1.50556\n",
      "Epoch 446/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5737 - mae: 0.9940 - val_loss: 1.5099 - val_mae: 1.0118\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 1.50556\n",
      "Epoch 447/1000\n",
      "633/633 [==============================] - 0s 193us/step - loss: 1.6874 - mae: 1.0364 - val_loss: 1.5143 - val_mae: 1.0117\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 1.50556\n",
      "Epoch 448/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4756 - mae: 0.9625 - val_loss: 1.5218 - val_mae: 1.0133\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 1.50556\n",
      "Epoch 449/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.6176 - mae: 1.0124 - val_loss: 1.5221 - val_mae: 1.0134\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 1.50556\n",
      "Epoch 450/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.6089 - mae: 1.0163 - val_loss: 1.5254 - val_mae: 1.0132\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 1.50556\n",
      "Epoch 451/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.6037 - mae: 1.0123 - val_loss: 1.5235 - val_mae: 1.0127\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 1.50556\n",
      "Epoch 452/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.5783 - mae: 0.9914 - val_loss: 1.5218 - val_mae: 1.0112\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 1.50556\n",
      "Epoch 453/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.6051 - mae: 1.0162 - val_loss: 1.5206 - val_mae: 1.0099\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 1.50556\n",
      "Epoch 454/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5520 - mae: 0.9755 - val_loss: 1.5152 - val_mae: 1.0085\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 1.50556\n",
      "Epoch 455/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.6540 - mae: 1.0159 - val_loss: 1.5173 - val_mae: 1.0096\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 1.50556\n",
      "Epoch 456/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6591 - mae: 1.0116 - val_loss: 1.5183 - val_mae: 1.0112\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 1.50556\n",
      "Epoch 457/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.6058 - mae: 0.9937 - val_loss: 1.5181 - val_mae: 1.0110\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 1.50556\n",
      "Epoch 458/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.6271 - mae: 1.0141 - val_loss: 1.5172 - val_mae: 1.0111\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 1.50556\n",
      "Epoch 459/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.6069 - mae: 1.0001 - val_loss: 1.5212 - val_mae: 1.0130\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 1.50556\n",
      "Epoch 460/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.6393 - mae: 1.0102 - val_loss: 1.5175 - val_mae: 1.0117\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 1.50556\n",
      "Epoch 461/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.5478 - mae: 0.9860 - val_loss: 1.5130 - val_mae: 1.0109\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 1.50556\n",
      "Epoch 462/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.5675 - mae: 0.9843 - val_loss: 1.5137 - val_mae: 1.0108\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 1.50556\n",
      "Epoch 463/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.4904 - mae: 0.9669 - val_loss: 1.5178 - val_mae: 1.0123\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 1.50556\n",
      "Epoch 464/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5209 - mae: 0.9670 - val_loss: 1.5129 - val_mae: 1.0111\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 1.50556\n",
      "Epoch 465/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.5444 - mae: 0.9836 - val_loss: 1.5154 - val_mae: 1.0112\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 1.50556\n",
      "Epoch 466/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6010 - mae: 1.0013 - val_loss: 1.5205 - val_mae: 1.0129\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 1.50556\n",
      "Epoch 467/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.6201 - mae: 1.0145 - val_loss: 1.5160 - val_mae: 1.0117\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 1.50556\n",
      "Epoch 468/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.5502 - mae: 0.9706 - val_loss: 1.5113 - val_mae: 1.0116\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 1.50556\n",
      "Epoch 469/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.5705 - mae: 0.9969 - val_loss: 1.5077 - val_mae: 1.0105\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 1.50556\n",
      "Epoch 470/1000\n",
      "633/633 [==============================] - 0s 199us/step - loss: 1.5657 - mae: 0.9984 - val_loss: 1.5068 - val_mae: 1.0098\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 1.50556\n",
      "Epoch 471/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6185 - mae: 1.0013 - val_loss: 1.5117 - val_mae: 1.0106\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 1.50556\n",
      "Epoch 472/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.6002 - mae: 1.0054 - val_loss: 1.5128 - val_mae: 1.0116\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 1.50556\n",
      "Epoch 473/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.6287 - mae: 1.0233 - val_loss: 1.5107 - val_mae: 1.0097\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 1.50556\n",
      "Epoch 474/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.6130 - mae: 0.9989 - val_loss: 1.5084 - val_mae: 1.0093\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 1.50556\n",
      "Epoch 475/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.5260 - mae: 0.9796 - val_loss: 1.5021 - val_mae: 1.0076\n",
      "\n",
      "Epoch 00475: val_loss improved from 1.50556 to 1.50211, saving model to model.sve\n",
      "Epoch 476/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.5335 - mae: 0.9651 - val_loss: 1.5024 - val_mae: 1.0071\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 1.50211\n",
      "Epoch 477/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.6527 - mae: 1.0214 - val_loss: 1.5012 - val_mae: 1.0058\n",
      "\n",
      "Epoch 00477: val_loss improved from 1.50211 to 1.50121, saving model to model.sve\n",
      "Epoch 478/1000\n",
      "633/633 [==============================] - 0s 204us/step - loss: 1.5866 - mae: 0.9979 - val_loss: 1.4977 - val_mae: 1.0047\n",
      "\n",
      "Epoch 00478: val_loss improved from 1.50121 to 1.49774, saving model to model.sve\n",
      "Epoch 479/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5544 - mae: 0.9924 - val_loss: 1.5026 - val_mae: 1.0070\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 1.49774\n",
      "Epoch 480/1000\n",
      "633/633 [==============================] - 0s 205us/step - loss: 1.5145 - mae: 0.9704 - val_loss: 1.5085 - val_mae: 1.0086\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 1.49774\n",
      "Epoch 481/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.6498 - mae: 1.0097 - val_loss: 1.5048 - val_mae: 1.0071\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 1.49774\n",
      "Epoch 482/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5485 - mae: 0.9806 - val_loss: 1.5046 - val_mae: 1.0055\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 1.49774\n",
      "Epoch 483/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.7349 - mae: 1.0347 - val_loss: 1.4989 - val_mae: 1.0039\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 1.49774\n",
      "Epoch 484/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.6427 - mae: 0.9960 - val_loss: 1.4969 - val_mae: 1.0029\n",
      "\n",
      "Epoch 00484: val_loss improved from 1.49774 to 1.49685, saving model to model.sve\n",
      "Epoch 485/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.5623 - mae: 0.9792 - val_loss: 1.5004 - val_mae: 1.0039\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 1.49685\n",
      "Epoch 486/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.5894 - mae: 0.9919 - val_loss: 1.4994 - val_mae: 1.0033\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 1.49685\n",
      "Epoch 487/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.5467 - mae: 0.9700 - val_loss: 1.5056 - val_mae: 1.0045\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 1.49685\n",
      "Epoch 488/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5127 - mae: 0.9868 - val_loss: 1.5058 - val_mae: 1.0042\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 1.49685\n",
      "Epoch 489/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.5182 - mae: 0.9680 - val_loss: 1.5043 - val_mae: 1.0035\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 1.49685\n",
      "Epoch 490/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4918 - mae: 0.9797 - val_loss: 1.5076 - val_mae: 1.0044\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 1.49685\n",
      "Epoch 491/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.5696 - mae: 0.9860 - val_loss: 1.5076 - val_mae: 1.0042\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 1.49685\n",
      "Epoch 492/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.5579 - mae: 0.9895 - val_loss: 1.5087 - val_mae: 1.0050\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 1.49685\n",
      "Epoch 493/1000\n",
      "633/633 [==============================] - 0s 209us/step - loss: 1.5441 - mae: 0.9707 - val_loss: 1.5139 - val_mae: 1.0069\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 1.49685\n",
      "Epoch 494/1000\n",
      "633/633 [==============================] - 0s 206us/step - loss: 1.4658 - mae: 0.9442 - val_loss: 1.5153 - val_mae: 1.0072\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 1.49685\n",
      "Epoch 495/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.5785 - mae: 1.0046 - val_loss: 1.5136 - val_mae: 1.0066\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 1.49685\n",
      "Epoch 496/1000\n",
      "633/633 [==============================] - 0s 195us/step - loss: 1.6245 - mae: 1.0082 - val_loss: 1.5135 - val_mae: 1.0067\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 1.49685\n",
      "Epoch 497/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5943 - mae: 1.0003 - val_loss: 1.5129 - val_mae: 1.0063\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 1.49685\n",
      "Epoch 498/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.6259 - mae: 1.0166 - val_loss: 1.5147 - val_mae: 1.0070\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 1.49685\n",
      "Epoch 499/1000\n",
      "633/633 [==============================] - 0s 193us/step - loss: 1.4756 - mae: 0.9506 - val_loss: 1.5230 - val_mae: 1.0084\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 1.49685\n",
      "Epoch 500/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.5121 - mae: 0.9766 - val_loss: 1.5190 - val_mae: 1.0076\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 1.49685\n",
      "Epoch 501/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.4420 - mae: 0.9458 - val_loss: 1.5203 - val_mae: 1.0090\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 1.49685\n",
      "Epoch 502/1000\n",
      "633/633 [==============================] - 0s 203us/step - loss: 1.5549 - mae: 0.9860 - val_loss: 1.5205 - val_mae: 1.0090\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 1.49685\n",
      "Epoch 503/1000\n",
      "633/633 [==============================] - 0s 195us/step - loss: 1.5227 - mae: 0.9709 - val_loss: 1.5198 - val_mae: 1.0091\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 1.49685\n",
      "Epoch 504/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.5729 - mae: 0.9987 - val_loss: 1.5193 - val_mae: 1.0093\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 1.49685\n",
      "Epoch 505/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.5687 - mae: 0.9918 - val_loss: 1.5190 - val_mae: 1.0090\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 1.49685\n",
      "Epoch 506/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.5393 - mae: 0.9859 - val_loss: 1.5176 - val_mae: 1.0084\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 1.49685\n",
      "Epoch 507/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5943 - mae: 1.0035 - val_loss: 1.5148 - val_mae: 1.0080\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 1.49685\n",
      "Epoch 508/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.4718 - mae: 0.9670 - val_loss: 1.5139 - val_mae: 1.0059\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 1.49685\n",
      "Epoch 509/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.6517 - mae: 0.9996 - val_loss: 1.5093 - val_mae: 1.0049\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 1.49685\n",
      "Epoch 510/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.5429 - mae: 0.9690 - val_loss: 1.5118 - val_mae: 1.0056\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 1.49685\n",
      "Epoch 511/1000\n",
      "633/633 [==============================] - 0s 199us/step - loss: 1.4990 - mae: 0.9766 - val_loss: 1.5099 - val_mae: 1.0052\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 1.49685\n",
      "Epoch 512/1000\n",
      "633/633 [==============================] - 0s 242us/step - loss: 1.5169 - mae: 0.9766 - val_loss: 1.5103 - val_mae: 1.0059\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 1.49685\n",
      "Epoch 513/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 1.5730 - mae: 0.9899 - val_loss: 1.5093 - val_mae: 1.0050\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 1.49685\n",
      "Epoch 514/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.5933 - mae: 0.9938 - val_loss: 1.5053 - val_mae: 1.0036\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 1.49685\n",
      "Epoch 515/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.5452 - mae: 0.9958 - val_loss: 1.5046 - val_mae: 1.0035\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 1.49685\n",
      "Epoch 516/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.5870 - mae: 0.9886 - val_loss: 1.5042 - val_mae: 1.0038\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 1.49685\n",
      "Epoch 517/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.6037 - mae: 0.9984 - val_loss: 1.4975 - val_mae: 1.0015\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 1.49685\n",
      "Epoch 518/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.5397 - mae: 0.9901 - val_loss: 1.5003 - val_mae: 1.0019\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 1.49685\n",
      "Epoch 519/1000\n",
      "633/633 [==============================] - 0s 206us/step - loss: 1.5365 - mae: 0.9723 - val_loss: 1.5042 - val_mae: 1.0031\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 1.49685\n",
      "Epoch 520/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.5041 - mae: 0.9506 - val_loss: 1.5059 - val_mae: 1.0036\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 1.49685\n",
      "Epoch 521/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.5865 - mae: 0.9947 - val_loss: 1.5080 - val_mae: 1.0043\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 1.49685\n",
      "Epoch 522/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.5838 - mae: 0.9862 - val_loss: 1.5114 - val_mae: 1.0049\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 1.49685\n",
      "Epoch 523/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.5534 - mae: 0.9752 - val_loss: 1.5056 - val_mae: 1.0034\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 1.49685\n",
      "Epoch 524/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.6376 - mae: 1.0065 - val_loss: 1.5030 - val_mae: 1.0027\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 1.49685\n",
      "Epoch 525/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.5207 - mae: 0.9743 - val_loss: 1.5025 - val_mae: 1.0017\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 1.49685\n",
      "Epoch 526/1000\n",
      "633/633 [==============================] - 0s 200us/step - loss: 1.5303 - mae: 0.9648 - val_loss: 1.4987 - val_mae: 1.0011\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 1.49685\n",
      "Epoch 527/1000\n",
      "633/633 [==============================] - 0s 202us/step - loss: 1.5829 - mae: 0.9809 - val_loss: 1.5021 - val_mae: 1.0006\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 1.49685\n",
      "Epoch 528/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.5395 - mae: 0.9621 - val_loss: 1.4970 - val_mae: 0.9986\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 1.49685\n",
      "Epoch 529/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 1.5025 - mae: 0.9775 - val_loss: 1.4994 - val_mae: 0.9975\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 1.49685\n",
      "Epoch 530/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.5453 - mae: 0.9797 - val_loss: 1.5019 - val_mae: 0.9985\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 1.49685\n",
      "Epoch 531/1000\n",
      "633/633 [==============================] - 0s 193us/step - loss: 1.5314 - mae: 0.9663 - val_loss: 1.5020 - val_mae: 0.9988\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 1.49685\n",
      "Epoch 532/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.4495 - mae: 0.9514 - val_loss: 1.5053 - val_mae: 1.0014\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 1.49685\n",
      "Epoch 533/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.5717 - mae: 0.9933 - val_loss: 1.5015 - val_mae: 1.0006\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 1.49685\n",
      "Epoch 534/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.5429 - mae: 0.9893 - val_loss: 1.5016 - val_mae: 1.0000\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 1.49685\n",
      "Epoch 535/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.6766 - mae: 1.0034 - val_loss: 1.5020 - val_mae: 0.9994\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 1.49685\n",
      "Epoch 536/1000\n",
      "633/633 [==============================] - 0s 198us/step - loss: 1.4847 - mae: 0.9642 - val_loss: 1.5022 - val_mae: 0.9993\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 1.49685\n",
      "Epoch 537/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.6303 - mae: 1.0099 - val_loss: 1.5005 - val_mae: 0.9987\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 1.49685\n",
      "Epoch 538/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 1.4688 - mae: 0.9480 - val_loss: 1.5010 - val_mae: 0.9978\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 1.49685\n",
      "Epoch 539/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.5810 - mae: 1.0020 - val_loss: 1.4968 - val_mae: 0.9974\n",
      "\n",
      "Epoch 00539: val_loss improved from 1.49685 to 1.49680, saving model to model.sve\n",
      "Epoch 540/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.5292 - mae: 0.9791 - val_loss: 1.4959 - val_mae: 0.9974\n",
      "\n",
      "Epoch 00540: val_loss improved from 1.49680 to 1.49591, saving model to model.sve\n",
      "Epoch 541/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.5688 - mae: 0.9969 - val_loss: 1.4963 - val_mae: 0.9972\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 1.49591\n",
      "Epoch 542/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.6254 - mae: 1.0077 - val_loss: 1.4963 - val_mae: 0.9970\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 1.49591\n",
      "Epoch 543/1000\n",
      "633/633 [==============================] - 0s 216us/step - loss: 1.5263 - mae: 0.9645 - val_loss: 1.4983 - val_mae: 0.9964\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 1.49591\n",
      "Epoch 544/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.5532 - mae: 0.9792 - val_loss: 1.4969 - val_mae: 0.9961\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 1.49591\n",
      "Epoch 545/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.5441 - mae: 0.9806 - val_loss: 1.4981 - val_mae: 0.9970\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 1.49591\n",
      "Epoch 546/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5423 - mae: 0.9802 - val_loss: 1.4972 - val_mae: 0.9970\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 1.49591\n",
      "Epoch 547/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.4021 - mae: 0.9258 - val_loss: 1.5027 - val_mae: 0.9978\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 1.49591\n",
      "Epoch 548/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.5063 - mae: 0.9787 - val_loss: 1.5069 - val_mae: 0.9995\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 1.49591\n",
      "Epoch 549/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.5076 - mae: 0.9710 - val_loss: 1.5060 - val_mae: 0.9997\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 1.49591\n",
      "Epoch 550/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.5501 - mae: 0.9914 - val_loss: 1.5006 - val_mae: 0.9988\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 1.49591\n",
      "Epoch 551/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.5311 - mae: 0.9707 - val_loss: 1.4927 - val_mae: 0.9961\n",
      "\n",
      "Epoch 00551: val_loss improved from 1.49591 to 1.49271, saving model to model.sve\n",
      "Epoch 552/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 1.4893 - mae: 0.9682 - val_loss: 1.4915 - val_mae: 0.9966\n",
      "\n",
      "Epoch 00552: val_loss improved from 1.49271 to 1.49153, saving model to model.sve\n",
      "Epoch 553/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.5481 - mae: 0.9805 - val_loss: 1.4846 - val_mae: 0.9947\n",
      "\n",
      "Epoch 00553: val_loss improved from 1.49153 to 1.48455, saving model to model.sve\n",
      "Epoch 554/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4563 - mae: 0.9302 - val_loss: 1.4846 - val_mae: 0.9944\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 1.48455\n",
      "Epoch 555/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.5838 - mae: 1.0009 - val_loss: 1.4822 - val_mae: 0.9935\n",
      "\n",
      "Epoch 00555: val_loss improved from 1.48455 to 1.48223, saving model to model.sve\n",
      "Epoch 556/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.5605 - mae: 0.9840 - val_loss: 1.4805 - val_mae: 0.9927\n",
      "\n",
      "Epoch 00556: val_loss improved from 1.48223 to 1.48047, saving model to model.sve\n",
      "Epoch 557/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.5574 - mae: 0.9784 - val_loss: 1.4835 - val_mae: 0.9932\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 1.48047\n",
      "Epoch 558/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.5315 - mae: 0.9768 - val_loss: 1.4819 - val_mae: 0.9929\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 1.48047\n",
      "Epoch 559/1000\n",
      "633/633 [==============================] - 0s 216us/step - loss: 1.5738 - mae: 0.9958 - val_loss: 1.4836 - val_mae: 0.9938\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 1.48047\n",
      "Epoch 560/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.4612 - mae: 0.9467 - val_loss: 1.4895 - val_mae: 0.9949\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 1.48047\n",
      "Epoch 561/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.5303 - mae: 0.9742 - val_loss: 1.4854 - val_mae: 0.9933\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 1.48047\n",
      "Epoch 562/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.5159 - mae: 0.9533 - val_loss: 1.4853 - val_mae: 0.9931\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 1.48047\n",
      "Epoch 563/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.5189 - mae: 0.9794 - val_loss: 1.4848 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 1.48047\n",
      "Epoch 564/1000\n",
      "633/633 [==============================] - 0s 202us/step - loss: 1.5528 - mae: 0.9881 - val_loss: 1.4913 - val_mae: 0.9953\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 1.48047\n",
      "Epoch 565/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.6492 - mae: 1.0148 - val_loss: 1.4852 - val_mae: 0.9928\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 1.48047\n",
      "Epoch 566/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.5618 - mae: 0.9917 - val_loss: 1.4861 - val_mae: 0.9920\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 1.48047\n",
      "Epoch 567/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.4110 - mae: 0.9367 - val_loss: 1.4905 - val_mae: 0.9938\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 1.48047\n",
      "Epoch 568/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5565 - mae: 0.9959 - val_loss: 1.4887 - val_mae: 0.9932\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 1.48047\n",
      "Epoch 569/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.4556 - mae: 0.9339 - val_loss: 1.4896 - val_mae: 0.9927\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 1.48047\n",
      "Epoch 570/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.5042 - mae: 0.9699 - val_loss: 1.4866 - val_mae: 0.9921\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 1.48047\n",
      "Epoch 571/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.5485 - mae: 0.9804 - val_loss: 1.4903 - val_mae: 0.9931\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 1.48047\n",
      "Epoch 572/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.5233 - mae: 0.9710 - val_loss: 1.4858 - val_mae: 0.9909\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 1.48047\n",
      "Epoch 573/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5220 - mae: 0.9741 - val_loss: 1.4826 - val_mae: 0.9894\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 1.48047\n",
      "Epoch 574/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.5775 - mae: 0.9879 - val_loss: 1.4843 - val_mae: 0.9899\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 1.48047\n",
      "Epoch 575/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.4835 - mae: 0.9681 - val_loss: 1.4896 - val_mae: 0.9914\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 1.48047\n",
      "Epoch 576/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.4783 - mae: 0.9586 - val_loss: 1.4923 - val_mae: 0.9923\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 1.48047\n",
      "Epoch 577/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.5271 - mae: 0.9701 - val_loss: 1.4978 - val_mae: 0.9941\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 1.48047\n",
      "Epoch 578/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5832 - mae: 0.9930 - val_loss: 1.5020 - val_mae: 0.9948\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 1.48047\n",
      "Epoch 579/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5179 - mae: 0.9612 - val_loss: 1.4990 - val_mae: 0.9940\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 1.48047\n",
      "Epoch 580/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.4992 - mae: 0.9609 - val_loss: 1.5016 - val_mae: 0.9936\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 1.48047\n",
      "Epoch 581/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5964 - mae: 1.0047 - val_loss: 1.4964 - val_mae: 0.9928\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 1.48047\n",
      "Epoch 582/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.4628 - mae: 0.9506 - val_loss: 1.4992 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 1.48047\n",
      "Epoch 583/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4369 - mae: 0.9560 - val_loss: 1.5018 - val_mae: 0.9934\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 1.48047\n",
      "Epoch 584/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.5140 - mae: 0.9638 - val_loss: 1.5043 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 1.48047\n",
      "Epoch 585/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.5315 - mae: 0.9825 - val_loss: 1.5029 - val_mae: 0.9931\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 1.48047\n",
      "Epoch 586/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.6009 - mae: 1.0070 - val_loss: 1.4990 - val_mae: 0.9920\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 1.48047\n",
      "Epoch 587/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.4756 - mae: 0.9629 - val_loss: 1.4947 - val_mae: 0.9915\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 1.48047\n",
      "Epoch 588/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4286 - mae: 0.9405 - val_loss: 1.4972 - val_mae: 0.9928\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 1.48047\n",
      "Epoch 589/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.6103 - mae: 1.0037 - val_loss: 1.4952 - val_mae: 0.9925\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 1.48047\n",
      "Epoch 590/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.4854 - mae: 0.9652 - val_loss: 1.4894 - val_mae: 0.9905\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 1.48047\n",
      "Epoch 591/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.5153 - mae: 0.9710 - val_loss: 1.4919 - val_mae: 0.9925\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 1.48047\n",
      "Epoch 592/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.4788 - mae: 0.9593 - val_loss: 1.4934 - val_mae: 0.9933\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 1.48047\n",
      "Epoch 593/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.5354 - mae: 0.9729 - val_loss: 1.4945 - val_mae: 0.9940\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 1.48047\n",
      "Epoch 594/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 1.5225 - mae: 0.9847 - val_loss: 1.4923 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 1.48047\n",
      "Epoch 595/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.4883 - mae: 0.9624 - val_loss: 1.4871 - val_mae: 0.9919\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 1.48047\n",
      "Epoch 596/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.4852 - mae: 0.9609 - val_loss: 1.4874 - val_mae: 0.9915\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 1.48047\n",
      "Epoch 597/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 1.4774 - mae: 0.9655 - val_loss: 1.4934 - val_mae: 0.9925\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 1.48047\n",
      "Epoch 598/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5536 - mae: 0.9688 - val_loss: 1.4959 - val_mae: 0.9919\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 1.48047\n",
      "Epoch 599/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4818 - mae: 0.9569 - val_loss: 1.4962 - val_mae: 0.9924\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 1.48047\n",
      "Epoch 600/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5387 - mae: 0.9744 - val_loss: 1.4923 - val_mae: 0.9922\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 1.48047\n",
      "Epoch 601/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4495 - mae: 0.9547 - val_loss: 1.4899 - val_mae: 0.9918\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 1.48047\n",
      "Epoch 602/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.5252 - mae: 0.9701 - val_loss: 1.4924 - val_mae: 0.9930\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 1.48047\n",
      "Epoch 603/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5757 - mae: 0.9809 - val_loss: 1.4909 - val_mae: 0.9934\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 1.48047\n",
      "Epoch 604/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5037 - mae: 0.9673 - val_loss: 1.4915 - val_mae: 0.9938\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 1.48047\n",
      "Epoch 605/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.4784 - mae: 0.9725 - val_loss: 1.4925 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 1.48047\n",
      "Epoch 606/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4641 - mae: 0.9509 - val_loss: 1.4888 - val_mae: 0.9922\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 1.48047\n",
      "Epoch 607/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5233 - mae: 0.9856 - val_loss: 1.4910 - val_mae: 0.9935\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 1.48047\n",
      "Epoch 608/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.4712 - mae: 0.9619 - val_loss: 1.4887 - val_mae: 0.9922\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 1.48047\n",
      "Epoch 609/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.4925 - mae: 0.9640 - val_loss: 1.4883 - val_mae: 0.9913\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 1.48047\n",
      "Epoch 610/1000\n",
      "633/633 [==============================] - 0s 169us/step - loss: 1.4888 - mae: 0.9761 - val_loss: 1.4858 - val_mae: 0.9901\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 1.48047\n",
      "Epoch 611/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.4831 - mae: 0.9610 - val_loss: 1.4815 - val_mae: 0.9886\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 1.48047\n",
      "Epoch 612/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5169 - mae: 0.9727 - val_loss: 1.4787 - val_mae: 0.9874\n",
      "\n",
      "Epoch 00612: val_loss improved from 1.48047 to 1.47870, saving model to model.sve\n",
      "Epoch 613/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.4839 - mae: 0.9530 - val_loss: 1.4818 - val_mae: 0.9880\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 1.47870\n",
      "Epoch 614/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5230 - mae: 0.9607 - val_loss: 1.4808 - val_mae: 0.9880\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 1.47870\n",
      "Epoch 615/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.5332 - mae: 0.9856 - val_loss: 1.4842 - val_mae: 0.9886\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 1.47870\n",
      "Epoch 616/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5393 - mae: 0.9755 - val_loss: 1.4913 - val_mae: 0.9918\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 1.47870\n",
      "Epoch 617/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.4979 - mae: 0.9688 - val_loss: 1.4914 - val_mae: 0.9920\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 1.47870\n",
      "Epoch 618/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5220 - mae: 0.9775 - val_loss: 1.4902 - val_mae: 0.9909\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 1.47870\n",
      "Epoch 619/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4166 - mae: 0.9385 - val_loss: 1.4922 - val_mae: 0.9925\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 1.47870\n",
      "Epoch 620/1000\n",
      "633/633 [==============================] - 0s 201us/step - loss: 1.4787 - mae: 0.9582 - val_loss: 1.4945 - val_mae: 0.9946\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 1.47870\n",
      "Epoch 621/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.6042 - mae: 1.0048 - val_loss: 1.4868 - val_mae: 0.9917\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 1.47870\n",
      "Epoch 622/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.4947 - mae: 0.9787 - val_loss: 1.4879 - val_mae: 0.9906\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 1.47870\n",
      "Epoch 623/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.4246 - mae: 0.9385 - val_loss: 1.4979 - val_mae: 0.9934\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 1.47870\n",
      "Epoch 624/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5256 - mae: 0.9761 - val_loss: 1.5004 - val_mae: 0.9960\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 1.47870\n",
      "Epoch 625/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4802 - mae: 0.9553 - val_loss: 1.4933 - val_mae: 0.9946\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 1.47870\n",
      "Epoch 626/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5026 - mae: 0.9663 - val_loss: 1.4974 - val_mae: 0.9941\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 1.47870\n",
      "Epoch 627/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.5069 - mae: 0.9692 - val_loss: 1.4956 - val_mae: 0.9939\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 1.47870\n",
      "Epoch 628/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5006 - mae: 0.9619 - val_loss: 1.4983 - val_mae: 0.9945\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 1.47870\n",
      "Epoch 629/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4729 - mae: 0.9590 - val_loss: 1.4990 - val_mae: 0.9944\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 1.47870\n",
      "Epoch 630/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5190 - mae: 0.9728 - val_loss: 1.4964 - val_mae: 0.9933\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 1.47870\n",
      "Epoch 631/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.4059 - mae: 0.9258 - val_loss: 1.4981 - val_mae: 0.9938\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 1.47870\n",
      "Epoch 632/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5773 - mae: 0.9888 - val_loss: 1.4973 - val_mae: 0.9934\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 1.47870\n",
      "Epoch 633/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.5034 - mae: 0.9716 - val_loss: 1.4996 - val_mae: 0.9942\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 1.47870\n",
      "Epoch 634/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4477 - mae: 0.9374 - val_loss: 1.5044 - val_mae: 0.9962\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 1.47870\n",
      "Epoch 635/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3838 - mae: 0.9302 - val_loss: 1.5014 - val_mae: 0.9949\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 1.47870\n",
      "Epoch 636/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.5296 - mae: 0.9760 - val_loss: 1.4991 - val_mae: 0.9941\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 1.47870\n",
      "Epoch 637/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 1.4820 - mae: 0.9611 - val_loss: 1.4981 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 1.47870\n",
      "Epoch 638/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4828 - mae: 0.9599 - val_loss: 1.4972 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 1.47870\n",
      "Epoch 639/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4767 - mae: 0.9523 - val_loss: 1.4925 - val_mae: 0.9910\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 1.47870\n",
      "Epoch 640/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.5114 - mae: 0.9611 - val_loss: 1.4841 - val_mae: 0.9884\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 1.47870\n",
      "Epoch 641/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.5175 - mae: 0.9608 - val_loss: 1.4840 - val_mae: 0.9887\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 1.47870\n",
      "Epoch 642/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.5082 - mae: 0.9749 - val_loss: 1.4817 - val_mae: 0.9878\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 1.47870\n",
      "Epoch 643/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.3911 - mae: 0.9160 - val_loss: 1.4849 - val_mae: 0.9904\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 1.47870\n",
      "Epoch 644/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4545 - mae: 0.9578 - val_loss: 1.4822 - val_mae: 0.9889\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 1.47870\n",
      "Epoch 645/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.5251 - mae: 0.9802 - val_loss: 1.4868 - val_mae: 0.9896\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 1.47870\n",
      "Epoch 646/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.5188 - mae: 0.9705 - val_loss: 1.4842 - val_mae: 0.9885\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 1.47870\n",
      "Epoch 647/1000\n",
      "633/633 [==============================] - 0s 169us/step - loss: 1.4258 - mae: 0.9316 - val_loss: 1.4818 - val_mae: 0.9878\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 1.47870\n",
      "Epoch 648/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.5429 - mae: 0.9822 - val_loss: 1.4816 - val_mae: 0.9871\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 1.47870\n",
      "Epoch 649/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.4505 - mae: 0.9470 - val_loss: 1.4844 - val_mae: 0.9876\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 1.47870\n",
      "Epoch 650/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.4468 - mae: 0.9519 - val_loss: 1.4856 - val_mae: 0.9879\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 1.47870\n",
      "Epoch 651/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4689 - mae: 0.9434 - val_loss: 1.4850 - val_mae: 0.9880\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 1.47870\n",
      "Epoch 652/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4655 - mae: 0.9470 - val_loss: 1.4834 - val_mae: 0.9883\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 1.47870\n",
      "Epoch 653/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5032 - mae: 0.9798 - val_loss: 1.4869 - val_mae: 0.9887\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 1.47870\n",
      "Epoch 654/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.4085 - mae: 0.9357 - val_loss: 1.4823 - val_mae: 0.9876\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 1.47870\n",
      "Epoch 655/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.5205 - mae: 0.9480 - val_loss: 1.4826 - val_mae: 0.9879\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 1.47870\n",
      "Epoch 656/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.4947 - mae: 0.9740 - val_loss: 1.4854 - val_mae: 0.9907\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 1.47870\n",
      "Epoch 657/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.3996 - mae: 0.9416 - val_loss: 1.4861 - val_mae: 0.9905\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 1.47870\n",
      "Epoch 658/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5067 - mae: 0.9720 - val_loss: 1.4905 - val_mae: 0.9918\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 1.47870\n",
      "Epoch 659/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4353 - mae: 0.9484 - val_loss: 1.4888 - val_mae: 0.9911\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 1.47870\n",
      "Epoch 660/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4900 - mae: 0.9671 - val_loss: 1.4932 - val_mae: 0.9919\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 1.47870\n",
      "Epoch 661/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.4606 - mae: 0.9480 - val_loss: 1.4896 - val_mae: 0.9915\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 1.47870\n",
      "Epoch 662/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3857 - mae: 0.9340 - val_loss: 1.4935 - val_mae: 0.9925\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 1.47870\n",
      "Epoch 663/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.4406 - mae: 0.9342 - val_loss: 1.4979 - val_mae: 0.9933\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 1.47870\n",
      "Epoch 664/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.4783 - mae: 0.9601 - val_loss: 1.4968 - val_mae: 0.9923\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 1.47870\n",
      "Epoch 665/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.4681 - mae: 0.9485 - val_loss: 1.5012 - val_mae: 0.9939\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 1.47870\n",
      "Epoch 666/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4311 - mae: 0.9316 - val_loss: 1.5004 - val_mae: 0.9924\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 1.47870\n",
      "Epoch 667/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5226 - mae: 0.9741 - val_loss: 1.4946 - val_mae: 0.9918\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 1.47870\n",
      "Epoch 668/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4481 - mae: 0.9258 - val_loss: 1.4953 - val_mae: 0.9926\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 1.47870\n",
      "Epoch 669/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.5630 - mae: 0.9772 - val_loss: 1.4927 - val_mae: 0.9923\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 1.47870\n",
      "Epoch 670/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.3875 - mae: 0.9177 - val_loss: 1.4964 - val_mae: 0.9939\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 1.47870\n",
      "Epoch 671/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4454 - mae: 0.9371 - val_loss: 1.4987 - val_mae: 0.9935\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 1.47870\n",
      "Epoch 672/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4579 - mae: 0.9549 - val_loss: 1.5018 - val_mae: 0.9943\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 1.47870\n",
      "Epoch 673/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 1.4995 - mae: 0.9616 - val_loss: 1.4976 - val_mae: 0.9924\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 1.47870\n",
      "Epoch 674/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.4348 - mae: 0.9556 - val_loss: 1.4964 - val_mae: 0.9918\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 1.47870\n",
      "Epoch 675/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.4751 - mae: 0.9568 - val_loss: 1.4940 - val_mae: 0.9924\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 1.47870\n",
      "Epoch 676/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.4069 - mae: 0.9338 - val_loss: 1.4944 - val_mae: 0.9913\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 1.47870\n",
      "Epoch 677/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4361 - mae: 0.9270 - val_loss: 1.4927 - val_mae: 0.9912\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 1.47870\n",
      "Epoch 678/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4983 - mae: 0.9602 - val_loss: 1.4931 - val_mae: 0.9919\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 1.47870\n",
      "Epoch 679/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.4603 - mae: 0.9569 - val_loss: 1.4961 - val_mae: 0.9931\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 1.47870\n",
      "Epoch 680/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.4332 - mae: 0.9531 - val_loss: 1.4991 - val_mae: 0.9946\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 1.47870\n",
      "Epoch 681/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4847 - mae: 0.9696 - val_loss: 1.5031 - val_mae: 0.9960\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 1.47870\n",
      "Epoch 682/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.4838 - mae: 0.9526 - val_loss: 1.4968 - val_mae: 0.9939\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 1.47870\n",
      "Epoch 683/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4682 - mae: 0.9658 - val_loss: 1.4974 - val_mae: 0.9936\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 1.47870\n",
      "Epoch 684/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.4966 - mae: 0.9572 - val_loss: 1.4960 - val_mae: 0.9928\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 1.47870\n",
      "Epoch 685/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4497 - mae: 0.9415 - val_loss: 1.4971 - val_mae: 0.9939\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 1.47870\n",
      "Epoch 686/1000\n",
      "633/633 [==============================] - 0s 218us/step - loss: 1.4323 - mae: 0.9463 - val_loss: 1.4945 - val_mae: 0.9930\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 1.47870\n",
      "Epoch 687/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.4094 - mae: 0.9219 - val_loss: 1.5010 - val_mae: 0.9952\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 1.47870\n",
      "Epoch 688/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4259 - mae: 0.9345 - val_loss: 1.5017 - val_mae: 0.9954\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 1.47870\n",
      "Epoch 689/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3927 - mae: 0.9401 - val_loss: 1.5047 - val_mae: 0.9962\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 1.47870\n",
      "Epoch 690/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 1.4506 - mae: 0.9373 - val_loss: 1.5024 - val_mae: 0.9946\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 1.47870\n",
      "Epoch 691/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4031 - mae: 0.9438 - val_loss: 1.5020 - val_mae: 0.9948\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 1.47870\n",
      "Epoch 692/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3957 - mae: 0.9272 - val_loss: 1.4953 - val_mae: 0.9919\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 1.47870\n",
      "Epoch 693/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4131 - mae: 0.9255 - val_loss: 1.4961 - val_mae: 0.9921\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 1.47870\n",
      "Epoch 694/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.5295 - mae: 0.9729 - val_loss: 1.4936 - val_mae: 0.9911\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 1.47870\n",
      "Epoch 695/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.5298 - mae: 0.9841 - val_loss: 1.4944 - val_mae: 0.9926\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 1.47870\n",
      "Epoch 696/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4571 - mae: 0.9662 - val_loss: 1.4956 - val_mae: 0.9938\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 1.47870\n",
      "Epoch 697/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4220 - mae: 0.9453 - val_loss: 1.4923 - val_mae: 0.9918\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 1.47870\n",
      "Epoch 698/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.4882 - mae: 0.9736 - val_loss: 1.4945 - val_mae: 0.9932\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 1.47870\n",
      "Epoch 699/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.4608 - mae: 0.9633 - val_loss: 1.4948 - val_mae: 0.9939\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 1.47870\n",
      "Epoch 700/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4756 - mae: 0.9637 - val_loss: 1.4896 - val_mae: 0.9930\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 1.47870\n",
      "Epoch 701/1000\n",
      "633/633 [==============================] - 0s 169us/step - loss: 1.3758 - mae: 0.9352 - val_loss: 1.4875 - val_mae: 0.9918\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 1.47870\n",
      "Epoch 702/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.3914 - mae: 0.9208 - val_loss: 1.4891 - val_mae: 0.9924\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 1.47870\n",
      "Epoch 703/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.4574 - mae: 0.9504 - val_loss: 1.4862 - val_mae: 0.9916\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 1.47870\n",
      "Epoch 704/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4654 - mae: 0.9421 - val_loss: 1.4841 - val_mae: 0.9909\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 1.47870\n",
      "Epoch 705/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4453 - mae: 0.9323 - val_loss: 1.4811 - val_mae: 0.9910\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 1.47870\n",
      "Epoch 706/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.4521 - mae: 0.9402 - val_loss: 1.4838 - val_mae: 0.9911\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 1.47870\n",
      "Epoch 707/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.4289 - mae: 0.9474 - val_loss: 1.4874 - val_mae: 0.9926\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 1.47870\n",
      "Epoch 708/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.4568 - mae: 0.9384 - val_loss: 1.4806 - val_mae: 0.9904\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 1.47870\n",
      "Epoch 709/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.4995 - mae: 0.9590 - val_loss: 1.4828 - val_mae: 0.9917\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 1.47870\n",
      "Epoch 710/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4896 - mae: 0.9710 - val_loss: 1.4821 - val_mae: 0.9910\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 1.47870\n",
      "Epoch 711/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.4608 - mae: 0.9525 - val_loss: 1.4852 - val_mae: 0.9925\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 1.47870\n",
      "Epoch 712/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4363 - mae: 0.9500 - val_loss: 1.4862 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 1.47870\n",
      "Epoch 713/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4030 - mae: 0.9318 - val_loss: 1.4835 - val_mae: 0.9913\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 1.47870\n",
      "Epoch 714/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.5439 - mae: 0.9855 - val_loss: 1.4877 - val_mae: 0.9931\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 1.47870\n",
      "Epoch 715/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4451 - mae: 0.9438 - val_loss: 1.4837 - val_mae: 0.9914\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 1.47870\n",
      "Epoch 716/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.5075 - mae: 0.9667 - val_loss: 1.4854 - val_mae: 0.9918\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 1.47870\n",
      "Epoch 717/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.5119 - mae: 0.9672 - val_loss: 1.4876 - val_mae: 0.9924\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 1.47870\n",
      "Epoch 718/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.4200 - mae: 0.9441 - val_loss: 1.4905 - val_mae: 0.9925\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 1.47870\n",
      "Epoch 719/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4042 - mae: 0.9362 - val_loss: 1.4869 - val_mae: 0.9917\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 1.47870\n",
      "Epoch 720/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3561 - mae: 0.9250 - val_loss: 1.4918 - val_mae: 0.9923\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 1.47870\n",
      "Epoch 721/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.3288 - mae: 0.9097 - val_loss: 1.4940 - val_mae: 0.9927\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 1.47870\n",
      "Epoch 722/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3748 - mae: 0.9294 - val_loss: 1.4926 - val_mae: 0.9926\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 1.47870\n",
      "Epoch 723/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4749 - mae: 0.9577 - val_loss: 1.4897 - val_mae: 0.9918\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 1.47870\n",
      "Epoch 724/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3746 - mae: 0.9116 - val_loss: 1.4933 - val_mae: 0.9935\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 1.47870\n",
      "Epoch 725/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3489 - mae: 0.9108 - val_loss: 1.4923 - val_mae: 0.9927\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 1.47870\n",
      "Epoch 726/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.4352 - mae: 0.9414 - val_loss: 1.4980 - val_mae: 0.9944\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 1.47870\n",
      "Epoch 727/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.5004 - mae: 0.9599 - val_loss: 1.4978 - val_mae: 0.9930\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 1.47870\n",
      "Epoch 728/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4471 - mae: 0.9447 - val_loss: 1.4907 - val_mae: 0.9912\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 1.47870\n",
      "Epoch 729/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4813 - mae: 0.9483 - val_loss: 1.4899 - val_mae: 0.9915\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 1.47870\n",
      "Epoch 730/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4381 - mae: 0.9417 - val_loss: 1.4916 - val_mae: 0.9928\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 1.47870\n",
      "Epoch 731/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.5009 - mae: 0.9711 - val_loss: 1.4887 - val_mae: 0.9917\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 1.47870\n",
      "Epoch 732/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4636 - mae: 0.9643 - val_loss: 1.4851 - val_mae: 0.9917\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 1.47870\n",
      "Epoch 733/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3416 - mae: 0.9099 - val_loss: 1.4833 - val_mae: 0.9904\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 1.47870\n",
      "Epoch 734/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3801 - mae: 0.9314 - val_loss: 1.4836 - val_mae: 0.9915\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 1.47870\n",
      "Epoch 735/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4697 - mae: 0.9613 - val_loss: 1.4835 - val_mae: 0.9908\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 1.47870\n",
      "Epoch 736/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.3902 - mae: 0.9361 - val_loss: 1.4840 - val_mae: 0.9915\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 1.47870\n",
      "Epoch 737/1000\n",
      "633/633 [==============================] - 0s 169us/step - loss: 1.4472 - mae: 0.9569 - val_loss: 1.4828 - val_mae: 0.9893\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 1.47870\n",
      "Epoch 738/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4489 - mae: 0.9469 - val_loss: 1.4791 - val_mae: 0.9878\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 1.47870\n",
      "Epoch 739/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4742 - mae: 0.9375 - val_loss: 1.4848 - val_mae: 0.9894\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 1.47870\n",
      "Epoch 740/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4815 - mae: 0.9588 - val_loss: 1.4838 - val_mae: 0.9902\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 1.47870\n",
      "Epoch 741/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.4696 - mae: 0.9576 - val_loss: 1.4810 - val_mae: 0.9888\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 1.47870\n",
      "Epoch 742/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.3735 - mae: 0.9200 - val_loss: 1.4848 - val_mae: 0.9899\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 1.47870\n",
      "Epoch 743/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4715 - mae: 0.9483 - val_loss: 1.4811 - val_mae: 0.9894\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 1.47870\n",
      "Epoch 744/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.4214 - mae: 0.9312 - val_loss: 1.4834 - val_mae: 0.9915\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 1.47870\n",
      "Epoch 745/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4916 - mae: 0.9782 - val_loss: 1.4781 - val_mae: 0.9900\n",
      "\n",
      "Epoch 00745: val_loss improved from 1.47870 to 1.47809, saving model to model.sve\n",
      "Epoch 746/1000\n",
      "633/633 [==============================] - 0s 195us/step - loss: 1.4303 - mae: 0.9295 - val_loss: 1.4834 - val_mae: 0.9915\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 1.47809\n",
      "Epoch 747/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.4867 - mae: 0.9521 - val_loss: 1.4834 - val_mae: 0.9909\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 1.47809\n",
      "Epoch 748/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3991 - mae: 0.9342 - val_loss: 1.4851 - val_mae: 0.9919\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 1.47809\n",
      "Epoch 749/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.4403 - mae: 0.9516 - val_loss: 1.4863 - val_mae: 0.9925\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 1.47809\n",
      "Epoch 750/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3386 - mae: 0.9074 - val_loss: 1.4882 - val_mae: 0.9927\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 1.47809\n",
      "Epoch 751/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.4281 - mae: 0.9461 - val_loss: 1.4904 - val_mae: 0.9936\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 1.47809\n",
      "Epoch 752/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4856 - mae: 0.9603 - val_loss: 1.4901 - val_mae: 0.9932\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 1.47809\n",
      "Epoch 753/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3643 - mae: 0.9170 - val_loss: 1.4885 - val_mae: 0.9919\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 1.47809\n",
      "Epoch 754/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4209 - mae: 0.9258 - val_loss: 1.4889 - val_mae: 0.9923\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 1.47809\n",
      "Epoch 755/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4431 - mae: 0.9520 - val_loss: 1.4885 - val_mae: 0.9922\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 1.47809\n",
      "Epoch 756/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.3918 - mae: 0.9260 - val_loss: 1.4864 - val_mae: 0.9917\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 1.47809\n",
      "Epoch 757/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4133 - mae: 0.9415 - val_loss: 1.4876 - val_mae: 0.9916\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 1.47809\n",
      "Epoch 758/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3892 - mae: 0.9295 - val_loss: 1.4912 - val_mae: 0.9932\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 1.47809\n",
      "Epoch 759/1000\n",
      "633/633 [==============================] - 0s 225us/step - loss: 1.5076 - mae: 0.9796 - val_loss: 1.4912 - val_mae: 0.9936\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 1.47809\n",
      "Epoch 760/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.4336 - mae: 0.9444 - val_loss: 1.4927 - val_mae: 0.9941\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 1.47809\n",
      "Epoch 761/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.4411 - mae: 0.9597 - val_loss: 1.4937 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 1.47809\n",
      "Epoch 762/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.4079 - mae: 0.9467 - val_loss: 1.4920 - val_mae: 0.9945\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 1.47809\n",
      "Epoch 763/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3866 - mae: 0.9296 - val_loss: 1.4833 - val_mae: 0.9916\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 1.47809\n",
      "Epoch 764/1000\n",
      "633/633 [==============================] - 0s 193us/step - loss: 1.5704 - mae: 0.9786 - val_loss: 1.4756 - val_mae: 0.9887\n",
      "\n",
      "Epoch 00764: val_loss improved from 1.47809 to 1.47562, saving model to model.sve\n",
      "Epoch 765/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4627 - mae: 0.9556 - val_loss: 1.4734 - val_mae: 0.9889\n",
      "\n",
      "Epoch 00765: val_loss improved from 1.47562 to 1.47337, saving model to model.sve\n",
      "Epoch 766/1000\n",
      "633/633 [==============================] - 0s 195us/step - loss: 1.4642 - mae: 0.9486 - val_loss: 1.4709 - val_mae: 0.9880\n",
      "\n",
      "Epoch 00766: val_loss improved from 1.47337 to 1.47094, saving model to model.sve\n",
      "Epoch 767/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.4047 - mae: 0.9290 - val_loss: 1.4699 - val_mae: 0.9873\n",
      "\n",
      "Epoch 00767: val_loss improved from 1.47094 to 1.46992, saving model to model.sve\n",
      "Epoch 768/1000\n",
      "633/633 [==============================] - 0s 221us/step - loss: 1.2914 - mae: 0.8846 - val_loss: 1.4772 - val_mae: 0.9897\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 1.46992\n",
      "Epoch 769/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4700 - mae: 0.9527 - val_loss: 1.4773 - val_mae: 0.9898\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 1.46992\n",
      "Epoch 770/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.3182 - mae: 0.8938 - val_loss: 1.4863 - val_mae: 0.9945\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 1.46992\n",
      "Epoch 771/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.3050 - mae: 0.8918 - val_loss: 1.4871 - val_mae: 0.9951\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 1.46992\n",
      "Epoch 772/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.3354 - mae: 0.9076 - val_loss: 1.4851 - val_mae: 0.9951\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 1.46992\n",
      "Epoch 773/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4411 - mae: 0.9613 - val_loss: 1.4859 - val_mae: 0.9942\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 1.46992\n",
      "Epoch 774/1000\n",
      "633/633 [==============================] - 0s 212us/step - loss: 1.4134 - mae: 0.9256 - val_loss: 1.4879 - val_mae: 0.9946\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 1.46992\n",
      "Epoch 775/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3509 - mae: 0.9106 - val_loss: 1.4864 - val_mae: 0.9940\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 1.46992\n",
      "Epoch 776/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.3294 - mae: 0.9146 - val_loss: 1.4875 - val_mae: 0.9948\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 1.46992\n",
      "Epoch 777/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.4169 - mae: 0.9405 - val_loss: 1.4870 - val_mae: 0.9954\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 1.46992\n",
      "Epoch 778/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4072 - mae: 0.9398 - val_loss: 1.4912 - val_mae: 0.9957\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 1.46992\n",
      "Epoch 779/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3979 - mae: 0.9244 - val_loss: 1.4856 - val_mae: 0.9947\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 1.46992\n",
      "Epoch 780/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.4054 - mae: 0.9262 - val_loss: 1.4827 - val_mae: 0.9936\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 1.46992\n",
      "Epoch 781/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4163 - mae: 0.9353 - val_loss: 1.4895 - val_mae: 0.9951\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 1.46992\n",
      "Epoch 782/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3648 - mae: 0.9251 - val_loss: 1.4912 - val_mae: 0.9951\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 1.46992\n",
      "Epoch 783/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3115 - mae: 0.9064 - val_loss: 1.4946 - val_mae: 0.9955\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 1.46992\n",
      "Epoch 784/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.3853 - mae: 0.9388 - val_loss: 1.4906 - val_mae: 0.9946\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 1.46992\n",
      "Epoch 785/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.4128 - mae: 0.9388 - val_loss: 1.4906 - val_mae: 0.9952\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 1.46992\n",
      "Epoch 786/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4385 - mae: 0.9455 - val_loss: 1.4873 - val_mae: 0.9938\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 1.46992\n",
      "Epoch 787/1000\n",
      "633/633 [==============================] - 0s 195us/step - loss: 1.3939 - mae: 0.9304 - val_loss: 1.4853 - val_mae: 0.9931\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 1.46992\n",
      "Epoch 788/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.4427 - mae: 0.9473 - val_loss: 1.4850 - val_mae: 0.9926\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 1.46992\n",
      "Epoch 789/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4435 - mae: 0.9603 - val_loss: 1.4842 - val_mae: 0.9935\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 1.46992\n",
      "Epoch 790/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4756 - mae: 0.9590 - val_loss: 1.4833 - val_mae: 0.9926\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 1.46992\n",
      "Epoch 791/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.2859 - mae: 0.8926 - val_loss: 1.4774 - val_mae: 0.9914\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 1.46992\n",
      "Epoch 792/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.3005 - mae: 0.9061 - val_loss: 1.4796 - val_mae: 0.9934\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 1.46992\n",
      "Epoch 793/1000\n",
      "633/633 [==============================] - 0s 168us/step - loss: 1.3502 - mae: 0.9103 - val_loss: 1.4814 - val_mae: 0.9952\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 1.46992\n",
      "Epoch 794/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.3313 - mae: 0.9183 - val_loss: 1.4860 - val_mae: 0.9961\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 1.46992\n",
      "Epoch 795/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.3847 - mae: 0.9280 - val_loss: 1.4860 - val_mae: 0.9961\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 1.46992\n",
      "Epoch 796/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.3343 - mae: 0.9253 - val_loss: 1.4929 - val_mae: 0.9981\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 1.46992\n",
      "Epoch 797/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.3997 - mae: 0.9350 - val_loss: 1.4927 - val_mae: 0.9983\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 1.46992\n",
      "Epoch 798/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3346 - mae: 0.9085 - val_loss: 1.4884 - val_mae: 0.9957\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 1.46992\n",
      "Epoch 799/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3138 - mae: 0.9080 - val_loss: 1.4931 - val_mae: 0.9982\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 1.46992\n",
      "Epoch 800/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3921 - mae: 0.9205 - val_loss: 1.4864 - val_mae: 0.9950\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 1.46992\n",
      "Epoch 801/1000\n",
      "633/633 [==============================] - 0s 169us/step - loss: 1.4332 - mae: 0.9385 - val_loss: 1.4837 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 1.46992\n",
      "Epoch 802/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3533 - mae: 0.9315 - val_loss: 1.4865 - val_mae: 0.9953\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 1.46992\n",
      "Epoch 803/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.3998 - mae: 0.9377 - val_loss: 1.4909 - val_mae: 0.9969\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 1.46992\n",
      "Epoch 804/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.3781 - mae: 0.9318 - val_loss: 1.4972 - val_mae: 1.0004\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 1.46992\n",
      "Epoch 805/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3134 - mae: 0.9047 - val_loss: 1.4884 - val_mae: 0.9970\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 1.46992\n",
      "Epoch 806/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3910 - mae: 0.9213 - val_loss: 1.4893 - val_mae: 0.9974\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 1.46992\n",
      "Epoch 807/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4383 - mae: 0.9476 - val_loss: 1.4862 - val_mae: 0.9981\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 1.46992\n",
      "Epoch 808/1000\n",
      "633/633 [==============================] - 0s 191us/step - loss: 1.3761 - mae: 0.9142 - val_loss: 1.4888 - val_mae: 0.9980\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 1.46992\n",
      "Epoch 809/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3487 - mae: 0.9100 - val_loss: 1.4919 - val_mae: 0.9978\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 1.46992\n",
      "Epoch 810/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3438 - mae: 0.9073 - val_loss: 1.4955 - val_mae: 0.9992\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 1.46992\n",
      "Epoch 811/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.4236 - mae: 0.9421 - val_loss: 1.4899 - val_mae: 0.9970\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 1.46992\n",
      "Epoch 812/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.4364 - mae: 0.9436 - val_loss: 1.4918 - val_mae: 0.9984\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 1.46992\n",
      "Epoch 813/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.4100 - mae: 0.9272 - val_loss: 1.4919 - val_mae: 0.9995\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 1.46992\n",
      "Epoch 814/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4783 - mae: 0.9555 - val_loss: 1.4888 - val_mae: 0.9996\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 1.46992\n",
      "Epoch 815/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4162 - mae: 0.9367 - val_loss: 1.4882 - val_mae: 0.9989\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 1.46992\n",
      "Epoch 816/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.4128 - mae: 0.9319 - val_loss: 1.4889 - val_mae: 0.9992\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 1.46992\n",
      "Epoch 817/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3059 - mae: 0.9011 - val_loss: 1.4901 - val_mae: 0.9990\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 1.46992\n",
      "Epoch 818/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.4149 - mae: 0.9236 - val_loss: 1.4940 - val_mae: 1.0006\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 1.46992\n",
      "Epoch 819/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3594 - mae: 0.9167 - val_loss: 1.4899 - val_mae: 0.9994\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 1.46992\n",
      "Epoch 820/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3700 - mae: 0.9160 - val_loss: 1.4943 - val_mae: 1.0008\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 1.46992\n",
      "Epoch 821/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.3762 - mae: 0.9281 - val_loss: 1.4928 - val_mae: 1.0002\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 1.46992\n",
      "Epoch 822/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.3816 - mae: 0.9322 - val_loss: 1.4899 - val_mae: 0.9997\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 1.46992\n",
      "Epoch 823/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3669 - mae: 0.9206 - val_loss: 1.4825 - val_mae: 0.9967\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 1.46992\n",
      "Epoch 824/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3842 - mae: 0.9305 - val_loss: 1.4864 - val_mae: 0.9983\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 1.46992\n",
      "Epoch 825/1000\n",
      "633/633 [==============================] - 0s 220us/step - loss: 1.3813 - mae: 0.9244 - val_loss: 1.4820 - val_mae: 0.9972\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 1.46992\n",
      "Epoch 826/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.5278 - mae: 0.9921 - val_loss: 1.4810 - val_mae: 0.9959\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 1.46992\n",
      "Epoch 827/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.4814 - mae: 0.9662 - val_loss: 1.4786 - val_mae: 0.9940\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 1.46992\n",
      "Epoch 828/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.4157 - mae: 0.9388 - val_loss: 1.4802 - val_mae: 0.9956\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 1.46992\n",
      "Epoch 829/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.3854 - mae: 0.9247 - val_loss: 1.4769 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 1.46992\n",
      "Epoch 830/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3812 - mae: 0.9346 - val_loss: 1.4694 - val_mae: 0.9907\n",
      "\n",
      "Epoch 00830: val_loss improved from 1.46992 to 1.46937, saving model to model.sve\n",
      "Epoch 831/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.3809 - mae: 0.9203 - val_loss: 1.4749 - val_mae: 0.9924\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 1.46937\n",
      "Epoch 832/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.4252 - mae: 0.9441 - val_loss: 1.4750 - val_mae: 0.9926\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 1.46937\n",
      "Epoch 833/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.4871 - mae: 0.9610 - val_loss: 1.4752 - val_mae: 0.9937\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 1.46937\n",
      "Epoch 834/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3802 - mae: 0.9152 - val_loss: 1.4742 - val_mae: 0.9938\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 1.46937\n",
      "Epoch 835/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.3248 - mae: 0.9076 - val_loss: 1.4754 - val_mae: 0.9939\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 1.46937\n",
      "Epoch 836/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.3303 - mae: 0.9108 - val_loss: 1.4810 - val_mae: 0.9948\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 1.46937\n",
      "Epoch 837/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3175 - mae: 0.9052 - val_loss: 1.4825 - val_mae: 0.9957\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 1.46937\n",
      "Epoch 838/1000\n",
      "633/633 [==============================] - 0s 205us/step - loss: 1.4240 - mae: 0.9428 - val_loss: 1.4832 - val_mae: 0.9957\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 1.46937\n",
      "Epoch 839/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.4334 - mae: 0.9562 - val_loss: 1.4803 - val_mae: 0.9940\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 1.46937\n",
      "Epoch 840/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4062 - mae: 0.9400 - val_loss: 1.4814 - val_mae: 0.9934\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 1.46937\n",
      "Epoch 841/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4281 - mae: 0.9481 - val_loss: 1.4797 - val_mae: 0.9930\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 1.46937\n",
      "Epoch 842/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3092 - mae: 0.8990 - val_loss: 1.4914 - val_mae: 0.9968\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 1.46937\n",
      "Epoch 843/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3899 - mae: 0.9377 - val_loss: 1.4988 - val_mae: 0.9992\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 1.46937\n",
      "Epoch 844/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.3589 - mae: 0.9143 - val_loss: 1.4934 - val_mae: 0.9966\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 1.46937\n",
      "Epoch 845/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3040 - mae: 0.9067 - val_loss: 1.4972 - val_mae: 0.9976\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 1.46937\n",
      "Epoch 846/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4286 - mae: 0.9436 - val_loss: 1.4954 - val_mae: 0.9970\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 1.46937\n",
      "Epoch 847/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 1.4217 - mae: 0.9230 - val_loss: 1.4929 - val_mae: 0.9974\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 1.46937\n",
      "Epoch 848/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3612 - mae: 0.9142 - val_loss: 1.4907 - val_mae: 0.9966\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 1.46937\n",
      "Epoch 849/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3277 - mae: 0.9102 - val_loss: 1.4982 - val_mae: 0.9988\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 1.46937\n",
      "Epoch 850/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.4174 - mae: 0.9394 - val_loss: 1.4859 - val_mae: 0.9952\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 1.46937\n",
      "Epoch 851/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3632 - mae: 0.9202 - val_loss: 1.4836 - val_mae: 0.9956\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 1.46937\n",
      "Epoch 852/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.2877 - mae: 0.9044 - val_loss: 1.4856 - val_mae: 0.9948\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 1.46937\n",
      "Epoch 853/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.3864 - mae: 0.9403 - val_loss: 1.4840 - val_mae: 0.9946\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 1.46937\n",
      "Epoch 854/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3810 - mae: 0.9166 - val_loss: 1.4926 - val_mae: 0.9977\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 1.46937\n",
      "Epoch 855/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.3488 - mae: 0.9135 - val_loss: 1.4943 - val_mae: 0.9980\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 1.46937\n",
      "Epoch 856/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3300 - mae: 0.9167 - val_loss: 1.4950 - val_mae: 0.9986\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 1.46937\n",
      "Epoch 857/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4014 - mae: 0.9308 - val_loss: 1.5010 - val_mae: 1.0009\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 1.46937\n",
      "Epoch 858/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.3505 - mae: 0.9245 - val_loss: 1.5000 - val_mae: 1.0006\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 1.46937\n",
      "Epoch 859/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.3393 - mae: 0.9150 - val_loss: 1.4994 - val_mae: 1.0008\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 1.46937\n",
      "Epoch 860/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3791 - mae: 0.9429 - val_loss: 1.5001 - val_mae: 1.0002\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 1.46937\n",
      "Epoch 861/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3635 - mae: 0.9349 - val_loss: 1.5007 - val_mae: 1.0003\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 1.46937\n",
      "Epoch 862/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.2699 - mae: 0.8903 - val_loss: 1.5063 - val_mae: 1.0023\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 1.46937\n",
      "Epoch 863/1000\n",
      "633/633 [==============================] - 0s 211us/step - loss: 1.3619 - mae: 0.9109 - val_loss: 1.5013 - val_mae: 1.0014\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 1.46937\n",
      "Epoch 864/1000\n",
      "633/633 [==============================] - 0s 197us/step - loss: 1.4097 - mae: 0.9391 - val_loss: 1.5043 - val_mae: 1.0020\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 1.46937\n",
      "Epoch 865/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4555 - mae: 0.9405 - val_loss: 1.4980 - val_mae: 1.0001\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 1.46937\n",
      "Epoch 866/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.3751 - mae: 0.9197 - val_loss: 1.4980 - val_mae: 1.0002\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 1.46937\n",
      "Epoch 867/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3302 - mae: 0.9049 - val_loss: 1.5058 - val_mae: 1.0019\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 1.46937\n",
      "Epoch 868/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3482 - mae: 0.9280 - val_loss: 1.5109 - val_mae: 1.0041\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 1.46937\n",
      "Epoch 869/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.4521 - mae: 0.9464 - val_loss: 1.5054 - val_mae: 1.0025\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 1.46937\n",
      "Epoch 870/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3903 - mae: 0.9217 - val_loss: 1.5013 - val_mae: 1.0016\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 1.46937\n",
      "Epoch 871/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3236 - mae: 0.9154 - val_loss: 1.4968 - val_mae: 1.0008\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 1.46937\n",
      "Epoch 872/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 1.3393 - mae: 0.9082 - val_loss: 1.5011 - val_mae: 1.0014\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 1.46937\n",
      "Epoch 873/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.4011 - mae: 0.9211 - val_loss: 1.4995 - val_mae: 0.9994\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 1.46937\n",
      "Epoch 874/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.3693 - mae: 0.9205 - val_loss: 1.4933 - val_mae: 0.9982\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 1.46937\n",
      "Epoch 875/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3517 - mae: 0.9069 - val_loss: 1.4940 - val_mae: 0.9990\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 1.46937\n",
      "Epoch 876/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3244 - mae: 0.9006 - val_loss: 1.4948 - val_mae: 0.9997\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 1.46937\n",
      "Epoch 877/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3755 - mae: 0.9109 - val_loss: 1.4961 - val_mae: 0.9999\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 1.46937\n",
      "Epoch 878/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3814 - mae: 0.9316 - val_loss: 1.4945 - val_mae: 0.9998\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 1.46937\n",
      "Epoch 879/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3787 - mae: 0.9169 - val_loss: 1.5029 - val_mae: 1.0039\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 1.46937\n",
      "Epoch 880/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.3361 - mae: 0.9118 - val_loss: 1.5062 - val_mae: 1.0047\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 1.46937\n",
      "Epoch 881/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3445 - mae: 0.9318 - val_loss: 1.5034 - val_mae: 1.0029\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 1.46937\n",
      "Epoch 882/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.4360 - mae: 0.9456 - val_loss: 1.5004 - val_mae: 1.0015\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 1.46937\n",
      "Epoch 883/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.3759 - mae: 0.9150 - val_loss: 1.5025 - val_mae: 1.0004\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 1.46937\n",
      "Epoch 884/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3519 - mae: 0.9164 - val_loss: 1.5050 - val_mae: 1.0011\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 1.46937\n",
      "Epoch 885/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4041 - mae: 0.9190 - val_loss: 1.5043 - val_mae: 1.0014\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 1.46937\n",
      "Epoch 886/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.3358 - mae: 0.9088 - val_loss: 1.5024 - val_mae: 1.0003\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 1.46937\n",
      "Epoch 887/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3905 - mae: 0.9313 - val_loss: 1.5087 - val_mae: 1.0033\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 1.46937\n",
      "Epoch 888/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3160 - mae: 0.9027 - val_loss: 1.5101 - val_mae: 1.0030\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 1.46937\n",
      "Epoch 889/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3884 - mae: 0.9266 - val_loss: 1.5082 - val_mae: 1.0022\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 1.46937\n",
      "Epoch 890/1000\n",
      "633/633 [==============================] - 0s 213us/step - loss: 1.2869 - mae: 0.8937 - val_loss: 1.5092 - val_mae: 1.0033\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 1.46937\n",
      "Epoch 891/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4630 - mae: 0.9620 - val_loss: 1.5039 - val_mae: 1.0015\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 1.46937\n",
      "Epoch 892/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.2612 - mae: 0.8822 - val_loss: 1.5080 - val_mae: 1.0036\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 1.46937\n",
      "Epoch 893/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3424 - mae: 0.9245 - val_loss: 1.5078 - val_mae: 1.0042\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 1.46937\n",
      "Epoch 894/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3556 - mae: 0.9191 - val_loss: 1.5101 - val_mae: 1.0048\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 1.46937\n",
      "Epoch 895/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3573 - mae: 0.8955 - val_loss: 1.5071 - val_mae: 1.0033\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 1.46937\n",
      "Epoch 896/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3789 - mae: 0.9383 - val_loss: 1.5042 - val_mae: 1.0011\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 1.46937\n",
      "Epoch 897/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3351 - mae: 0.9095 - val_loss: 1.5014 - val_mae: 1.0005\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 1.46937\n",
      "Epoch 898/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.4728 - mae: 0.9568 - val_loss: 1.5016 - val_mae: 1.0004\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 1.46937\n",
      "Epoch 899/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.4490 - mae: 0.9438 - val_loss: 1.4948 - val_mae: 0.9988\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 1.46937\n",
      "Epoch 900/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3274 - mae: 0.9141 - val_loss: 1.4983 - val_mae: 1.0001\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 1.46937\n",
      "Epoch 901/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3991 - mae: 0.9328 - val_loss: 1.5003 - val_mae: 1.0008\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 1.46937\n",
      "Epoch 902/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.2896 - mae: 0.8861 - val_loss: 1.5054 - val_mae: 1.0025\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 1.46937\n",
      "Epoch 903/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3146 - mae: 0.9010 - val_loss: 1.5092 - val_mae: 1.0032\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 1.46937\n",
      "Epoch 904/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.4403 - mae: 0.9341 - val_loss: 1.5114 - val_mae: 1.0038\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 1.46937\n",
      "Epoch 905/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.2742 - mae: 0.8984 - val_loss: 1.5198 - val_mae: 1.0070\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 1.46937\n",
      "Epoch 906/1000\n",
      "633/633 [==============================] - 0s 202us/step - loss: 1.3578 - mae: 0.9119 - val_loss: 1.5184 - val_mae: 1.0074\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 1.46937\n",
      "Epoch 907/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.3178 - mae: 0.8997 - val_loss: 1.5187 - val_mae: 1.0075\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 1.46937\n",
      "Epoch 908/1000\n",
      "633/633 [==============================] - 0s 203us/step - loss: 1.3260 - mae: 0.9118 - val_loss: 1.5125 - val_mae: 1.0052\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 1.46937\n",
      "Epoch 909/1000\n",
      "633/633 [==============================] - 0s 169us/step - loss: 1.2782 - mae: 0.8899 - val_loss: 1.5127 - val_mae: 1.0053\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 1.46937\n",
      "Epoch 910/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3505 - mae: 0.9070 - val_loss: 1.5126 - val_mae: 1.0048\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 1.46937\n",
      "Epoch 911/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3758 - mae: 0.9290 - val_loss: 1.5143 - val_mae: 1.0056\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 1.46937\n",
      "Epoch 912/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.2931 - mae: 0.8966 - val_loss: 1.5258 - val_mae: 1.0091\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 1.46937\n",
      "Epoch 913/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.3850 - mae: 0.9156 - val_loss: 1.5192 - val_mae: 1.0081\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 1.46937\n",
      "Epoch 914/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3240 - mae: 0.9035 - val_loss: 1.5250 - val_mae: 1.0099\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 1.46937\n",
      "Epoch 915/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.4008 - mae: 0.9343 - val_loss: 1.5296 - val_mae: 1.0117\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 1.46937\n",
      "Epoch 916/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.2975 - mae: 0.8769 - val_loss: 1.5233 - val_mae: 1.0101\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 1.46937\n",
      "Epoch 917/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.3729 - mae: 0.9252 - val_loss: 1.5210 - val_mae: 1.0095\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 1.46937\n",
      "Epoch 918/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3479 - mae: 0.9131 - val_loss: 1.5196 - val_mae: 1.0089\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 1.46937\n",
      "Epoch 919/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4130 - mae: 0.9333 - val_loss: 1.5119 - val_mae: 1.0059\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 1.46937\n",
      "Epoch 920/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.3054 - mae: 0.8984 - val_loss: 1.5101 - val_mae: 1.0064\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 1.46937\n",
      "Epoch 921/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.3294 - mae: 0.9230 - val_loss: 1.5078 - val_mae: 1.0057\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 1.46937\n",
      "Epoch 922/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3671 - mae: 0.9188 - val_loss: 1.5114 - val_mae: 1.0073\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 1.46937\n",
      "Epoch 923/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3995 - mae: 0.9352 - val_loss: 1.5061 - val_mae: 1.0063\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 1.46937\n",
      "Epoch 924/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.2402 - mae: 0.8814 - val_loss: 1.5059 - val_mae: 1.0073\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 1.46937\n",
      "Epoch 925/1000\n",
      "633/633 [==============================] - 0s 194us/step - loss: 1.3102 - mae: 0.9162 - val_loss: 1.5163 - val_mae: 1.0101\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 1.46937\n",
      "Epoch 926/1000\n",
      "633/633 [==============================] - 0s 181us/step - loss: 1.3998 - mae: 0.9227 - val_loss: 1.5127 - val_mae: 1.0087\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 1.46937\n",
      "Epoch 927/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3417 - mae: 0.9014 - val_loss: 1.5168 - val_mae: 1.0099\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 1.46937\n",
      "Epoch 928/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.3621 - mae: 0.9159 - val_loss: 1.5155 - val_mae: 1.0088\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 1.46937\n",
      "Epoch 929/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4305 - mae: 0.9346 - val_loss: 1.5117 - val_mae: 1.0069\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 1.46937\n",
      "Epoch 930/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.3829 - mae: 0.9255 - val_loss: 1.5045 - val_mae: 1.0047\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 1.46937\n",
      "Epoch 931/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3141 - mae: 0.9179 - val_loss: 1.5068 - val_mae: 1.0065\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 1.46937\n",
      "Epoch 932/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.4503 - mae: 0.9401 - val_loss: 1.4997 - val_mae: 1.0047\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 1.46937\n",
      "Epoch 933/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3876 - mae: 0.9226 - val_loss: 1.4961 - val_mae: 1.0036\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 1.46937\n",
      "Epoch 934/1000\n",
      "633/633 [==============================] - 0s 186us/step - loss: 1.3270 - mae: 0.8930 - val_loss: 1.4923 - val_mae: 1.0007\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 1.46937\n",
      "Epoch 935/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.4134 - mae: 0.9272 - val_loss: 1.4947 - val_mae: 1.0008\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 1.46937\n",
      "Epoch 936/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3111 - mae: 0.8936 - val_loss: 1.4984 - val_mae: 1.0015\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 1.46937\n",
      "Epoch 937/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3649 - mae: 0.9267 - val_loss: 1.4997 - val_mae: 1.0015\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 1.46937\n",
      "Epoch 938/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3643 - mae: 0.9176 - val_loss: 1.5016 - val_mae: 1.0019\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 1.46937\n",
      "Epoch 939/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3473 - mae: 0.9247 - val_loss: 1.5001 - val_mae: 1.0011\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 1.46937\n",
      "Epoch 940/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3806 - mae: 0.9237 - val_loss: 1.5023 - val_mae: 1.0006\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 1.46937\n",
      "Epoch 941/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3289 - mae: 0.9160 - val_loss: 1.5035 - val_mae: 1.0025\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 1.46937\n",
      "Epoch 942/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.4065 - mae: 0.9272 - val_loss: 1.5040 - val_mae: 1.0026\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 1.46937\n",
      "Epoch 943/1000\n",
      "633/633 [==============================] - 0s 204us/step - loss: 1.3677 - mae: 0.9238 - val_loss: 1.5063 - val_mae: 1.0041\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 1.46937\n",
      "Epoch 944/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3484 - mae: 0.9312 - val_loss: 1.5030 - val_mae: 1.0018\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 1.46937\n",
      "Epoch 945/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3160 - mae: 0.9079 - val_loss: 1.5066 - val_mae: 1.0025\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 1.46937\n",
      "Epoch 946/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.4002 - mae: 0.9349 - val_loss: 1.5114 - val_mae: 1.0041\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 1.46937\n",
      "Epoch 947/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.2787 - mae: 0.9039 - val_loss: 1.5072 - val_mae: 1.0026\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 1.46937\n",
      "Epoch 948/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.3950 - mae: 0.9310 - val_loss: 1.5040 - val_mae: 1.0013\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 1.46937\n",
      "Epoch 949/1000\n",
      "633/633 [==============================] - 0s 189us/step - loss: 1.3261 - mae: 0.9101 - val_loss: 1.5026 - val_mae: 1.0010\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 1.46937\n",
      "Epoch 950/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3559 - mae: 0.9089 - val_loss: 1.5072 - val_mae: 1.0031\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 1.46937\n",
      "Epoch 951/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.2942 - mae: 0.9097 - val_loss: 1.5077 - val_mae: 1.0028\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 1.46937\n",
      "Epoch 952/1000\n",
      "633/633 [==============================] - 0s 196us/step - loss: 1.3205 - mae: 0.9023 - val_loss: 1.5015 - val_mae: 1.0012\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 1.46937\n",
      "Epoch 953/1000\n",
      "633/633 [==============================] - 0s 202us/step - loss: 1.3145 - mae: 0.8987 - val_loss: 1.5035 - val_mae: 1.0027\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 1.46937\n",
      "Epoch 954/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.2934 - mae: 0.8991 - val_loss: 1.5131 - val_mae: 1.0059\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 1.46937\n",
      "Epoch 955/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3571 - mae: 0.9000 - val_loss: 1.5104 - val_mae: 1.0055\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 1.46937\n",
      "Epoch 956/1000\n",
      "633/633 [==============================] - 0s 184us/step - loss: 1.3989 - mae: 0.9239 - val_loss: 1.5083 - val_mae: 1.0036\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 1.46937\n",
      "Epoch 957/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3288 - mae: 0.9167 - val_loss: 1.5173 - val_mae: 1.0054\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 1.46937\n",
      "Epoch 958/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.2776 - mae: 0.8917 - val_loss: 1.5181 - val_mae: 1.0057\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 1.46937\n",
      "Epoch 959/1000\n",
      "633/633 [==============================] - 0s 185us/step - loss: 1.3848 - mae: 0.9045 - val_loss: 1.5163 - val_mae: 1.0054\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 1.46937\n",
      "Epoch 960/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3054 - mae: 0.9122 - val_loss: 1.5170 - val_mae: 1.0063\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 1.46937\n",
      "Epoch 961/1000\n",
      "633/633 [==============================] - 0s 190us/step - loss: 1.3705 - mae: 0.9136 - val_loss: 1.5154 - val_mae: 1.0055\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 1.46937\n",
      "Epoch 962/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3238 - mae: 0.9022 - val_loss: 1.5087 - val_mae: 1.0023\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 1.46937\n",
      "Epoch 963/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3383 - mae: 0.9248 - val_loss: 1.5071 - val_mae: 1.0017\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 1.46937\n",
      "Epoch 964/1000\n",
      "633/633 [==============================] - 0s 201us/step - loss: 1.3407 - mae: 0.9096 - val_loss: 1.5061 - val_mae: 1.0023\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 1.46937\n",
      "Epoch 965/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.3975 - mae: 0.9335 - val_loss: 1.5123 - val_mae: 1.0063\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 1.46937\n",
      "Epoch 966/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.3886 - mae: 0.9306 - val_loss: 1.5088 - val_mae: 1.0043\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 1.46937\n",
      "Epoch 967/1000\n",
      "633/633 [==============================] - 0s 175us/step - loss: 1.3830 - mae: 0.9213 - val_loss: 1.5103 - val_mae: 1.0054\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 1.46937\n",
      "Epoch 968/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.3404 - mae: 0.9149 - val_loss: 1.5145 - val_mae: 1.0074\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 1.46937\n",
      "Epoch 969/1000\n",
      "633/633 [==============================] - 0s 192us/step - loss: 1.4285 - mae: 0.9381 - val_loss: 1.5100 - val_mae: 1.0061\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 1.46937\n",
      "Epoch 970/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3096 - mae: 0.8830 - val_loss: 1.5125 - val_mae: 1.0072\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 1.46937\n",
      "Epoch 971/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.3507 - mae: 0.9061 - val_loss: 1.5092 - val_mae: 1.0061\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 1.46937\n",
      "Epoch 972/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3635 - mae: 0.9204 - val_loss: 1.5055 - val_mae: 1.0051\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 1.46937\n",
      "Epoch 973/1000\n",
      "633/633 [==============================] - 0s 171us/step - loss: 1.2722 - mae: 0.8872 - val_loss: 1.5053 - val_mae: 1.0051\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 1.46937\n",
      "Epoch 974/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.3713 - mae: 0.9175 - val_loss: 1.5017 - val_mae: 1.0042\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 1.46937\n",
      "Epoch 975/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3784 - mae: 0.9363 - val_loss: 1.5033 - val_mae: 1.0044\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 1.46937\n",
      "Epoch 976/1000\n",
      "633/633 [==============================] - 0s 173us/step - loss: 1.2706 - mae: 0.8784 - val_loss: 1.5155 - val_mae: 1.0073\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 1.46937\n",
      "Epoch 977/1000\n",
      "633/633 [==============================] - 0s 170us/step - loss: 1.3356 - mae: 0.9087 - val_loss: 1.5176 - val_mae: 1.0079\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 1.46937\n",
      "Epoch 978/1000\n",
      "633/633 [==============================] - 0s 201us/step - loss: 1.2894 - mae: 0.8992 - val_loss: 1.5232 - val_mae: 1.0103\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 1.46937\n",
      "Epoch 979/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.3049 - mae: 0.8911 - val_loss: 1.5204 - val_mae: 1.0083\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 1.46937\n",
      "Epoch 980/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3157 - mae: 0.9098 - val_loss: 1.5219 - val_mae: 1.0085\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 1.46937\n",
      "Epoch 981/1000\n",
      "633/633 [==============================] - 0s 195us/step - loss: 1.2779 - mae: 0.8833 - val_loss: 1.5262 - val_mae: 1.0105\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 1.46937\n",
      "Epoch 982/1000\n",
      "633/633 [==============================] - 0s 176us/step - loss: 1.3387 - mae: 0.9121 - val_loss: 1.5255 - val_mae: 1.0104\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 1.46937\n",
      "Epoch 983/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.2860 - mae: 0.8903 - val_loss: 1.5188 - val_mae: 1.0083\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 1.46937\n",
      "Epoch 984/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3090 - mae: 0.9145 - val_loss: 1.5166 - val_mae: 1.0084\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 1.46937\n",
      "Epoch 985/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.2744 - mae: 0.8868 - val_loss: 1.5193 - val_mae: 1.0087\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 1.46937\n",
      "Epoch 986/1000\n",
      "633/633 [==============================] - 0s 174us/step - loss: 1.2585 - mae: 0.8761 - val_loss: 1.5200 - val_mae: 1.0092\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 1.46937\n",
      "Epoch 987/1000\n",
      "633/633 [==============================] - 0s 205us/step - loss: 1.3517 - mae: 0.9261 - val_loss: 1.5169 - val_mae: 1.0084\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 1.46937\n",
      "Epoch 988/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3174 - mae: 0.9046 - val_loss: 1.5225 - val_mae: 1.0097\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 1.46937\n",
      "Epoch 989/1000\n",
      "633/633 [==============================] - 0s 183us/step - loss: 1.3553 - mae: 0.9107 - val_loss: 1.5191 - val_mae: 1.0089\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 1.46937\n",
      "Epoch 990/1000\n",
      "633/633 [==============================] - 0s 179us/step - loss: 1.3565 - mae: 0.9184 - val_loss: 1.5169 - val_mae: 1.0098\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 1.46937\n",
      "Epoch 991/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3608 - mae: 0.9139 - val_loss: 1.5185 - val_mae: 1.0106\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 1.46937\n",
      "Epoch 992/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.3263 - mae: 0.9057 - val_loss: 1.5210 - val_mae: 1.0105\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 1.46937\n",
      "Epoch 993/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3275 - mae: 0.9062 - val_loss: 1.5185 - val_mae: 1.0102\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 1.46937\n",
      "Epoch 994/1000\n",
      "633/633 [==============================] - 0s 177us/step - loss: 1.3021 - mae: 0.8937 - val_loss: 1.5167 - val_mae: 1.0092\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 1.46937\n",
      "Epoch 995/1000\n",
      "633/633 [==============================] - 0s 180us/step - loss: 1.3126 - mae: 0.9097 - val_loss: 1.5220 - val_mae: 1.0127\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 1.46937\n",
      "Epoch 996/1000\n",
      "633/633 [==============================] - 0s 188us/step - loss: 1.3493 - mae: 0.9077 - val_loss: 1.5182 - val_mae: 1.0115\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 1.46937\n",
      "Epoch 997/1000\n",
      "633/633 [==============================] - 0s 182us/step - loss: 1.3489 - mae: 0.9031 - val_loss: 1.5189 - val_mae: 1.0119\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 1.46937\n",
      "Epoch 998/1000\n",
      "633/633 [==============================] - 0s 178us/step - loss: 1.2545 - mae: 0.8904 - val_loss: 1.5153 - val_mae: 1.0100\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 1.46937\n",
      "Epoch 999/1000\n",
      "633/633 [==============================] - 0s 172us/step - loss: 1.3087 - mae: 0.9032 - val_loss: 1.5184 - val_mae: 1.0114\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 1.46937\n",
      "Epoch 1000/1000\n",
      "633/633 [==============================] - 0s 187us/step - loss: 1.2806 - mae: 0.8992 - val_loss: 1.5264 - val_mae: 1.0134\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 1.46937\n"
     ]
    }
   ],
   "source": [
    "history = keras_model.fit(scaled_X_Kmeans, np.array(y_train), epochs=1000, \n",
    "                          validation_split=0.2, batch_size=32, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6s1edADUgAf2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4sLcY4SdgEY"
   },
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "Hqk-TZVtuXXg",
    "outputId": "cca5679a-40d1-4e57-dc31-8bc6c19edc46"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualize model loss\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3DEnRaYg4Jh"
   },
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)\n",
    "scaled_X_Kmeans_test = np.column_stack((scaled_X_test, km.predict(scaled_X_test).reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dU7CcAU1iKur"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XRavHKmgudFD",
    "outputId": "c67c9428-e2ab-42db-d08c-aed6e20eb630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 0s 493us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.49976976073567, 0.9685293436050415]"
      ]
     },
     "execution_count": 339,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_model = load_model(\"model.sve\")\n",
    "k_model.evaluate(scaled_X_Kmeans_test, np.array(y_test))\n",
    "\n",
    "###1.34 best fit (so far)\n",
    "###1.27 best fit (so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wMnUMSVDvD9y",
    "outputId": "53cf4a59-8711-4688-e697-b7d98b7b6267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1433584.105292253, 443942.24230036914)"
      ]
     },
     "execution_count": 340,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(10**np.array(y_test), \n",
    "                           10**k_model.predict(scaled_X_Kmeans_test))), mean_absolute_error(10**np.array(y_test), \n",
    "                           10**k_model.predict(scaled_X_Kmeans_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "656PCTNjiUrv"
   },
   "outputs": [],
   "source": [
    "10**k_model.predict(scaled_X_Kmeans_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N6wp946tlcPH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CN6jZveRihhR"
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "keras_json = k_model.to_json()\n",
    "\n",
    "with open(\"keras.json\", \"w\") as json_file:\n",
    "    json_file.write(keras_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "k_model.save_weights(\"keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "zTsZ5VVRPNot",
    "outputId": "78f8a010-97b1-4277-8900-a49a0c68724e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=5,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=4,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 175,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "clf = GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
    "                          init=None, learning_rate=0.1, loss='ls', max_depth=5,\n",
    "                          max_features=None, max_leaf_nodes=None,\n",
    "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                          min_samples_leaf=1, min_samples_split=4,\n",
    "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                          n_iter_no_change=None, presort='deprecated',\n",
    "                          random_state=None, subsample=1.0, tol=0.0001,\n",
    "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "clf.fit(scaled_X_Kmeans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "BDpfVOrovLe4",
    "outputId": "4d61003e-4226-4ac8-e041-ec60d1355741"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1342797.0610217627,\n",
       " 479837.92434069887,\n",
       " 1803103947088.6833,\n",
       " 320449.08122964506)"
      ]
     },
     "execution_count": 176,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test**2, \n",
    "                    clf.predict(scaled_X_Kmeans_test)**2)), mean_absolute_error(y_test**2, \n",
    "                    clf.predict(scaled_X_Kmeans_test)**2), mean_squared_error(y_test**2, \n",
    "                    clf.predict(scaled_X_Kmeans_test)**2), np.sqrt(mean_squared_error(y_train**2, clf.predict(scaled_X_Kmeans)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxbrh8kCG2z6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zeg6uYEKUH_c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXNYdLFv-aEV"
   },
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('GBM.model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syhgbG5HJ2iz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "cRqPT2qLJ3Zh",
    "outputId": "c4e64c8e-d75a-46e1-a037-05efde682a5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=4,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=500,\n",
       "                                                 n_ite...,\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=None,\n",
       "                                                 subsample=1.0, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [3, 4, 5, 6],\n",
       "                         'min_samples_split': [2, 3, 4],\n",
       "                         'n_estimators': [100, 300, 700, 900, 2000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 162,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "'''parameters = {'n_estimators':[100, 300, 700, 900, 2000], \n",
    "              'min_samples_split':[2, 3, 4], 'max_depth':[3, 4, 5, 6]\n",
    "              }\n",
    "\n",
    "clf = GridSearchCV(clf, parameters, scoring='neg_mean_squared_error')\n",
    "clf.fit(scaled_X_Kmeans, y_train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "a8BkQbY2J2fM",
    "outputId": "42525af5-008d-4f88-a552-29d1834da6d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=5,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=4,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ri9e1MnjoK0r"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "KR = KerasRegressor(build_model, epochs=466, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLF0LOkwXx8E"
   },
   "outputs": [],
   "source": [
    "KR.fit(scaled_X_Kmeans, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5qISCmr7dk_r"
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezRV0TZNnXX6"
   },
   "outputs": [],
   "source": [
    "cols = X_train.columns.tolist()\n",
    "cols.append('C_Label')\n",
    "\n",
    "### Feature Importances - GradientBoosting\n",
    "imp = permutation_importance(clf, scaled_X_Kmeans_test, \n",
    "                                                y_test, scoring='neg_mean_squared_error')\n",
    "\n",
    "\n",
    "imp = PermutationImportance(clf,n_iter=2).fit(scaled_X_Kmeans_test, y_test)\n",
    "eli5.show_weights(imp, feature_names = cols, top=scaled_X_Kmeans.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPYgtLZXaAK7"
   },
   "outputs": [],
   "source": [
    "### Feature Importances - ANN\n",
    "\n",
    "imp = permutation_importance(KR, scaled_X_Kmeans_test, \n",
    "                                                y_test, scoring='neg_mean_squared_error')\n",
    "\n",
    "imp = PermutationImportance(clf,n_iter=2).fit(scaled_X_Kmeans_test, y_test)\n",
    "eli5.show_weights(imp, feature_names = cols, top=scaled_X_Kmeans.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36dpKGmsMPeC"
   },
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x44NHec0I2IU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jo_dogzEI2Yb"
   },
   "outputs": [],
   "source": [
    "#data_dmatrix = xgb.DMatrix(data=scaled_X_Kmeans,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "PfECkws6JEy2",
    "outputId": "3f388558-67f3-45ee-a637-7de63dd0c427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.05, max_delta_step=0,\n",
       "             max_depth=7, min_child_weight=4, missing=None, n_estimators=500,\n",
       "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 174,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.05, max_delta_step=0,\n",
    "             max_depth=7, min_child_weight=4, missing=None, n_estimators=500,\n",
    "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
    "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "             seed=None, silent=None, subsample=0.8, verbosity=1)\n",
    "\n",
    "\n",
    "\n",
    "xg_reg.fit(scaled_X_Kmeans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "_DfIynxNUtlp",
    "outputId": "abb8c6e8-ca54-4789-84ac-e79f132f38ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=XGBRegressor(alpha=10, base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=0.2, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=4,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=1000, n_jobs=1, nthread=None,\n",
       "                                    objective='reg:squarederror',\n",
       "                                    random_sta...\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.7, 0.5, 0.8],\n",
       "                         'learning_rate': [0.03, 0.05, 0.07],\n",
       "                         'max_depth': [4, 5, 6, 7],\n",
       "                         'min_child_weight': [3, 4, 6],\n",
       "                         'n_estimators': [500, 700, 1000, 2000],\n",
       "                         'objective': ['reg:squarederror'],\n",
       "                         'subsample': [0.7, 0.6, 0.8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 169,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''parameters = {\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [4, 5, 6, 7],\n",
    "              'min_child_weight': [3, 4, 6],\n",
    "              'subsample': [0.7, 0.6, 0.8],\n",
    "              'colsample_bytree': [0.7, 0.5, 0.8],\n",
    "              'n_estimators': [500, 700, 1000, 2000]}\n",
    "\n",
    "xg_reg = GridSearchCV(xg_reg, parameters, scoring='neg_mean_squared_error')\n",
    "xg_reg.fit(scaled_X_Kmeans, y_train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "x2IspEOGUR8w",
    "outputId": "336952fe-1bad-4651-a1d0-4a0e71dd078a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.05, max_delta_step=0,\n",
       "             max_depth=7, min_child_weight=4, missing=None, n_estimators=500,\n",
       "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 170,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4lB_aHz2vUCa",
    "outputId": "dfbd6800-2f04-4c2c-c69d-9bddace66e81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1333414.2126299362, 487400.9387098868)"
      ]
     },
     "execution_count": 172,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test**2, \n",
    "                           xg_reg.predict(scaled_X_Kmeans_test)**2)), mean_absolute_error(y_test**2, \n",
    "                           xg_reg.predict(scaled_X_Kmeans_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E363cV7YvY0R"
   },
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('XGB.model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UhJrrhcKuHZ"
   },
   "outputs": [],
   "source": [
    "'''params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.4,'learning_rate': 0.1,\n",
    "                'max_depth':3, 'alpha': 10, 'n_estimators':2000}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, verbose_eval=1,\n",
    "                    num_boost_round=250,early_stopping_rounds=20,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "\n",
    "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=88)\n",
    "xgb_test = xgb.DMatrix(scaled_X_Kmeans_test)\n",
    "\n",
    "\n",
    "np.sqrt(mean_squared_error(10**y_test, \n",
    "                           10**xg_reg.predict(xgb_test)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pBtymEeMcnf"
   },
   "outputs": [],
   "source": [
    "xg_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anC2u-I7MvB6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KP42PNK_NS_V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3L-n8H_4Z7S"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "L_R = LinearRegression()\n",
    "#L_R.fit(scaled_X_Kmeans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4b-1Mwi74u55"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "SVM = SVR()\n",
    "#SVM.fit(scaled_X_Kmeans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s01dnLZ75RDr"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RF = RandomForestRegressor()\n",
    "#RF.fit(scaled_X_Kmeans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKUSEP6f7HC3"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRFRegressor\n",
    "XGB = XGBRFRegressor(n_estimators=2000, max_depth=4, learning_rate=0.1, \n",
    "                     objective ='reg:squarederror', colsample_bytree = 0.2)\n",
    "#XGB.fit(scaled_X_Kmeans, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-1hr8BMydZk"
   },
   "source": [
    "## Visualize Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpVAqCq6ynHY"
   },
   "outputs": [],
   "source": [
    "XGB_pred = pd.DataFrame({\"Pred\": y_test**2, \n",
    "              \"Actual\": XGB.predict(scaled_X_Kmeans_test)**2, \n",
    "              \"Residual\":(y_test**2) - (XGB.predict(scaled_X_Kmeans_test)**2)})\n",
    "\n",
    "print(ggplot(XGB_pred, aes(x='Actual', y='Pred'))\n",
    " + geom_point()\n",
    " + scale_x_log10()\n",
    " + scale_y_log10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HJcnhnlG21Od"
   },
   "outputs": [],
   "source": [
    "XGB_pred = pd.DataFrame({\"Pred\": y_test**2, \n",
    "              \"Actual\": xg_reg.predict(scaled_X_Kmeans_test)**2, \n",
    "              \"Residual\":(y_test**2) - (xg_reg.predict(scaled_X_Kmeans_test)**2)})\n",
    "\n",
    "\n",
    "print(ggplot(XGB_pred, aes(x='Actual', y='Pred'))\n",
    " + geom_point()\n",
    " + scale_x_log10()\n",
    " + scale_y_log10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2z7ZaclxzWF5"
   },
   "outputs": [],
   "source": [
    "GB_pred = pd.DataFrame({\"Pred\": y_test**2, \n",
    "              \"Actual\": clf.predict(scaled_X_Kmeans_test)**2, \n",
    "              \"Residual\":(y_test**2) - (clf.predict(scaled_X_Kmeans_test)**2)})\n",
    "\n",
    "print(ggplot(GB_pred, aes(x='Actual', y='Pred'))\n",
    " + geom_point()\n",
    " + scale_x_log10()\n",
    " + scale_y_log10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dEFG9KPW4TTW"
   },
   "outputs": [],
   "source": [
    "LR_pred = pd.DataFrame({\"Pred\": y_test**2, \n",
    "              \"Actual\": L_R.predict(scaled_X_Kmeans_test)**2, \n",
    "              \"Residual\":(y_test**2) - (L_R.predict(scaled_X_Kmeans_test)**2)})\n",
    "\n",
    "\n",
    "print(ggplot(LR_pred, aes(x='Actual', y='Pred'))\n",
    " + geom_point()\n",
    " + scale_x_log10()\n",
    " + scale_y_log10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhnJLpSx4-wC"
   },
   "outputs": [],
   "source": [
    "SVM_pred = pd.DataFrame({\"Pred\": y_test**2, \n",
    "              \"Actual\": SVM.predict(scaled_X_Kmeans_test)**2, \n",
    "              \"Residual\":(y_test**2) - (SVM.predict(scaled_X_Kmeans_test)**2)})\n",
    "\n",
    "\n",
    "print(ggplot(SVM_pred, aes(x='Actual', y='Pred'))\n",
    " + geom_point()\n",
    " + scale_x_log10()\n",
    " + scale_y_log10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLVWHoXg5GIq"
   },
   "outputs": [],
   "source": [
    "RF_pred = pd.DataFrame({\"Pred\": y_test**2, \n",
    "              \"Actual\": RF.predict(scaled_X_Kmeans_test)**2, \n",
    "              \"Residual\":(y_test**2) - (RF.predict(scaled_X_Kmeans_test)**2)})\n",
    "\n",
    "\n",
    "print(ggplot(RF_pred, aes(x='Actual', y='Pred'))\n",
    " + geom_point()\n",
    " + scale_x_log10()\n",
    " + scale_y_log10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJvB1Yzh6DiD"
   },
   "outputs": [],
   "source": [
    "clfs = [('Random Forest', RF), ('Support Vector',SVM), ('Linear',L_R), \n",
    "        ('XGB',XGB), ('GBM',clf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OGcMtek8MTH"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "SR = StackingRegressor(clfs)\n",
    "\n",
    "SR.fit(scaled_X_Kmeans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dumDflWHOQ91"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sejOqc8ePA7L"
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test**2, \n",
    "                           SR.predict(scaled_X_Kmeans_test)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewGuPqfllfdJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IiMwzSGKlj2O"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=2)\n",
    "split = kf.split(scaled_X_Kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gk_ByhJxmLFA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcOxAPR3s6jx"
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, (train_index, test_index) in enumerate(split):\n",
    "\n",
    "  train_vec = np.zeros((scaled_X_Kmeans.shape[0],))\n",
    "  test_vec = np.zeros((ntrain,))\n",
    "  hold_vec = np.empty((kf.get_n_splits(), ntest))\n",
    "\n",
    "  x_t = scaled_X_Kmeans[train_index]\n",
    "  y_t = y_train[train_index]\n",
    "\n",
    "  clf.fit(scaled_X_Kmeans[train_index], y_train[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1M8bEhkztKx5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mreVv9_tKvr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3urmpAyPRLV"
   },
   "outputs": [],
   "source": [
    "SR_pred = pd.DataFrame({\"Pred\": y_test**2, \n",
    "              \"Actual\": SR.predict(scaled_X_Kmeans_test)**2, \n",
    "              \"Residual\":(y_test**2) - (SR.predict(scaled_X_Kmeans_test)**2)})\n",
    "\n",
    "\n",
    "print(ggplot(SR_pred, aes(x='Actual', y='Pred'))\n",
    " + geom_point()\n",
    " + scale_x_log10()\n",
    " + scale_y_log10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DllQa81r-Gvj",
    "outputId": "bf44789e-d801-4ad6-c512-c43f040ad4f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.2.post1'"
      ]
     },
     "execution_count": 304,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yh-VGX548kMw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WDBch__I8vRn",
    "outputId": "3d2eda81-94e5-4c27-a93d-26215e7881a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6, -5, -4, -3, -2, -1,  0,  1,  2,  3,  4,  5])"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df['MAX_USA_SSHS'].unique())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "omdena-keras-nn_sij.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
