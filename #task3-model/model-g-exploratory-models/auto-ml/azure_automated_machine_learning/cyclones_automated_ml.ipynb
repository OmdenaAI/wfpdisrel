{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Fetched 252 kB in 1s (311 kB/s)\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "19 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt update -y -q\n",
    "!sudo apt install g++ -y -q\n",
    "!pip install -q azureml-sdk azureml-widgets azureml-train-automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.run import get_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'OUTPUT_WBI_exposer_cyclones_v14.csv'\n",
    "input_file_path = Path.cwd()\\\n",
    "    .parent.parent.parent.parent\\\n",
    "    .joinpath('#task4-eda', 'datasets', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/#task4-eda/datasets/OUTPUT_WBI_exposer_cyclones_v14.csv')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclones_df = pd.read_csv(input_file_path, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 991 entries, 0 to 990\n",
      "Data columns (total 51 columns):\n",
      "SID                                                   991 non-null object\n",
      "NAME                                                  991 non-null object\n",
      "ISO                                                   991 non-null object\n",
      "YEAR                                                  991 non-null int64\n",
      "COORDS                                                991 non-null object\n",
      "COORDS_MAX_WINDS                                      991 non-null object\n",
      "COORDS_MIN_DIST2LAND                                  991 non-null object\n",
      "BASIN                                                 991 non-null object\n",
      "SUB BASIN                                             991 non-null object\n",
      "MONTH_START                                           991 non-null int64\n",
      "MONTH_END                                             991 non-null int64\n",
      "DATE_START                                            991 non-null object\n",
      "DATE_END                                              991 non-null object\n",
      "DATE_LAND_START                                       991 non-null object\n",
      "DATE_LAND_END                                         991 non-null object\n",
      "TOTAL_HOURS_EVENT                                     991 non-null float64\n",
      "TOTAL_HOURS_IN_LAND                                   991 non-null float64\n",
      "NATURE                                                991 non-null object\n",
      "GENERAL_CATEGORY                                      991 non-null object\n",
      "MAX_WIND                                              991 non-null float64\n",
      "MIN_PRES                                              991 non-null int64\n",
      "MIN_DIST2LAND                                         991 non-null int64\n",
      "MAX_STORMSPEED                                        989 non-null float64\n",
      "MAX_USA_SSHS                                          991 non-null int64\n",
      "MAX_USA_SSHS_INLAND                                   991 non-null object\n",
      "V_LAND_KN                                             991 non-null float64\n",
      "DISTANCE_TRACK                                        991 non-null float64\n",
      "DISTANCE_TRACK_VINCENTY                               991 non-null float64\n",
      "34KN_POP                                              761 non-null float64\n",
      "64KN_POP                                              761 non-null float64\n",
      "96KN_POP                                              761 non-null float64\n",
      "64KN_ASSETS                                           760 non-null float64\n",
      "34KN_ASSETS                                           760 non-null float64\n",
      "96KN_ASSETS                                           760 non-null float64\n",
      "TOTAL_DAMAGE_(000$)                                   678 non-null float64\n",
      "TOTAL_DEATHS                                          861 non-null float64\n",
      "POP_DEN_SQ_KM                                         991 non-null float64\n",
      "RURAL_POP(%)                                          991 non-null float64\n",
      "HDI                                                   991 non-null float64\n",
      "Arable land (hectares per person)                     990 non-null float64\n",
      "Cereal yield (kg per hectare)                         981 non-null float64\n",
      "Food production index (2004-2006 = 100)               987 non-null float64\n",
      "GDP per capita (constant 2010 US$)                    982 non-null float64\n",
      "Net flows from UN agencies US$                        991 non-null float64\n",
      "Life expectancy at birth, total (years)               987 non-null float64\n",
      "Adjusted savings: education expenditure (% of GNI)    981 non-null float64\n",
      "Income_level_Final                                    991 non-null object\n",
      "POP_MAX_34_ADJ                                        911 non-null float64\n",
      "POP_MAX_50_ADJ                                        911 non-null float64\n",
      "POP_MAX_64_ADJ                                        911 non-null float64\n",
      "TOTAL_AFFECTED                                        991 non-null int64\n",
      "dtypes: float64(28), int64(7), object(16)\n",
      "memory usage: 394.9+ KB\n"
     ]
    }
   ],
   "source": [
    "cyclones_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 3 files\n",
      "Uploading ./data/.ipynb_checkpoints/test-checkpoint.csv\n",
      "Uploading ./data/test.csv\n",
      "Uploading ./data/train.csv\n",
      "Uploaded ./data/test.csv, 1 files out of an estimated total of 3\n",
      "Uploaded ./data/.ipynb_checkpoints/test-checkpoint.csv, 2 files out of an estimated total of 3\n",
      "Uploaded ./data/train.csv, 3 files out of an estimated total of 3\n",
      "Uploaded 3 files\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(cyclones_df, test_size=0.2, random_state=223)\n",
    "\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "train_df.to_csv('data/train.csv', index=False)\n",
    "test_df.to_csv('data/test.csv', index=False)\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data', target_path='cyclonedata', overwrite=True, show_progress=True)\n",
    "\n",
    "training_data = Dataset.Tabular.from_delimited_files(path=ds.path('cyclonedata/train.csv'), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "cpu_cluster_name = \"test-cluster\"\n",
    "\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='STANDARD_DS2_V2',\n",
    "        max_nodes=2,\n",
    "        min_nodes=2)\n",
    "    \n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)\n",
    "\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 5,\n",
    "    \"iterations\": 10,\n",
    "    \"primary_metric\": 'normalized_root_mean_squared_error',\n",
    "    \"preprocess\": True,\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"n_cross_validations\": 5,\n",
    "    \"compute_target\": cpu_cluster,\n",
    "    \"max_cores_per_iteration\": -1,\n",
    "    \"max_concurrent_iterations\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Parameter `preprocess` will be deprecated. Use `featurization`\n",
      "WARNING - Detected both `preprocess` and `featurization`. `preprocess` is being deprecated and will be overridden by `featurization` setting.\n"
     ]
    }
   ],
   "source": [
    "automl_config = AutoMLConfig(task='regression',\n",
    "                             debug_log='automated_ml_errors.log',\n",
    "                             training_data=training_data,\n",
    "                             label_column_name='TOTAL_AFFECTED',\n",
    "                             **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote or ADB.\n",
      "Running on remote compute: test-cluster\n",
      "Parent Run ID: AutoML_dafb46d5-e777-4f0e-afda-ba8aaa355b8b\n",
      "\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  If the missing values are expected, let the run complete. Otherwise cancel the current run and use a script to customize the handling of missing feature values that may be more appropriate based on the data type and business requirement.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "DETAILS:      \n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "|Column name                      |Missing value count              |Imputation type                  |\n",
      "+=================================+=================================+=================================+\n",
      "|MAX_STORMSPEED                   |2                                |mean                             |\n",
      "|34KN_POP                         |181                              |mean                             |\n",
      "|64KN_POP                         |181                              |mean                             |\n",
      "|96KN_POP                         |181                              |mean                             |\n",
      "|64KN_ASSETS                      |182                              |mean                             |\n",
      "|34KN_ASSETS                      |182                              |mean                             |\n",
      "|96KN_ASSETS                      |182                              |mean                             |\n",
      "|TOTAL_DAMAGE_(000$)              |256                              |mean                             |\n",
      "|TOTAL_DEATHS                     |107                              |mean                             |\n",
      "|Arable land (hectares per person)|1                                |mean                             |\n",
      "|Cereal yield (kg per hectare)    |10                               |mean                             |\n",
      "|Food production index (2004-20...|4                                |mean                             |\n",
      "|GDP per capita (constant 2010 ...|7                                |mean                             |\n",
      "|Life expectancy at birth, tota...|4                                |mean                             |\n",
      "|Adjusted savings: education ex...|8                                |mean                             |\n",
      "|POP_MAX_34_ADJ                   |66                               |mean                             |\n",
      "|POP_MAX_50_ADJ                   |66                               |mean                             |\n",
      "|POP_MAX_64_ADJ                   |66                               |mean                             |\n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  High cardinality features were detected in your inputs and handled.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "DETAILS:      High cardinality features refer to columns that contain a large percentage of unique values.\n",
      "+---------------------------------+---------------------------------+\n",
      "|Column name                      |Column Content Type              |\n",
      "+=================================+=================================+\n",
      "|NAME                             |categorical_hash                 |\n",
      "|ISO                              |categorical_hash                 |\n",
      "|COORDS                           |text                             |\n",
      "|COORDS_MAX_WINDS                 |text                             |\n",
      "|COORDS_MIN_DIST2LAND             |text                             |\n",
      "+---------------------------------+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:02:53       0.0875    0.0875\n",
      "         1   StandardScalerWrapper ElasticNet               0:06:10          nan    0.0875\n",
      "ERROR: TimeoutException:\n",
      "\tMessage: \n",
      "\tInnerException: None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"UserError\",\n",
      "        \"inner_error\": {\n",
      "            \"code\": \"EarlyTermination\"\n",
      "        },\n",
      "        \"message\": \"\"\n",
      "    }\n",
      "}\n",
      "ERROR: TimeoutException:\n",
      "\tMessage: \n",
      "\tInnerException: None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"UserError\",\n",
      "        \"inner_error\": {\n",
      "            \"code\": \"EarlyTermination\"\n",
      "        },\n",
      "        \"message\": \"\"\n",
      "    }\n",
      "}\n",
      "         2   StandardScalerWrapper ElasticNet               0:06:02          nan    0.0875\n",
      "ERROR: TimeoutException:\n",
      "\tMessage: \n",
      "\tInnerException: None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"UserError\",\n",
      "        \"inner_error\": {\n",
      "            \"code\": \"EarlyTermination\"\n",
      "        },\n",
      "        \"message\": \"\"\n",
      "    }\n",
      "}\n",
      "ERROR: TimeoutException:\n",
      "\tMessage: \n",
      "\tInnerException: None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"UserError\",\n",
      "        \"inner_error\": {\n",
      "            \"code\": \"EarlyTermination\"\n",
      "        },\n",
      "        \"message\": \"\"\n",
      "    }\n",
      "}\n",
      "         3   StandardScalerWrapper ElasticNet               0:06:04          nan    0.0875\n",
      "ERROR: TimeoutException:\n",
      "\tMessage: \n",
      "\tInnerException: None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"UserError\",\n",
      "        \"inner_error\": {\n",
      "            \"code\": \"EarlyTermination\"\n",
      "        },\n",
      "        \"message\": \"\"\n",
      "    }\n",
      "}\n",
      "ERROR: TimeoutException:\n",
      "\tMessage: \n",
      "\tInnerException: None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"UserError\",\n",
      "        \"inner_error\": {\n",
      "            \"code\": \"EarlyTermination\"\n",
      "        },\n",
      "        \"message\": \"\"\n",
      "    }\n",
      "}\n",
      "         5   StandardScalerWrapper RandomForest             0:02:04       0.0847    0.0847\n",
      "         4   StandardScalerWrapper ElasticNet               0:06:02          nan    0.0847\n",
      "ERROR: TimeoutException:\n",
      "\tMessage: \n",
      "\tInnerException: None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"UserError\",\n",
      "        \"inner_error\": {\n",
      "            \"code\": \"EarlyTermination\"\n",
      "        },\n",
      "        \"message\": \"\"\n",
      "    }\n",
      "}\n",
      "ERROR: TimeoutException:\n",
      "\tMessage: \n",
      "\tInnerException: None\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"UserError\",\n",
      "        \"inner_error\": {\n",
      "            \"code\": \"EarlyTermination\"\n",
      "        },\n",
      "        \"message\": \"\"\n",
      "    }\n",
      "}\n",
      "         6   StandardScalerWrapper LightGBM                 0:02:27       0.0790    0.0790\n",
      "         7   MaxAbsScaler DecisionTree                      0:02:25       0.0954    0.0790\n",
      "         9   StackEnsemble                                  0:02:03       0.0802    0.0790\n",
      "         8   VotingEnsemble                                 0:02:08       0.0790    0.0790\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(ws, \"cyclone-experiment\")\n",
    "# run = get_run(experiment, 'AutoML_963f860f-806d-4e86-b399-2c24f537f73c')\n",
    "run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: cyclone-experiment,\n",
      "Id: AutoML_dafb46d5-e777-4f0e-afda-ba8aaa355b8b_8,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "RegressionPipeline(pipeline=Pipeline(memory=None,\n",
      "     steps=[('datatransformer', DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
      "        feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
      "        featurization_config=None, force_text_dnn=None,\n",
      "        is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
      "        obser...=200000, subsample_freq=7, verbose=-1))]))],\n",
      "               flatten_transform=None, weights=[1.0]))]),\n",
      "          stddev=None)\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = test_df.columns.tolist()\n",
    "columns.remove('TOTAL_AFFECTED')\n",
    "\n",
    "y_test = test_df['TOTAL_AFFECTED']\n",
    "x_test = test_df.loc[:,columns]\n",
    "\n",
    "y_predict = fitted_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse:  2334574.3848183285\n",
      "r2:  0.18283851754988156\n",
      "msle:  3.7346262843470184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from math import sqrt\n",
    "\n",
    "y_actual = y_test.values.flatten().tolist()\n",
    "rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
    "print('rmse: ', rmse)\n",
    "r2 = r2_score(y_actual, y_predict)\n",
    "print('r2: ', r2)\n",
    "msle = sqrt(mean_squared_log_error(y_actual, y_predict))\n",
    "print('msle: ', msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
