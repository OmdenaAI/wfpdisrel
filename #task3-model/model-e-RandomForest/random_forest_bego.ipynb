{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "# import data\n",
    "df = pd.read_csv('../../#task1-datacollection/OUTPUT_WBI_exposer_cyclones_v3.csv')\n",
    "df.columns = [e.lower().replace(' ','_') for e in df.columns]\n",
    "\n",
    "# separate X and y\n",
    "X = df.drop(['total_affected'], axis=1)\n",
    "y = df['total_affected']\n",
    "\n",
    "# types of features\n",
    "num_features = list(df.loc[:, df.dtypes != object].columns)\n",
    "cat_features = list(df.loc[:, df.dtypes == object].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transformers\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    # selects a slice of the dataset based on feature_names\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[set(X.columns).intersection(self.feature_names)]\n",
    "\n",
    "\n",
    "class TransformerCat(BaseEstimator, TransformerMixin):\n",
    "    # transforms categorical features\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.columns_to_drop = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns_to_drop= ['sid', 'name', 'iso', 'sub_basin', 'nature', 'iso_time',\n",
    "       'coords', 'in_susan', 'year_tiff_c']\n",
    "        return self\n",
    "    \n",
    "    def _get_income_level(self, income):\n",
    "        order = {'High': 4, 'High_Middle': 3, 'Low_Middle': 2, 'Low': 1 }\n",
    "        return order[income]\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        X['income_level_final'] = X['income_level_final'].apply(self._get_income_level)\n",
    "        X = X.drop(self.columns_to_drop, axis = 1)\n",
    "        return X\n",
    "    \n",
    "class TransformerNum(BaseEstimator, TransformerMixin):\n",
    "    # transforms numerical features\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.columns_to_drop = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns_to_drop = ['unnamed:_0', 'year', 'total_hrs', 'day_hrs', 'night_hrs',\n",
    "                                '34kn_pop', '34kn_assets', '64kn_pop', '64kn_assets','total_damage_(000$)', 'total_deaths',\n",
    "                               'air_transport,_freight_(million_ton-km)',\n",
    "                               'arable_land_(hectares_per_person)', 'cereal_yield_(kg_per_hectare)',\n",
    "                               'food_production_index_(2004-2006_=_100)', 'gdp_growth_(annual_%)','net_flows_from_un_agencies_us$',\n",
    "                               'mobile_cellular_subscriptions_(per_100_people)',\n",
    "                               'adjusted_savings:_education_expenditure_(%_of_gni)',\n",
    "                               'population_2000', 'population_2005',\n",
    "                               'population_2010', 'population_2015', 'population_2020', 'in_wbi',\n",
    "                               'pop_max_34', 'pop_max_50', 'pop_max_64', 'numeric', 'pop_max_34_adj',\n",
    "                               'pop_max_50_adj', 'year_tiff', 'coef_year']\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.drop(self.columns_to_drop, axis = 1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess pipeline\n",
    "\n",
    "preprocess_pipeline = FeatureUnion(transformer_list =[\n",
    "        (\"num_pipeline\", Pipeline([\n",
    "            ('selector', DataFrameSelector(num_features)),\n",
    "            ('num_transformer', TransformerNum()),\n",
    "            ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "             ])),\n",
    "        (\"cat_pipeline\", Pipeline([\n",
    "            ('selector', DataFrameSelector(cat_features)),\n",
    "            ('cat_transformer', TransformerCat()),\n",
    "            ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse = False)), # TODO: not encode income_level_final\n",
    "            (\"scaler\", StandardScaler())\n",
    "            ]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    # evaluates different models using cross validation on the whole dataset\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def evaluate_models(self, models):\n",
    "        for model_name, model in models.items():\n",
    "            print(f'***{model_name}***')\n",
    "            self._evaluate_model(model_name, model)\n",
    "            print('\\n')\n",
    "            \n",
    "    def _display_scores(self, scores):\n",
    "            print(\"Scores:\", scores)\n",
    "            print(\"Mean:\", scores.mean())\n",
    "            print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "    def _evaluate_model(self, model_name, model):\n",
    "        transformed_X = preprocess_pipeline.fit_transform(self.X)\n",
    "        scores = cross_val_score(model, transformed_X, self.y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        tree_rmse_scores = np.sqrt(-scores)\n",
    "        self._display_scores(tree_rmse_scores)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 168 candidates, totalling 1008 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2507844188752.267\n",
      "{'max_features': 2, 'min_samples_leaf': 6, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1008 out of 1008 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "# grid search random_forest\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': list(range(10,200,30)), 'max_features': list(range(2, 10, 2)), 'min_samples_leaf':[2,4,6]},\n",
    "    {'bootstrap': [False], 'n_estimators': list(range(10,200,30)), 'max_features': list(range(2, 10, 2)), 'min_samples_leaf':[2,4,6]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "grid_search_forest = GridSearchCV(forest_reg, \n",
    "                                  param_grid, \n",
    "                                  cv=6, \n",
    "                                  scoring='neg_mean_squared_error', \n",
    "                                  return_train_score=True, \n",
    "                                  iid = True, \n",
    "                                  verbose=1) # higher verbose desactivated for Github visualization purposes\n",
    "transformed_X = preprocess_pipeline.fit_transform(X)\n",
    "grid_search_forest.fit(transformed_X, y)\n",
    "\n",
    "print(grid_search_forest.score(transformed_X, y))\n",
    "print(grid_search_forest.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***forest_grid_search***\n",
      "Scores: [ 801246.98124193 1192102.05630572 1415787.85084803 1649069.59585499\n",
      " 1216158.82270432 3788041.75874604 1571856.45248941 1174365.29334794\n",
      " 2206267.61955972 2158662.00958737]\n",
      "Mean: 1717355.8440685451\n",
      "Standard deviation: 806193.9304452471\n",
      "\n",
      "\n",
      "***forest_1***\n",
      "Scores: [1203935.6467219  1221914.54210311 1866030.4192242  2041583.1177857\n",
      " 2446371.91911332 4023303.5768814  1727616.98042126 1375373.83548063\n",
      " 2269022.99047438 3266021.47866986]\n",
      "Mean: 2144117.450687577\n",
      "Standard deviation: 865081.1179126535\n",
      "\n",
      "\n",
      "***forest_2***\n",
      "Scores: [1070183.89069505 1213526.78678144 1433558.66806751 1807821.43924724\n",
      " 1229701.83592892 3792966.29749878 1380569.79691128 1163771.04404076\n",
      " 2185099.52482229 2301506.80894139]\n",
      "Mean: 1757870.609293467\n",
      "Standard deviation: 791886.8804492861\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate models \n",
    "\n",
    "models = {'forest_grid_search': grid_search_forest.best_estimator_, \n",
    "          'forest_1': RandomForestRegressor(n_estimators=3, random_state=42), \n",
    "          'forest_2':RandomForestRegressor(max_depth=5, n_estimators=10, max_features=9, random_state=42)}\n",
    "\n",
    "random_forest_evaluator = ModelEvaluator(X, y)\n",
    "\n",
    "random_forest_evaluator.evaluate_models(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
